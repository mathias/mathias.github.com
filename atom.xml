<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[blog.mattgauger.com]]></title>
  <link href="http://blog.mattgauger.com/atom.xml" rel="self"/>
  <link href="http://blog.mattgauger.com/"/>
  <updated>2014-07-27T12:14:41-05:00</updated>
  <id>http://blog.mattgauger.com/</id>
  <author>
    <name><![CDATA[Matt Gauger]]></name>
    <email><![CDATA[contact@mattgauger.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Housekeeping: Imported Coderwall protips]]></title>
    <link href="http://blog.mattgauger.com/blog/2014/07/27/housekeeping-imported-coderwall-protips/"/>
    <updated>2014-07-27T12:05:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2014/07/27/housekeeping-imported-coderwall-protips</id>
    <content type="html"><![CDATA[<p>As part of my continuing effort to archive content I&#8217;ve created to this blog, I&#8217;ve migrated all of <a href="https://coderwall.com/p/u/mathias">my Coderwall protips</a>.</p>

<p>Here&#8217;s a quick list of the posts:</p>

<ul>
<li><a href="http://blog.mattgauger.com/blog/2013/11/14/indent-and-colorize-html-strings-in-pry/">Indent and Colorize HTML Strings in Pry</a> <em>November 14, 2013.</em></li>
<li><a href="http://blog.mattgauger.com/blog/2013/09/03/git-fml/">git fml</a> <em>September 3, 2013.</em></li>
<li><a href="http://blog.mattgauger.com/blog/2013/07/27/minskys-circle-algorithm-in-shoes-dot-rb-slash-hackety-hack/">Minsky&#8217;s Circle Algorithm in Shoes.rb / Hackety Hack</a> <em>July 27, 2013.</em></li>
<li><a href="http://blog.mattgauger.com/blog/2013/05/23/warning-nokogiri-was-built-against-libxml-version-x-dot-x-x/">WARNING: Nokogiri Was Built Against LibXML Version x.x.x</a> <em>May 23, 2013.</em></li>
<li><a href="http://blog.mattgauger.com/blog/2013/04/24/reset-a-lost-password-on-an-ubuntu-vm/">Reset a Lost Password on an Ubuntu VM</a> <em>April 24, 2013.</em></li>
<li><a href="http://blog.mattgauger.com/blog/2013/01/24/find-naughty-naughty-model-calls-in-your-views/">Find Naughty Naughty Model Calls in Your Views</a> <em>January 24, 2013.</em></li>
<li><a href="http://blog.mattgauger.com/blog/2012/12/25/find-a-unique-name-for-your-project/">Find a Unique Name for Your Project</a> <em>December 25, 2012.</em></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure Data Science: Refactoring and Cleanup]]></title>
    <link href="http://blog.mattgauger.com/blog/2014/04/13/clojure-data-science-refactoring-and-cleanup/"/>
    <updated>2014-04-13T16:28:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2014/04/13/clojure-data-science-refactoring-and-cleanup</id>
    <content type="html"><![CDATA[<hr />

<p>This is Part 2 of a series of blog posts called <a href="http://blog.mattgauger.com/blog/categories/clojure-data-science">Clojure Data Science</a>. Check out the <a href="http://blog.mattgauger.com/blog/2014/03/30/clojure-data-science-ingesting-your-gmail-inbox/">previous post</a> if you missed it.</p>

<hr />

<p>Welcome to the second post in this series. If you followed along in the last post, your code should be ready to use in this post. If not, or if you need to go back to known working state, you can clone the <a href="https://github.com/mathias/autodjinn">autodjinn repo</a> and <code>git checkout v0.1.0</code>.</p>

<p>I started out writing this post to develop simple functionality on our inbox data. Finishing the post was taking longer than I was expecting, so I split the post in half in the interest of posting this sooner.</p>

<p>In this post, we need to create an email ingestion script that we can run repeatedly with <code>lein</code>. And we need to talk about refactoring our code out into maintainable namespaces.</p>

<p>So make sure your Datomic transactor is running and launch a REPL, because it is time to give our code a makeover.</p>

<h2>A Gmail ingestion script</h2>

<p>Because Clojure sits on the JVM, it shares some similarities with Java. One of these is the special purpose of a <code>-main</code> function. You can think of this as the <code>main</code> method in a Java class. The <code>-main</code> function in a Clojure namespace will be run when a tool like <code>lein</code> tries to &#8220;run&#8221; the namespace. That sounds like exactly what we want to do with our Gmail import functionality, so we will add a <code>-main</code> function that calls our <code>ingest-inbox</code> function. To get started, we will only have it print us a message.</p>

<script src="https://gist.github.com/mathias/9965864.js"></script>


<p>You can then run this by invoking <code>lein run -m autodjinn.core</code>. You should see <code>Hello world!</code> if everything worked. You may notice that the process doesn&#8217;t seem to quit after it prints the hello world message &#8211; this seems to be problem with Leiningen. To ensure that our process ends when the script is done, we can add a <code>(System/exit 0)</code> line to the end of our <code>-main</code> function to ensure that the process quits normally. On *nix systems, a 0 return code means successful exit, and a nonzero response code means something went wrong. Knowing this, we can take advantage of response codes in the future to signal that an error occurred in our script. But for now, we will have the script end by returning 0 to indicate a successful exit.</p>

<p>Think back to what we did to ingest email in our REPL in the last post. We had to connect to the database, run the data schema transaction, and then we were able to run <code>ingest-inbox</code> to pull in our email.</p>

<p>The following function will do the same thing. Remember that things like trying to create an existing database or performing a schema update against the same schema in Datomic should be harmless. It will add a new transaction ID, but it will not modify or destroy data. Putting together all the steps we need to run, we get a <code>-main</code> function that looks like this:</p>

<script src="https://gist.github.com/mathias/9965933.js"></script>


<h2>Refactoring namespaces</h2>

<p>With Clojure, one must walk a fine line between putting all of your functions into one big file, and having too many namespaces. One big file quickly grows unmaintainable and gains too many responsibilities.</p>

<p>But having too many namespaces can also be a problem. It may create strange cyclic dependency errors. Or you may find that with many separate namespaces, you have to require many namespaces to get anything done.</p>

<p>To avoid this, I start with most code in one namespace, and then look for common functionality to extract to a new namespace. Good candidates to extract are those that all talk about the same business logic or business domain. You may notice that the responsibility for one group of functions is different than the rest of the functions. That is a good candidate for a new namespace. Looking at responsibilities can be a good way to determine where to break apart functions into namespaces.</p>

<p>In this project, we can identify two responsibilities that currently live in our autodjinn.core namespace. The first is working with the database. The second is ingesting Gmail messages. As our project grows, we will not want the code for ingesting Gmail messages to live in <code>autodjinn.core</code>. With that in mind, let&#8217;s create a new file called <code>src/autodjinn/gmail_ingestion.clj</code> and move over the vars and functions that we think should live there. That file should look like this:</p>

<script src="https://gist.github.com/mathias/9966207.js"></script>


<p>Be sure to remove the functions and vars that we moved to this file from the <code>autodjinn.core</code> namespace. Note that we moved the <code>-main</code> function here, too, so that we can now run <code>lein run -m autodjinn.gmail-ingestion</code></p>

<p>You may also notice that we still had to require the <code>datomic.api</code> namespace here to be able to perform a transaction. Our <code>autodjinn.core</code> namespace already handles database interaction, though. So let&#8217;s write a <code>create-mail</code> function in <code>core.clj</code> and call it in our new namespace:</p>

<script src="https://gist.github.com/mathias/9966294.js"></script>


<p>And in <code>gmail_ingestion.clj</code> we change <code>ingest-inbox</code> to use the new function. While we&#8217;re at it, we&#8217;ll break out a convenience function to prepare the attr map for Datomic:</p>

<script src="https://gist.github.com/mathias/9966304.js"></script>


<p>If we run our <code>lein run -m autodjinn.gmail-ingestion</code> command, we should see that the code is still working.</p>

<p>Don&#8217;t forget to remove the <code>datomic.api</code> requirement in <code>gmail-ingestion</code> namespace! Now we only need to require Datomic in the <code>autodjinn.core</code> namespace.</p>

<p>There&#8217;s one more low-hanging fruit that we can refactor about this code before moving on. The config file is loaded and used in both namespaces. We already require everything from <code>autodjinn.core</code> into <code>autodjinn.gmail-ingestion</code>. So we can safely change a few lines to use the config in <code>gmail_ingestion.clj</code> and stop requiring <code>nomad</code> in two places:</p>

<script src="https://gist.github.com/mathias/9966372.js"></script>


<p>And in <code>core.clj</code>:</p>

<script src="https://gist.github.com/mathias/9966384.js"></script>


<p>Running <code>lein run -m autodjinn.gmail-ingestion</code> one more time, we should see that our changes did not break the system. The config is now only loaded once, and we use it everything.</p>

<p>That&#8217;s it! We&#8217;ve taken care of some low-hanging fruit and are ready to implement some new functionality. If you want to compare what you&#8217;ve done with my version, you can run <code>git diff v0.1.1</code> on the <a href="https://github.com/mathias/autodjinn">autodjinn repo</a>.</p>

<p>Please let me know what you think of these posts by sending me an email at <a href="mailto:contact@mattgauger.com">contact@mattgauger.com</a>. I&#8217;d love to hear from you!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure Data Science: Ingesting Your Gmail Inbox]]></title>
    <link href="http://blog.mattgauger.com/blog/2014/03/30/clojure-data-science-ingesting-your-gmail-inbox/"/>
    <updated>2014-03-30T14:44:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2014/03/30/clojure-data-science-ingesting-your-gmail-inbox</id>
    <content type="html"><![CDATA[<hr />

<p>This is Part 1 of a series of blog posts inspired by the exercises from <a href="http://shop.oreilly.com/product/0636920025054.do">Agile Data Science</a> with Clojure. You may be interested in my <a href="http://blog.mattgauger.com/blog/2014/03/14/agile-data-science-review-and-thoughts/">review</a> of the book.</p>

<hr />

<p>For this blog post series, we are going to use your Gmail inbox as a dataset for an exploration of data science practices. Namely, we will use your email for machine learning and natural language processing applications. Email makes interesting data to process:</p>

<ul>
<li>it has lots of metadata that we can use as features <a href="#cds-gmail-footnote-1" name="cds-gmail-footnote-1-return">[1]</a></li>
<li>we can model the relationships of senders and receivers as a graph</li>
<li>each message has a body of text associated with it that we can analyze</li>
<li>gaining insights from our personal communication is far more interesting than using an open data set!</li>
</ul>


<p><strong>Note:</strong> This is not an intro-to-Clojure blog post. If you need a tutorial that starts with the basics, I recommend the <a href="http://aphyr.com/tags/Clojure-from-the-ground-up">Clojure from the ground up</a> blog post series by <a href="https://twitter.com/aphyr">Aphyr</a>. It does an excellent job at introducing concepts in Clojure.</p>

<p>In this post, I follow my typical Clojure workflow: I open a REPL and begin exploring the problem space. I look at individual pieces of data and start transforming them. When I write some functionality that I like for one piece of data, I try to extract it into the source code as a function that can work for any data our project may see. In this way, we can build up the project to contain the functions that are necessary to get to our goal.</p>

<p>So what is our goal for this blog post? Well, we want to fetch all emails from our Gmail inbox. We want to get metadata for each email, including things like who sent it and when it was sent. Then, we want to save the messages into a database so we can do further processing in later posts.</p>

<p>Starting off, make a new basic Clojure project with lein. I&#8217;ve named my project <a href="https://github.com/mathias/autodjinn">autodjinn</a> after <a href="http://en.wikipedia.org/wiki/Email#Origin">AUTODIN</a>, one of the first email networks. You can use the <a href="https://github.com/mathias/autodjinn">repo</a> to refer to and to clone to follow along. At the beginning of each subsequent post, I&#8217;ll provide a SHA that you can reset the code to. Feel free to name your project whatever you want; just be sure to pay attention to the changes in filenames and namespaces as we go along!</p>

<p>Create the project and enter it:</p>

<script src="https://gist.github.com/mathias/9861772.js"></script>


<p>To import our Gmail data, we will use a Clojure library called <a href="https://github.com/owainlewis/clojure-mail">clojure-mail</a>. Clojure-mail is still under active development and is likely to change. For this blog post, we&#8217;ll be using version <code>0.1.6</code> to ensure compatibility between the code in this post and the library.</p>

<p>Edit <code>project.clj</code> to contain your information and add the <code>[clojure-mail "0.1.6"]</code> dependency:</p>

<script src="https://gist.github.com/mathias/9861804.js"></script>


<p>We&#8217;ll start by working in <code>src/autodjinn/core.clj</code> and later move the functionality out into a script for our email import task. Open up the file in your favorite editor and launch a REPL.</p>

<p>In your REPL, <code>(use 'autodjinn.core)</code> and verify it worked by running <code>(foo "MYNAME")</code>. You should see &#8220;MYNAME Hello, World!&#8221; printed out. Feel free to remove the <code>(defn foo…)</code> in <code>core.clj</code> now. We will not need it.</p>

<p>You may want to use something like Emacs&#8217; <a href="https://github.com/clojure-emacs/cider">cider</a> or LightTable&#8217;s InstaREPL as your REPL environment. But you can use the regular Clojure REPL to build this project, as well. If you are not working with a REPL integrated to your editor, you will need to run <code>(use 'autodjinn.core :reload)</code> to force a reload of the code each time you save.</p>

<h2>Connecting to Gmail</h2>

<p>Our first goal is to connect to our inbox and verify that we can read email from it. To do that, we&#8217;re going to need to use our Gmail address and password &mdash; which we don&#8217;t want to put into our source files. <strong>It&#8217;s bad practice to put a password or a private key into a source file or check it into our repo! Just don&#8217;t do it!</strong></p>

<p>Instead, we will use a nice library called <a href="https://github.com/james-henderson/nomad">nomad</a> to load a config file containing our email address and password. We will add the config file to <code>.gitignore</code> so that it is never saved into our code.</p>

<p>Add the line <code>[jarohen/nomad "0.6.3"]</code> to your <code>project.clj</code> dependencies before moving on, and run <code>lein deps</code> in a console to pull in the dependency.</p>

<p>Back in our <code>core.clj</code> add the require statements for <code>clojure-mail</code> and <code>nomad</code> to your ns macro like this:</p>

<script src="https://gist.github.com/mathias/9863912.js"></script>


<p>Then create a new file in <code>resources/config/autodjinn-config.edn</code>. It should look like this, with your email address and password filled in:</p>

<script src="https://gist.github.com/mathias/9864315.js"></script>


<p>Now open up your <code>.gitignore</code> file and add the following line to it:</p>

<script src="https://gist.github.com/mathias/9866473.js"></script>


<p>Following <a href="https://github.com/james-henderson/nomad#hello-world">nomad&#8217;s README</a>, we need to load our config file and pull out our <code>gmail-username</code> and <code>gmail-password</code> keys. We add to the following to <code>core.clj</code> after the <code>ns</code> macro:</p>

<script src="https://gist.github.com/mathias/8c0849fc0e137f1bd611.js"></script>


<p>Using the <code>get</code> function here is a safe lookup for maps that returns <code>nil</code> if nothing is found for the key. Back in our REPL, we can see this in action with some quick experimentation:</p>

<script src="https://gist.github.com/mathias/9864411.js"></script>


<p>We could also use the shorter <code>(:keyname mymap)</code> syntax here, since symbols are an invocable function that looks up a key in a map. But the <code>get</code> function reads better than <code>(:gmail-username (autodjinn-config))</code> in my opinion.</p>

<p>In your REPL, you should now be able to get the values for <code>gmail-username</code> and <code>gmail-password</code>:</p>

<script src="https://gist.github.com/mathias/9864585.js"></script>


<p>Note that since I&#8217;m in the <code>user</code> namespace here, I had to qualify the vars with their <code>autodjinn.core</code> namespace. If this is confusing, you might want to read up on <a href="http://clojure-doc.org/articles/language/namespaces.html">namespaces in Clojure</a> before moving on. (See also: the &#8216;Namespaces&#8217; section in <a href="http://aphyr.com/posts/311-clojure-from-the-ground-up-logistics">Clojure from the ground up: logistics</a>.)</p>

<p><code>clojure-mail</code> requires us to open a connection to Gmail with the <code>gen-store</code> function (<a href="https://github.com/owainlewis/clojure-mail/blob/c3aad67b42aad96405d4c329ca48e29b7960d412/src/clojure_mail/core.clj#L80-L83">src</a>). We then pass that connection around to various functions to interact with our inbox. Define a var called <code>my-store</code> in your <code>core.clj</code> that does this with our email address and password:</p>

<script src="https://gist.github.com/mathias/9865909.js"></script>


<p>Make sure the <code>(def my-store…</code> above has been run in your REPL and then take a look at our open connection:</p>

<script src="https://gist.github.com/mathias/9865937.js"></script>


<p>The type of <code>my-store</code> should be an <code>IMAPSSLStore</code> as above. If it didn&#8217;t work, you&#8217;ll see a string error message when you try to define <code>my-store</code>.</p>

<h2>Your inbox as a list</h2>

<p>Now we&#8217;ll use our REPL to build up a function that will eventually import all of our email. To start, we can use the <code>inbox</code> function (<a href="https://github.com/owainlewis/clojure-mail/blob/c3aad67b42aad96405d4c329ca48e29b7960d412/src/clojure_mail/core.clj#L198-L201">src</a>) from <code>clojure-mail</code> to get a seq of messages in our inbox. Note that since it is a seq and inboxes can be very large, we limit it with the <code>take</code> function.</p>

<script src="https://gist.github.com/mathias/9866030.js"></script>


<p>If everything is working, you should see a list of of the <code>IMAPMessage</code>s returned by the last line in your REPL.</p>

<p>What if, instead, we wanted to loop over many messages and print out their subjects? We can pull in the <code>message</code> namespace (<a href="https://github.com/owainlewis/clojure-mail/blob/master/src/clojure_mail/message.clj">src</a>) from <code>clojure-mail</code>, which gives us convenience functions for getting at message data.</p>

<p>You&#8217;ll have to be careful running this next line &mdash; on a large inbox it&#8217;ll print out the subject of everything in your inbox! If you have a lot of messages, consider wrapping the call to <code>inbox</code> in a <code>take</code> as above.</p>

<script src="https://gist.github.com/mathias/9866059.js"></script>


<p>Those are the subject lines of the 4 messages in the inbox of my test account, so I know that this is working. Save our <code>doseq</code> line into a function called <code>ingest-inbox</code>; we&#8217;ll come back to it later:</p>

<script src="https://gist.github.com/mathias/9866289.js"></script>


<h2>Examining messages</h2>

<p>Before we move on, let&#8217;s take a look at an individual message and what we can get out of it from the <code>message</code> namespace.</p>

<script src="https://gist.github.com/mathias/9866195.js"></script>


<p>From this, we can see a few things:</p>

<ul>
<li>The ID returned by <code>message/id</code> looks like a good candidate to get good unique IDs for each message when we store the messages. But we might want to strip off those angle brackets first.</li>
<li>The <code>message/message-body</code> function doesn&#8217;t return a string of the body. Instead, it returns a list of maps which contains the <code>text/plain</code> form of the body and the <code>text/html</code> form. We will have to extract each from the map so that we can use the plaintext version for things like language processing. We&#8217;ll also keep the HTML version in case we need it later.</li>
<li>If you started digging in to the <code>message</code> namespace&#8217;s source you may have noticed that we don&#8217;t have functions for getting date sent or date received for a message. Nor can we get a list of addresses CCed or BCCed for the message. We&#8217;ll have to write those functions ourselves.</li>
</ul>


<h2>Cleaning up the IDs</h2>

<p>Let&#8217;s focus on writing a function to clean up the ID returned by the <code>message/id</code> function. Recall that such IDs look like <code>&lt;CAJiAYR90LbbN6k8tVXuhQc8f6bZoK647ycdc7mxF5mVEaoLKHw@mail.gmail.com&gt;</code></p>

<p>The <code>clojure.string</code> namespace provides a <code>replace</code> function which does simple replacement on a string. We can use it like this:</p>

<script src="https://gist.github.com/mathias/9866344.js"></script>


<p>That worked for replacing the angle brackets for the original string. But remember that data structures are immutable in Clojure, including strings. Replacing the first angle bracket didn&#8217;t change the original string when we tried to replace the other angle bracket. We need something that allows us to build up an intermediate value and pass it to the next function. For that, we will use the <a href="http://clojure.github.io/clojure/clojure.core-api.html#clojure.core/-%3e">thread-first</a> macro: <code>-&gt;</code>. It is easiest if I show the macro in use with some comments showing what the intermediate values would be at each step:</p>

<script src="https://gist.github.com/mathias/9866380.js"></script>


<p>It is called the <strong>thread-first</strong> macro because it threads through the first argument to each function. In this case, <code>clojure.string/replace</code>&#8217;s first argument is the string to replace on. So the each successively returned value gets passed to the next function above.</p>

<p>Now that we&#8217;ve figured out how to clean up that ID, we will create a function to clean up any ID we pass it:</p>

<script src="https://gist.github.com/mathias/9866436.js"></script>


<h2>Extracting the message bodies</h2>

<p>Recall the <code>message/message-body</code> call above:</p>

<script src="https://gist.github.com/mathias/9866777.js"></script>


<p>Ideally, we want to write a function that can get the <code>text/plain</code> body out of this value, and another function that can get the <code>text/html</code> body out. Notice that the <code>:content-type</code> values aren&#8217;t quite so simple as just selecting the item in the list where the string <code>text/plain</code> appears. We will need our function to ignore the additional information in the <code>:content-type</code> value, which includes things like string encodings.</p>

<p>Let&#8217;s look at just the first map in the list returned by <code>message/message-body</code>:</p>

<script src="https://gist.github.com/mathias/9866861.js"></script>


<p>If we build a predicate function that can detect when the <code>:content-type</code> key is the type we want, we can use it in a <code>filter</code> function to choose the correct type of body in our functions.</p>

<p>Notice that <code>TEXT/PLAIN</code> and <code>TEXT/HTML</code> are always separated from the rest of the content-type by a semicolon, and it always appears first. You&#8217;d have to look at a few messages from your inbox to arrive at the same conclusion, but I&#8217;ve already done the work and can assure you that the previous statement is true.</p>

<p>Then, an easy to to get at the part of the content-type we want would be to split on the semicolon and take the first element returned:</p>

<script src="https://gist.github.com/mathias/9867049.js"></script>


<p>This leads us to a function to first clean up the content-type string, and then our predicate function to detect if it is the one we want:</p>

<script src="https://gist.github.com/mathias/9867072.js"></script>


<p>To finish off our work on the message bodies, we want to filter the list returned by <code>message/message-body</code>:</p>

<script src="https://gist.github.com/mathias/9867356.js"></script>


<p>And turn it into a function that works for any message bodies list:</p>

<script src="https://gist.github.com/mathias/9867382.js"></script>


<p>Note that we&#8217;ve also used this function to create two convenience functions, one for extracting plaintext bodies and one for extracting HTML bodies. By keeping functions simple and small, we can build up useful functions for our project rather than try to plan it all out ahead of time.</p>

<h2>Getting more information out of the IMAPMessages</h2>

<p>As noted above, we will need to write a few more functions to get the fields of the <code>IMAPMessage</code>s that we cannot get through this version of <code>clojure-mail</code>. Recall that we want to get CC list, BCC list, date sent, and date received values. To do that, we will use Java interop functionality. It&#8217;s really not as bad as it sounds. Remember that the <code>IMAPMessage</code>s we see are Java instances of the <code>IMAPMessage</code> class. Calling a method on an instance is accomplished by using a dot before the method name, with the method in the function position, such as: <code>(.javaMethod some-java-instance)</code></p>

<p>To start, we can look at <code>clojure-mail</code>&#8217;s <a href="https://github.com/owainlewis/clojure-mail/blob/c3aad67b42aad96405d4c329ca48e29b7960d412/project.clj">project.clj</a> and see that it depends on <code>javax.mail</code>. The next step is to find the documentation for the Java implementation of <code>javax.mail.Message</code>, which <a href="http://docs.oracle.com/javaee/6/api/javax/mail/Message.html">lives here</a>.</p>

<p>In the REPL, we can try some of the Java interop on our <code>my-msg</code>:</p>

<script src="https://gist.github.com/mathias/9876540.js"></script>


<p>The datetimes for each message are automatically turned into Clojure instants for us, which is convenient. If we dig into how the <code>clojure-mail.message/to</code> function [<a href="https://github.com/owainlewis/clojure-mail/blob/c3aad67b42aad96405d4c329ca48e29b7960d412/src/clojure_mail/message.clj#L16-L20">src</a>] works, we see that it is using the <code>.getRecipients</code> method. <code>.getRecipients</code> takes the message and a constant of a <code>RecipientType</code>. For our purposes, we want the <code>javax.mail.Message$RecipientType/CC</code> and <code>javax.mail.Message$RecipientType/BCC</code> recipients:</p>

<script src="https://gist.github.com/mathias/9876632.js"></script>


<p>The last line maps the <code>str</code> function across each element returned, so that we get the string representation of the email addresses. That way, our database can just store the strings.</p>

<p>As before, now that we know how to use these methods in the REPL, we write functions in <code>core.clj</code> to take advantage of our newfound knowledge:</p>

<script src="https://gist.github.com/mathias/9876737.js"></script>


<p>In the REPL, it should now be possible to get a nice map representation of all the fields on the message we care about:</p>

<script src="https://gist.github.com/mathias/9876884.js"></script>


<p>Congrats on making it this far. We&#8217;ve used quite a few neat little features of Clojure and the libraries we&#8217;re building this project with to get here.</p>

<p>The last step we&#8217;ll go through in this post is to get these messages into a database.</p>

<h2>Enter Datomic, the immutable datastore</h2>

<p><a href="http://www.datomic.com/">Datomic</a> is a great database layer built on Clojure that gives us a database value representing immutable data. New transactions on the database create new database values. It fits very well with Clojure&#8217;s own concept of <a href="http://clojure.org/state">state and identity</a> because it was designed by the same folks as Clojure. Plus, Datomic is meant to grow and scale in modern environments like AWS, with many backend datastore options to run it on.</p>

<p>There&#8217;s some important reasons why you might choose Datomic as your database for a data science / machine learning application:</p>

<ul>
<li>There are various storage backends, so you can grow from tens of thousands of rows in PostgreSQL on a developer&#8217;s laptop to millions of records (or more) in Riak or DynamoDB on AWS. That is, it has a good migration path from small datasets to big data through the Datomic import/export process</li>
<li>The concept of time associated with each value in Datomic means that we can query for historical data to compare against</li>
<li>Datomic has a lightweight schema compared to a relational database like PostgreSQL. Schemas are just data! When we begin computing new values from our dataset, we can add new types of entities easily at the same time.</li>
<li>Datomic&#8217;s schemas allow us to treat it as a key-value store, relational database, or even build a graph store on top of it, if we need to</li>
</ul>


<p><strong>Note</strong>: I won&#8217;t go through setting up an entire Datomic installation here. It&#8217;s worth reading up on the <a href="http://docs.datomic.com/">docs</a> and the <a href="http://www.datomic.com/rationale.html">rationale</a> behind Datomic&#8217;s design.</p>

<p>You can get the <a href="https://my.datomic.com/downloads/free">Datomic free build</a> if you like, but you will be limited to in-memory stores. It is unlikely that your Gmail inbox will fit into memory on your dev machine. Instead, I recommend signing up for the free <a href="http://www.datomic.com/get-datomic.html">Datomic Pro Starter Edition</a>. (The free Starter Edition is fine because you will not be using this project in a commercial capacity.) Once you have Datomic Pro downloaded and installed in your local Maven, I recommend using the PostgreSQL storage adapter locally with memcached. Follow the guides for configuring storage on the <a href="http://docs.datomic.com/storage.html">Datomic Storage</a> page.</p>

<p>Add the correct line to your <code>project.clj</code> dependencies for the version of Datomic you&#8217;ll be using (mine was <code>[com.datomic/datomic-pro "0.9.4384"]</code> which might be a bit out of date and likely won&#8217;t match yours.) Now we can start using Datomic in our <code>core.clj</code> and our REPL.</p>

<p>The first thing we need is the URI where the Datomic database lives. When we start up the Datomic transactor, you will see a DB URI that looks something like <code>datomic:sql://DBNAMEHERE?jdbc:postgresql://localhost:5432/datomic?user=datomic&amp;password=datomic</code> in the output. Grab that URI and add it to our <code>resources/config/autodjinn-config.edn</code>:</p>

<script src="https://gist.github.com/mathias/9877346.js"></script>


<p>Back at the top of <code>core.clj</code>, save that value to a var as we did with <code>gmail-username</code> and <code>gmail-password</code>:</p>

<script src="https://gist.github.com/mathias/9877374.js"></script>


<p>And then in the REPL:</p>

<script src="https://gist.github.com/mathias/9879199.js"></script>


<p>Note that according to the <a href="http://docs.datomic.com/clojure/index.html#datomic.api/create-database">datomic clojure docs for the create-database function</a>, it returns true if the database was created, and false if it already exists. So running <code>create-database</code> every time we run our script is safe, since it won&#8217;t destroy data.</p>

<p>If the above work in the REPL doesn&#8217;t work, it is likely your code is unable to talk to your running Datomic, or your Datomic transactor is not configured correctly. Diagnose it with Googling and reading the docs until you get it to work, then move on.</p>

<p>Calling <code>(d/db db-connection)</code> gives us the current value of our database. In most cases, we want to just get the most current value. So, we can write a convenience function <code>new-db-val</code> to always get us the current (and possibly different) database value. But there are cases where we want to coordinate several queries and use the same database values for each. In those cases, we won&#8217;t use the function get the latest database value, but rather pass this database value to the queries so that all query against the same state.</p>

<p>In our <code>core.clj</code>, we can add the code we need to create the database, get our connection, and the convenience <code>new-db-val</code> function:</p>

<script src="https://gist.github.com/mathias/9879246.js"></script>


<p>Next, we need to tell Datomic about the schema of our data. Schemas are just data that you run as a transaction on the database. Reading up on the <a href="http://docs.datomic.com/schema.html">Schema</a> page of the Datomic docs might be helpful to understand what&#8217;s going on here. The short version is that we define each attribute of an email and set up its properties. The collection of all attributes together will constitute a <code>mail</code> entity, so we namespace all the attributes under the <code>:mail/</code> namespace.</p>

<script src="https://gist.github.com/mathias/9879323.js"></script>


<p>We add that var def to our <code>core.clj</code> because it is, after all, just data. We may choose later to move it to its own <code>edn</code> file, but for now, it can live in our source code. Next, we want to apply this schema to our database with a transaction. That looks like this:</p>

<script src="https://gist.github.com/mathias/9879355.js"></script>


<p>Now we put that transaction in a convenience function in <code>core.clj</code> that we&#8217;ll run every time we run this file. The function will ensure that our database is &#8216;converged&#8217; to this schema. Running a transaction will create a new database value. But it will not blow away any data that we had in the database by running this transaction many times. It will simply try to update the existing attributes, and nothing in the attributes themselves need change. It is far more work to retract (delete) data in Datomic than it is to add or update it. This leads to much more safety around working with data without worrying that we will destroy data, and it encourages a REPL-based exploration of the data and its history.</p>

<script src="https://gist.github.com/mathias/9879424.js"></script>


<p>Now that our <code>mail</code> entities are defined in Datomic, we can try a query to find all the entity-IDs where any <code>:mail/uid</code> value is present. Read up on the <a href="http://docs.datomic.com/query.html">Query</a> page of the Datomic docs to dig into querying deeper. You might also be interested in the excellent <a href="http://www.learndatalogtoday.org/">Learn Datalog Today</a> website to learn more about querying Datomic with Datalog.</p>

<script src="https://gist.github.com/mathias/9879491.js"></script>


<p>Since we have no <code>mail</code> entities in our database, Datomic returns an empty set. So now we reach the end of task: We can ingest some emails and save them in our database! Return to the <code>ingest-inbox</code> function that we left before. Here&#8217;s what the updated version will look like:</p>

<script src="https://gist.github.com/mathias/9879494.js"></script>


<p>We use the <code>@</code>-sign before the <code>(d/transact…)</code> call because Datomic normally returns a promise of the completed transaction. However, we want to force Datomic to complete each transaction before moving on by deref-ing it with the <code>@</code>-sign. Per the Clojure docs: &#8220;Calls to deref/@ prior to delivery will block.&#8221;</p>

<p>If you run this function in your REPL, you should see it start to ingest your email from Gmail!</p>

<script src="https://gist.github.com/mathias/9879552.js"></script>


<p>Note that this could a take a <strong>long time</strong> if you&#8217;ve chosen to import a really large Gmail inbox! You might want to stop the import at some point; in most REPLs <code>Ctrl-c</code> will stop the running function.</p>

<p>If we query for our entity-IDs again, as above, we should see some values returned!</p>

<p>What does one of those database entities look like when we run it through Datomic&#8217;s <a href="http://docs.datomic.com/clojure/index.html#datomic.api/entity">entity</a> and <a href="http://docs.datomic.com/clojure/index.html#datomic.api/touch">touch</a> functions to instantiate all its attributes?</p>

<script src="https://gist.github.com/mathias/9879636.js"></script>


<h2>Wrapping up</h2>

<p>That&#8217;s it for this blog post. It took a little setup, but we were able to build up a working Gmail import tool with help from our REPL and some nice Clojure libraries.</p>

<p>Next time, we&#8217;ll be looking at doing some basic querying of the data, including getting a count of the number of times each email address has sent you an email.</p>

<p>Comments? Questions? Feel free to contact me at <a href="mailto:contact@mattgauger.com">contact@mattgauger.com</a>. I&#8217;d love to hear from you.</p>

<hr />

<p><a name="cds-gmail-footnote-1"></a>
<strong>1</strong> In this case, machine learning <em>features</em>, which are the input variables for our learning tasks. Not software features that we a client might ask us to implement. See: <a href="https://en.wikipedia.org/wiki/Feature_learning">Feature learning - Wikipedia, the free encyclopedia</a>.
<a href="#cds-gmail-footnote-1-return">↩</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A quick dashboard in Hoplon &amp; Castra]]></title>
    <link href="http://blog.mattgauger.com/blog/2014/03/20/a-quick-dashboard-in-hoplon-and-castra/"/>
    <updated>2014-03-20T13:29:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2014/03/20/a-quick-dashboard-in-hoplon-and-castra</id>
    <content type="html"><![CDATA[<p><em>Note:</em> I began writing a much longer blog post that went into a ton of detail about how to build an app dashboard that used Hoplon and Castra. The kind of dashboard that just consumes JSON API endpoints from another app or other data sources. Such dashboards update on the fly in the browser. Many apps these days need a dashboard like this to monitor stats: worker job queues, database size, average response times, etc.</p>

<p>Rather than that long blog post, I wanted to simply show the steps I would take to build such a dashboard with <a href="http://hoplon.io">Hoplon</a> and <a href="https://github.com/tailrecursion/castra">Castra</a>. I won&#8217;t go into detail here or explain either Hoplon or Castra &mdash; go read on your own first, and also look into <a href="https://github.com/tailrecusion/boot">boot</a>, the build tool this uses.</p>

<p>If you want to follow along, I&#8217;ve provided a <a href="https://github.com/mathias/gleam">repo</a>. The <a href="https://github.com/mathias/gleam/blob/30b4976b313c950c6cc97e64c65036eb21d75378/README.md">README</a> has instructions for getting setup. Assuming you have boot installed, you can just run <code>boot gleam-app</code> to get started.</p>

<p>So here&#8217;s how I&#8217;d build up a dashboard, in several iterations:</p>

<h2>Static data in the browser:</h2>

<p>First, we get some data into the HTML using Hoplon cells:</p>

<script src="https://gist.github.com/mathias/9670739.js"></script>


<p>You&#8217;ll want to <code>git reset --hard 69b070</code> to get to this point.</p>

<h2>Move the data to ClojureScript:</h2>

<p>In <code>src/cljs/gleam/rpc.cljs</code>:</p>

<script src="https://gist.github.com/mathias/9635157.js"></script>


<p>And take out the <code>(def articles…)</code> from <code>index.html.hl</code>. After boot recompiles everything, you should still see the data in the page.</p>

<p>To get to this point, you can run <code>git reset --hard d63f299</code>.</p>

<h2>Move the data to the server side</h2>

<p>Change <code>src/cljs/gleam/rpc.cljs</code> again, this time to make a remote call for data:</p>

<script src="https://gist.github.com/mathias/9671172.js"></script>


<p>On the backend, we need something like this in <code>src/castra/gleam/api/gleam.clj</code>:</p>

<script src="https://gist.github.com/mathias/9671200.js"></script>


<p>The Hoplon HTML file changes in the script tag at the top to use the new ClojureScript remote call and start up the polling:</p>

<script src="https://gist.github.com/mathias/9671220.js"></script>


<p>To get to this point in the example repo, you can do <code>git reset --hard 0bad1e5</code>.</p>

<h2>Real time data</h2>

<p>The last step that I will show is to verify that we are in fact getting regular updates of data from the back end.</p>

<p>Change your Castra Clojure file to look like this:</p>

<script src="https://gist.github.com/mathias/9671661.js"></script>


<p>To get to this point, you can do a <code>git reset --hard f19325</code></p>

<h2>Talking to a remote service.</h2>

<p>The last step here is left as an exercise for the reader. You can imagine replacing the <code>articles</code> function in <code>src/castra/gleam/api/gleam.clj</code> with something that polls a remote JSON API for data. Or you could look at my social news app <a href="http://github.com/mathias/gnar">gnar</a> for inspiration on using a Postgres database for data.</p>

<p>I hope to finish up a post with full explanations soon. Castra is relatively new, and it&#8217;s worth explaining how some of the pieces fit together. My explanation should include more complicated interaction. like user authentication. I will be publishing that blog post after I get back from <a href="http://clojurewest.org">ClojureWest</a> next week!</p>

<p>Let me know what you thought of this post by shooting me an <a href="mailto:contact@mattgauger.com">email</a>. I&#8217;d love to hear from you.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Agile Data Science: Review and Thoughts]]></title>
    <link href="http://blog.mattgauger.com/blog/2014/03/14/agile-data-science-review-and-thoughts/"/>
    <updated>2014-03-14T19:53:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2014/03/14/agile-data-science-review-and-thoughts</id>
    <content type="html"><![CDATA[<p><a href="http://shop.oreilly.com/product/0636920025054.do">
  <img src="http://blog.mattgauger.com//blog.mattgauger.com/images/agile_data_science_cover.gif" alt="Agile Data Science cover" style="display: block; float:right; margin: 10px;">
</a></p>

<p>Recently, I read the book <a href="http://shop.oreilly.com/product/0636920025054.do">Agile Data Science</a> by Russell Jurney. The book covers data science and how the author applies an agile workflow and powerful tooling to accomplish tasks. While I found the book interesting, and would recommend it as a good introduction, I have some issues with the book that I&#8217;d like to discuss. I&#8217;d like to go over the book and the tools briefly, if only to save my thoughts for later.</p>

<p>A quick note: data science is actively being defined by the web community as the process of analyzing large data sets with statistics and other approaches. That definition is ongoing and changing all the time. Big Data is the term that the industry seems to be using for such large datasets. You&#8217;ll also see the terms machine learning, analytics, and recommender systems mentioned: these are all various sub-topics that I won&#8217;t cover in depth here.</p>

<p>The book centers around the use of <a href="http://hadoop.apache.org/">Hadoop</a>. In turn, Hadoop is commanded by writing and running <a href="https://pig.apache.org/">Apache Pig</a> scripts in the book. Pig allows you to write workflows in a high-level scripting language that may compose many Hadoop jobs into one system. With Pig, you need not worry about the specifics of what each Hadoop job is doing when you write a Pig script.</p>

<p>Hadoop is patterned after Google&#8217;s <a href="http://static.googleusercontent.com/media/research.google.com/en/us/archive/mapreduce-osdi04.pdf">MapReduce paper</a>. Google had large clusters of computers and large data sets that it wanted to process on those clusters. What they came up with was a simple idea: Write a single program that would specify a <code>map</code> function to run across tuples of all the input data. Add a <code>reduce</code> function that compiles that output down into the expected format. MapReduce coordinates deploying the program to each worker machine, divvying up the input data across the different machines, gathering up the results, and handling things like restarts after failures. This was a huge success inside Google, and Hadoop implements that architecture with improvements.</p>

<p>It should be noted that this MapReduce architecture is essentially batch-processing for large amounts of data. The same system would have a hard time with continuous streams of data.</p>

<p>Hadoop is, unfortunately, my first stumbling block with learning to process big data.</p>

<p>Configuring and running Hadoop is not easy. I have far more experience as a developer than a sysadmin (or today&#8217;s term: devops engineer). There exists more than one &#8220;distribution&#8221; of Hadoop and more than one versioning scheme between those. This means that understanding what&#8217;s available, how to configure it, and whether search results are relevant to you is quite hard for the unexperienced.  Imagine the confusion of trying to install a Debian Linux distro and only being able to find instructions for Red Hat Linux; further, not being able to tell what the problem was when it wouldn’t boot and printed a Debian-specific error.</p>

<p>It seems like Hadoop is designed for to be run by someone whose full-time job is to configure and maintain that cluster. That person will need to have enough experience with all the different choices to have an opinion on them. For a developer wanting to run things locally before committing to configuring (and paying for!) a full cluster out on AWS, it was daunting.</p>

<p>Luckily for me, <a href="https://github.com/charlesflynn">Charles Flynn</a> has created a neat repo on Github at <a href="https://github.com/charlesflynn/agiledata">charlesflynn/agiledata</a>. It builds a local development VM for the Agile Data Science book, with all the dependencies installed and the book&#8217;s code in the right place to run. With that project, I was able to get up and running with the project quickly and found it useful to not have to sink anymore time into configuring Hadoop. I&#8217;d like to give another shout-out to Charles for this great resource and the work done to make sure it works.</p>

<p>The book has the reader work with email data: your Gmail inbox pulled locally for analyzing. I thought this was neat, in itself. Many data science tools use free datasets; as a result working with those datasets may not be the most interesting problem space to you. But insights about your own communication and how others communicate with you is something you might find more interesting.</p>

<p>After explaining Hadoop, Pig, and a few other tools, the rest of the book follows a fairly lightweight &#8220;recipe&#8221; format. Each chapter explains the goal and how it fits in an &#8220;agile data science&#8221; workflow. Then, some code is presented, and then we see what kinds of results we can take from that step. Once this pattern is set up, the book moves fairly quickly through some rather interesting data wrangling. By the end, the reader has built several data analysis scripts and a simple web app put together with MongoDB, Python Flask, and D3.js graphs to display all the results.</p>

<p>At times, though, the quick recipe format seemed to explain too little. There was little explanation of how Pig script syntax worked or how to understand what was going on under the covers. What this book is not: an exhaustive guide to how to write Pig scripts, how to pick approaches to analyzing a dataset, or how to compose these systems in production in the wild.  Also missing were any mention of performance tuning or what other algorithms might be considered.</p>

<p>Which seems like an awful lot to be missing, but for this book that would have been diversions that bogged the book down.</p>

<p>To the author&#8217;s benefit, I finished the book, and finished it far faster than I expected I would. I cam away having done almost all of the book&#8217;s examples (helped a great deal by the excellent virtual machine repo from Charles Flynn mentioned above). And, I had a deeper understanding and respect for tools that I&#8217;d never used before.</p>

<h2>Final thoughts</h2>

<p>When it comes down to it, I wouldn&#8217;t recommend Agile Data Science to read on its own. I&#8217;d recommend that you used it as a quick introductory book to build familiarity and confidence, so that you could dive into a deeper resource afterwards. I&#8217;d also recommend it if you&#8217;re a developer who isn&#8217;t going to be doing data science as your full time job but are curious about the tools and practices, this book would be a good read.</p>

<h2>What I&#8217;m doing next</h2>

<p>Almost immediately after finishing this book, I attended an event at a nearby college to talk about <a href="http://storm.incubator.apache.org/">Apache Storm</a>. Our company blog <a href="http://bendyworks.com/geekville/articles/2014/2/uw-big-data-event-presents-storm">covered the event</a> if you&#8217;re curious.</p>

<p>Storm is a tool that came out of Twitter for processing streams of big data. If you think about it, Twitter has one of the biggest streaming data sets ever. They need to use that streaming data for everything from recommendations to analytics to top tweet/hashtag rankings.</p>

<p>After attending the event and having run a word-counting topology (Storm&#8217;s term for a workflow that may contain many data-processing jobs) out on a cluster, I began to see the potential of using Storm.</p>

<p>Plus, Storm is far friendlier to local development on a laptop. One can run it with a simple command line tool or even from inside your Java or Clojure code. Or, perhaps most simply, from inside the Clojure REPL.</p>

<p>The other plus here is that Storm is mostly written in Clojure and has a full Clojure API. Combined with a few other Clojure tools that I prefer, like <a href="http://www.datomic.com/">Datomic</a>, <a href="https://github.com/ring-clojure/ring">Ring</a>, and <a href="http://keminglabs.com/c2/">C2</a>, I can see a toolset similar to that used in Agile Data Science. This toolset has the benefit of using the same language for everything. And, Clojure is already well-suited for data manipulation and processing.</p>

<p>So I began to rewrite the examples in Agile Data Science in Clojure. I am hoping to make enough progress to begin posting some of the code with explanations in blog format. Stay tuned for that.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A theory of compound intelligence gain]]></title>
    <link href="http://blog.mattgauger.com/blog/2014/01/12/a-theory-of-compound-intelligence-gain/"/>
    <updated>2014-01-12T14:02:00-06:00</updated>
    <id>http://blog.mattgauger.com/blog/2014/01/12/a-theory-of-compound-intelligence-gain</id>
    <content type="html"><![CDATA[<p>Note that this is probably not enough to call a theory. It&#8217;s an idea, at most.</p>

<p>I&#8217;m currently reading the book <a href="http://www.amazon.com/gp/product/0984725113">Race Against the Machine</a>, which describes how increasing levels of automation by technology are related to capital and labor. But this post isn&#8217;t about that book. It simply triggered me to think about my motivations for my current side projects, and how I might explain to others why exactly I think that my current side projects are so important.</p>

<p>While <em>Race Against the Machine</em> describes technological progress as a force that leaves behind skilled workers who no longer have relevant skills, my thinking is on intelligence augmentation, and how I can use my own knowledge and programming skills to build tools that increase my own effectiveness and ability to perform my job. Namely, how can I write software that improves my cognition and memory such that I am better at writing software, and gain other benefits from having increased cognition and memory?</p>

<p>Douglas Engelbart <a href="http://www.dougengelbart.org/pubs/augment-3906.html">wrote extensively</a> about augmenting intelligence, primarily with improving workflows and then with computer software. I&#8217;ve previously <a href="http://blog.mattgauger.com/blog/2013/03/17/by-augmenting-human-intellect/">quoted him</a> on this blog. I feel that part of that quote bears repeating here:</p>

<blockquote>
By &#8220;augmenting human intellect&#8221; we mean increasing the capability of a man to approach a complex problem situation, to gain comprehension to suit his particular needs, and to derive solutions to problems.
<footer>
<strong>Douglas C. Engelbart</strong>
&ndash;
<cite><a href="http://www.dougengelbart.org/pubs/augment-3906.html">Augmenting Human Intellect: A Conceptual Framework </a></cite>
</blockquote>


<p>Of course, Engelbart was writing about this in 1962 &#8211; well before every home had a personal computer and everyone had a powerful supercomputer in their pocket. For a modern overview of Engelbart&#8217;s framework, see <a href="http://fluid.media.mit.edu/sites/default/files/The%20Design%20of%20Artifacts%20for%20Augmenting%20Intellect.pdf">The Design of Artifacts for Augmenting Intellect</a>.</p>

<p>My earliest encounters with concepts of intelligence augmentation most likely come from science fiction. One character that has inspired a lot of my work (and that I&#8217;ve probably told you a lot about if we&#8217;ve discussed this project in person) is Manfred Macx from Charles Stross&#8217;s <a href="http://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html">Accelerando</a>. Macx is described in the early parts of the book as having a wearable computer that acts as his <em>exocortex</em>. The idea of an exocortex being that some part of his memory, thinking, and information processing lives outside of his head and on the wearable computer. Similarly, the exocortex can help act as a gate to his attention, which is one of our limited resources.</p>

<p>If you think about it, just as <a href="http://www.ted.com/talks/amber_case_we_are_all_cyborgs_now.html">we are all cyborgs now</a> by virtue of the technology we use every day, we are also all on our way to having exocortexes. Many of us use Gmail filters to protect our attention spans from email we receive but don&#8217;t always need to read. Or we use Google search to add on to our existing memory, perhaps to remember some long-forgotten fact that we only have an inkling of.</p>

<p>I&#8217;ve had Manfred Macx&#8217;s exocortex (and other flavors of science fiction&#8217;s wearable computers and augmented intelligences) kicking around in my head for years. Gmail tells me that I was trying to plan the architecture for such a thing as far back as 2006. It&#8217;s taken a lot of thinking and further learning in my career to even get to the point where I felt ready to tackle such a project.</p>

<p>What I am setting out to build is an exocortex of my own design, under my own control. Not something that is handed to me by Google in bits and pieces. And to do so, it turns out, requires a lot of research and learning. There&#8217;s tons of research on the topics of proactive autonomous agents, text classification, and wearable computing that I have been reading up on. Just to build the first phase of my project, I have been learning all of the following:</p>

<ul>
<li><a href="https://github.com/clojure/core.logic">core.logic</a> (which is based on Prolog, so I&#8217;m learning some Prolog now, too)</li>
<li><a href="https://github.com/clojure/core.async">core.async</a> (Clojure&#8217;s implementation of C.A.R. Hoare&#8217;s <a href="http://www.amazon.com/Communicating-Sequential-Processes-International-Computing/dp/0131532715/">Communicating Sequential Processes</a>, which is also how Go&#8217;s goroutines work)</li>
<li><a href="http://cascalog.org/">Cascalog</a> and <a href="http://hadoop.apache.org/">Hadoop</a>, to do my distributed computing tasks</li>
<li><a href="http://www.datomic.com/">Datomic</a> &amp; Datalog (a subset of Prolog for querying Datomic), to store knowledge in a historical fashion that makes sense for a persistent, lifelong knowledge system</li>
<li>Topic clustering, text classification, and other natural language processing approaches</li>
<li>Data mining, and in particular, streaming data mining of large datasets on Hadoop clusters, by reading the Stanford textbook <a href="http://infolab.stanford.edu/~ullman/mmds.html">Mining of Massive Datasets</a></li>
<li>Generally learning Clojure and ClojureScript better</li>
<li>and probably more that I am forgetting to mention</li>
</ul>


<p>Of course, if I look at that list, I can be fairly certain that this project is already paying off. These are all things that I had very little experience with before, and very little reason to dig into so deeply. Not represented here are the 40 or so academic papers that I identified as important, and seriously set out to read and take notes on &#8211; again, probably learning more deeply these topics than I otherwise would have.</p>

<p>Which brings me to this theory, the idea of this post: That by even beginning to work on this problem, I&#8217;m seeing some gains, and that any tools I can build that give me further gains will only compound the impact and effectiveness. <strong>Improving cognition and learning compounds to allow further gains in cognition and learning.</strong></p>

<p>There&#8217;s some idea in the artificial intelligence community that we don&#8217;t need the first general artificial intelligence to be built as a super-intelligence; we need only build an artificial intelligence that is capable of improving itself (or a new generation of artificial intelligence.) As each generation improves, such intelligences could become unfathomably intelligent. But all it takes is that first seed AI that can improve the next.</p>

<p>So for improving our own human intelligences, we may not need to build a single device up-front that makes us massively intelligent. We only need take measures to improve our current knowledge and cognition, to build tools that will help us improve further, and continue down this path. It will definitely not be the exponential gains predicted for AI, and may not be even linear &#8211; that is, the gains in cognition from building further tools and learning more may plateau. But there will be improvements.</p>

<p>For that reason, I&#8217;m not setting out to build Manfred Macx&#8217;s exocortex from the beginning. Instead, I have been building what I describe as a &#8220;Instapaper clone for doing research&#8221; &#8211; a tool that, if it improves my existing ability to research and learn new topics, could pay off in helping me to build the next phase of my projects.</p>

<p>Of course, at the same time, I have an eye towards using the foundation of this tool as the datastore and relevance-finding tool for the overall project. Such a tool can automatically go and find related content &#8211; either things I have read, or simply crawl related content on the web. Eventually, this tool will also ingest all of the information I interact with on a daily basis: every website I browse, every email I receive, every book that I read. A searchable, tagged, annotatable reference with full metadata for each document as an external long-term memory. But this is all a topic for another post.</p>

<p>This, in concert with what current research tells us is effective: <a href="http://www.salon.com/2013/12/29/sciences_obsession_the_search_for_a_smart_pill/">improved nutrition and supplementation, exercise, meditation, and N-back training</a>, may just be my ticket to higher levels of human intelligence. But for now, I just want the early-adopter edge. I want to see how far I can push myself on my own skills. Some large corporation may be able to field hundreds of developers to create a consumer product for the public that benefits everyone in similar ways &#8211; but I might be able to do this for myself years ahead of that. And wouldn&#8217;t that be cool?</p>

<p>And this is where I call it a theory: it could very well be that there&#8217;s no such thing as compounding interest on intelligence. Only time and my own experiences with this project will tell me.</p>

<p>If you&#8217;ve made it this far and you&#8217;re interested in this kind of stuff, that is: intelligence augmentation, wearable computing, autonomous proactive agents, etc., <a href="https://twitter.com/mathiasx">get in touch</a>. There doesn&#8217;t seem to be much of an online community around these topics, and I&#8217;d like to start creating one for discussion and organizing open source projects around these topics.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An (unscientific) study in behavior change with software]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/12/28/an-unscientific-study-in-behavior-change-with-software/"/>
    <updated>2013-12-28T08:54:00-06:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/12/28/an-unscientific-study-in-behavior-change-with-software</id>
    <content type="html"><![CDATA[<p>Forming habits is hard. There&#8217;s been tons of research on what practices help form new habits successfully. And there has been research on what software can do to help form new habits. It&#8217;s not enough to simply send daily reminders or keep track of the goals in a visible place. For software to help us form new habits successfully, we must look to the current research for clues as to how habits are formed.</p>

<p>Over the past year or so, I&#8217;ve been trying to adopt a habit to take Vitamin D every morning. I&#8217;ve been largely successful, which I think is partly due to the software I used. I use <a href="http://lift.do">Lift</a> on my iPhone, which sends me emails every morning as a reminder. The app itself has checkins for each habit, progress charts, and social features. Most mornings, I wake up, swipe away the reminder email, and take my morning antihistamine and a Vitamin D. <a href="#behavior-footnote-1" name="behavior-footnote-1-return">[1]</a> Like I said, I&#8217;ve been mostly successful, and at this point, I&#8217;ve taken Vitamin D every day in a row for 442 days in a row. <a href="#behavior-footnote-2" name="behavior-footnote-2-return">[2]</a>  Granted, taking a vitamin every morning is only a small change, but it is one that I wanted to accomplish and did. Small successes add up to bigger successes, and this gives me confidence that if I set out to make a bigger change in my life, I have a toolset that will help me to accomplish that goal.</p>

<p>So what does the research say helps us form successful habits? The Fogg Method <a href="#behavior-footnote-3" name="behavior-footnote-3-return">[3]</a> is one of the more well-known systems, and suggests that a way to be successful is to:</p>

<ol>
<li>Select the right target behavior.</li>
<li>Make the target behavior easy to do.</li>
<li>Ensure a trigger will prompt the behavior.</li>
</ol>


<p>So what do each of these steps tell us?</p>

<h2>The Right Target Behavior</h2>

<p>It&#8217;s hard to be successful in picking up a habit that you don&#8217;t already want to accomplish. Some things you may already want to do include things like learning a language, eating a specific diet, or flossing your teeth. It goes without saying that things you&#8217;d rather not do are going to be harder to implement.</p>

<p>But there&#8217;s another factor in play here that I think determines the <strong>right</strong> target behavior: simplicity. That is, is the habit a simple task to accomplish, or is it something complex and unmanageable? Can you perform one simple task per day and call it &#8220;done&#8221;, or is it more complicated as to whether it is &#8220;done&#8221; or not each day? The simple &#8220;done&#8221; state seems really important, and so it is good to focus on using this technique for binary actions: either you did them today, or you didn&#8217;t. Things that must be done with complicated schedules, every other day, or once a week, will be much harder to establish as habits.</p>

<h2>Easy to do</h2>

<p>One reason we want a simple target behavior is so that it is easy for us to add to our schedule. You may have a goal of exercising more. But &#8220;exercising more&#8221; doesn&#8217;t have a binary action associated with it; for example: what is &#8220;more&#8221;? Instead, you might say, &#8220;I want to exercise 45 minutes per day.&#8221; And that would be a much better goal. But if exercising means you have to drive to the gym, and the gym is out of your way each day, it might be very unlikely that you will do it. This is not a simple target behavior.</p>

<p>If you do have some goal that may not be simple to implement at first &mdash; say, the example of having to drive out of your way to the gym &mdash; instead try to find a simpler version of the habit that you can adopt first. You may decide instead to just do some bodyweight exercises before you leave for work each morning. Decide on the exercises and write them down. Either you did them or you didn&#8217;t. Later on, you can modify this existing habit to be more exercise, but for now, focus on what you can reasonably adopt as a simple habit.</p>

<p>The other concern in implementing an &#8220;easy&#8221; habit is how much time the new habit will take. In the above example, the initial goal was something like 45 minutes per day. Eventually, you could probably find when you exercise best and are least likely to schedule appointments (say, early morning or late at night), and actually implement that goal. But early on, it&#8217;s going to be hard to change your schedule for your new habit. I ran into this frequently while trying to find time after 5PM but before dinner to practice guitar. It didn&#8217;t help that after-work and dinnertime are frequently scheduled as social events, and that I have a habit of staying at the office past 5; all these added up to very little success in trying to spend 45 minutes to an hour practicing guitar at home after work.</p>

<h2>Triggers</h2>

<p>The last step is quite important. Where you might think of triggers as things like alerts on your phone or daily emails from a service like <a href="http://lift.do">Lift</a>, I didn&#8217;t find those kinds of prompts very effective in helping me adopt a habit.</p>

<p>To be more likely to perform some task on any given day, look at the habits you already have. I&#8217;ve been taking an antihistamine every morning since I was about 12; this has been a constant in my life and part of my routine for a very long time. Since I already have this daily habit, I added taking Vitamin D every morning to that habit. Other habits with no daily routine to hinge off of, like practicing guitar, were much harder to make stick.</p>

<p>Flossing is an easy addition to brushing your teeth every night, and just took enough of me making it simpler (finding a brand of flossers I liked rather than wrangling loose floss) and doing it enough times before it stuck, too.</p>

<h2>What didn&#8217;t work for me?</h2>

<p>As noted above, despite a couple attempts to really make daily guitar practice stick, I&#8217;ve never been able to tackle that habit. There were no good triggers that I could add the event on to, and I frequently didn&#8217;t have time for what I was trying to accomplish. If I were to go back to trying to focus on guitar, I&#8217;d probably start with much less time commitment, and schedule it some time when I&#8217;m very likely to be home and have 5-10 minutes, like early in the morning before work. Whether or not guitar practice is effective with my first cup of coffee would have to be tested, of course.</p>

<p>What I&#8217;ve found is that I&#8217;m partially motivated by progress bars and graphs, though, and so I will make time in my day for easy-to-accomplish things. So when I can, I will try to squeeze in some mundane activity I&#8217;m tracking in Lift, like washing the dishes. <a href="#behavior-footnote-4" name="behavior-footnote-4-return">[4]</a></p>

<p>The social component of Lift, on the other hand, doesn&#8217;t really help me any. For others, it might be a good motivator. In cycling, I have several local friends, including one local cyclist who is quite prolific and who frequently rides 10x as much as I do in a given week. We all use <a href="http://www.strava.com/">Strava</a> to track our cycling, and the social component alerts me to new rides that the prolific cyclist has done. Seeing that cyclist&#8217;s rides helps remind me to get out and enjoy more cycling, as well as sets up a nice carrot-on-a-stick for me to ride more to &#8220;catch up.&#8221; In that case, the social features definitely help me to perform an action more, but I wouldn&#8217;t really call cycling a habit as much as my transportation and leisure-time hobby that I can do whenever I have time.</p>

<p>Habits with no simple binary action and no triggers, such as creative acts, are especially hard to form as habits. I have tracked writing blog posts in Lift for some time, but since I only write blog posts when the mood strikes me, it is hardly a daily goal, and it would be difficult for me to implement the above steps to form an actual habit of blogging on a daily basis.</p>

<h2>Final thoughts</h2>

<p>Notice that most of the guidelines above have very little to do with software? Software itself can&#8217;t convince you to go to the gym or make you more likely to floss. But it can provide some prompts and some encouragement, and that might be enough to get you over the hurdle of adopting a new habit.</p>

<p>As with anything, you are an individual and your mileage may vary. Experiment, use an app like Lift or something else you prefer to track your progress, and see where it takes you.</p>

<p>There&#8217;s more resources out there to help understand forming new habits, self-control, and behavior change, but I feel like this is the baseline one needs to know to be more successful in implementing behavior change. Some references of note that I have been consuming:</p>

<ol>
<li><a href="http://shop.oreilly.com/product/0636920030201.do">Designing for Behavior Change</a>. Stephen Wendel. 2013.</li>
<li><a href="http://www.nytimes.com/2011/09/04/books/review/willpower-by-roy-f-baumeister-and-john-tierney-book-review.html?pagewanted=a0l&amp;_r=0">The Sugary Secret of Self-Control</a>. New York Times. September 2, 2011.</li>
<li><a href="http://pragprog.com/book/jkthp/the-healthy-programmer">The Healthy Programmer</a>. Joe Kutner. 2013.</li>
</ol>


<p>If you&#8217;re interested in some research, the above book (Designing for Behavior Change) is a good reference, as well as these papers:</p>

<ol>
<li><a href="http://dspace.mit.edu/handle/1721.1/79306">ReflectOns : mental prostheses for self-reflection</a> (hardware and software solutions)</li>
<li><a href="http://captology.stanford.edu/wp-content/uploads/2010/10/Fogg-and-Hreha-BehaviorWizard.pdf">Behavior Wizard: A Method for Matching Target Behaviors with Solutions</a></li>
</ol>


<hr />

<p><a name="behavior-footnote-1"></a></p>

<p><strong>1</strong> Yes, I&#8217;m aware of the fact that taking vitamins with an antihistamine decreases the effectiveness of the antihistamine. I&#8217;ll cover why I take them at the same time in this post. <a href="#behavior-footnote-1-return">&#8617;</a></p>

<p><a name="behavior-footnote-2"></a></p>

<p><strong>2</strong> You can view my progress on Lift <a href="https://lift.do/users/34b3bcceda0808f3c096">on my public profile</a>. Notice there&#8217;s quite a few habits I&#8217;ve tried to form with Lift in the past that didn&#8217;t quite work. <a href="#behavior-footnote-2-return">&#8617;</a></p>

<p><a name="behavior-footnote-3"></a></p>

<p><strong>3</strong> As described by BJ Fogg in the preface to <a href="http://shop.oreilly.com/product/0636920030201.do">Designing for Behavior Change</a>. <a href="#behavior-footnote-3-return">&#8617;</a></p>

<p><a name="behavior-footnote-4"></a></p>

<p><strong>4</strong> We don&#8217;t have a dishwasher in our current apartment, and I both dislike dirty dishes and dislike washing dishes by hand. <a href="#behavior-footnote-4-return">&#8617;</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[In the year 2100]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/12/16/in-the-year-2100/"/>
    <updated>2013-12-16T23:41:00-06:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/12/16/in-the-year-2100</id>
    <content type="html"><![CDATA[<p>Recently I was asked by a coworker to write up some ideas for where our company would be in the future. Not just next year, or in 5 years, but where we saw the company in the year 2100. For my other coworkers, the year 2100 probably represents far enough out to ensure they stop thinking in the constraints of right now. But for someone who has read as much science fiction as I have, I saw a wide gulf of time.</p>

<p>So I hit up Wolfram Alpha, asking myself what technology might look like in the year 2100.</p>

<p>If Moore&#8217;s Law holds, then processors could contain 3.5 x 10<sup>22</sup> transistors &mdash; roughly 350 times more transistors than the number of grains of sands on the planet. (Thanks, Wolfram Alpha!) This also represents roughly 2.9x10<sup>18</sup> MIPS per chip, which is roughly a factor of ten more processing power in each chip than all 7 billion brains of humans on the planet, combined. That kind of computing power is almost unimaginable to me now.</p>

<p>While I don&#8217;t have a religious belief in the Singularity, I <strong>do</strong> think that we can&#8217;t really predict what it&#8217;ll mean to have so much computing power available to us. Or what technology, society, or people will look like by then. Of course, someone&#8217;s gotta write the software to make that hardware useful…</p>

<hr />

<p><small>
Note: It could be that I messed up these numbers a bit; I went off the current transistor count and MIPS for the Intel i7-4770k processor, since I recently started putting together a server with one. And the numbers are extrapolated out quite a bit. If you&#8217;ve got corrections to these numbers, hit me up on <a href="https://twitter.com/mathiasx">Twitter</a> to let me know!
</small></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Indent and colorize HTML strings in pry]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/11/14/indent-and-colorize-html-strings-in-pry/"/>
    <updated>2013-11-14T11:32:00-06:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/11/14/indent-and-colorize-html-strings-in-pry</id>
    <content type="html"><![CDATA[<hr />

<p><em>(This post is part of my blog archiving project. This post appeared on <a href="https://coderwall.com/p/hlbana">Coderwall</a> on November 14, 2013.)</em></p>

<p><em>Note: I have converted the inline code to Gists for better readabililty.</em></p>

<hr />

<p>An issue I run into frequently while testing with tools like <a href="https://github.com/jnicklas/capybara">capybara</a> by dropping into <a href="http://pryrepl.org/">pry</a> is that the last response for a page is a single string, containing the HTML that was rendered. But those string have lost indentation and generally make it really hard to see the content of the page, or whatever you care about.</p>

<p>For example, a simple login page might look like:</p>

<script src="https://gist.github.com/mathias/2007dab63a9fe77d7182.js"></script>


<p>Wouldn&#8217;t it be great if Pry could re-indent and colorize that string of HTML for you? Well, I put together a quick little Pry command that does. Throw this into your <code>~/.pryrc</code>:</p>

<script src="https://gist.github.com/mathias/21a971d0bdb3620a8909.js"></script>


<p>Originally, I had tried to use the html5 fork of the <code>tidy</code> command: <a href="https://github.com/w3c/tidy-html5">https://github.com/w3c/tidy-html5</a> but that tool <em>changes</em> the HTML as it parses it, and spits out a bunch of warnings. So instead, I have this pry command use <code>nokogiri</code> when it is available. The command should warn you if you try to use it without <code>nokogiri</code> available. What is output should be very close to the original rendered HTML, just cleaned up and re-indented.</p>

<p>So what does it look like in action?</p>

<script src="https://gist.github.com/mathias/4065f861db4cd9e280ad.js"></script>


<p>(imagine that pry has colorized this output, too, through the excellent CodeRay tool.)</p>

<p>I&#8217;d love to hear from you if you find this useful! Or even if you don&#8217;t find it useful, but have some suggestions to improve it. Thanks!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apprentice Talk Video &amp; Notes]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/11/11/apprentice-talk-video-and-notes/"/>
    <updated>2013-11-11T19:22:00-06:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/11/11/apprentice-talk-video-and-notes</id>
    <content type="html"><![CDATA[<p>Back in September, I had a blast speaking at <a href="http://nickelcityruby.com/">Nickel City Ruby</a>. My talk was entitled &#8220;Apprenticeship: Software Craftsmanship&#8217;s Missing Link&#8221; and included a lot of slides of sasquatches. The video has been posted to Confreaks, so I&#8217;m embedding it here. Also note that I have posted my notes and a few resources over on the microsite I created for this talk, <a href="http://blog.mattgauger.com/apprenticeship/">http://blog.mattgauger.com/apprenticeship/</a></p>

<iframe width="640" height="360" src="http://blog.mattgauger.com//www.youtube.com/embed/zuL7rAwmwCY" frameborder="0" allowfullscreen></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[git fml]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/09/03/git-fml/"/>
    <updated>2013-09-03T11:32:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/09/03/git-fml</id>
    <content type="html"><![CDATA[<hr />

<p><em>(This post is part of my blog archiving project. This post appeared on <a href="https://coderwall.com/p/ypsd8w">Coderwall</a> on September 3, 2013.)</em></p>

<hr />

<p>For when you need to go back to a clean slate and declare FML, add this to your <code>~/.gitconfig</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[alias]
</span><span class='line'>  fml = !"git fetch && git reset --hard origin/master"</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A simple text editor foot pedal]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/08/06/a-simple-text-editor-foot-pedal/"/>
    <updated>2013-08-06T15:06:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/08/06/a-simple-text-editor-foot-pedal</id>
    <content type="html"><![CDATA[<p>When I first starting talking about <a href="http://blog.mattgauger.com/blog/2013/08/03/building-a-chording-keyboard-lessons-learned-and-progress-so-far/">building a chording keyboard</a>, both in person and online, people began to ask me about the possibility of building a computer foot pedal. With the Teensy microcontroller, a foot pedal would only need to watch a single digital input and output a few characters to the OS; much simpler than my chording keyboard project.</p>

<h2>Commercial products</h2>

<p>There are quite a few commercial products you can buy. They come with their own caveats:</p>

<ul>
<li><a href="http://www.kinesis-ergo.com/fs-savant-elite.htm">Kinesis</a> makes several, but they <a href="http://www.kinesis-ergo.com/fs-elite-single-compatibility.htm">can only be programmed on Windows</a>. They are also very expensive.</li>
<li>The <a href="http://www.xkeys.com/xkeys/xkfoot.php">Xkeys Foot Pedals</a> look good, but they are also expensive.</li>
<li>The DealExtreme <a href="http://dx.com/p/usb-triple-action-foot-switch-keyboard-control-foot-pedal-56508">Triple Action Foot Pedal</a> provides three buttons and is relatively cheap; however, the reviews I&#8217;ve read say the reliably is poor. This product can only be programmed on Windows.</li>
</ul>


<h2>Building the foot pedal</h2>

<p>My first idea for a foot pedal was to use DIY guitar pedal hardware. Such guitar pedals have nice, sturdy aluminum project boxes, robust foot switches, and look pretty good. But the ergonomics of such a pedal worried me: while a guitarist momentarily stomps on guitar pedals to turn them on or off while standing, a programmer would likely be tapping and/or holding a foot pedal for long periods of time, most likely from a seated position.</p>

<p><img src="http://blog.mattgauger.com/images/guitar_pedal_true_bypass_looper.JPG" alt="true bypass looper" style="display: block; margin: 0 auto;" /></p>

<p>Such a pedal would look something like the above, but with a USB cable coming out of it.  If you wish to use guitar pedal hardware, I suggest checking out <a href="http://www.mammothelectronics.com/">Mammoth Electronics</a>. (I receive no compensation for mentioning them; I have been a happy customer for several years.) For a two-to-three switch foot pedal, I suggest the 1590BB enclosures, and Mammoth can drill them in several ways for you.</p>

<p>My coworker <a href="http://sencjw.com/">Chris Wilson</a> suggested that I try a digital piano foot switch. These are relatively cheap and extremely sturdy. I picked up an <a href="http://www.amazon.com/M-Audio-Sustain-Pedal-Action-Keyboards/dp/B00063678K/">M-Audio Sustain Pedal</a> from Amazon for about $17.</p>

<p>The sustain pedal is designed to plug into a digital piano, so it has a 1/4&#8221; audio plug on its cable. In the past, I&#8217;ve built a lot of guitar effects pedals and some amps, and so I have a lot of 1/4&#8221; jacks around.</p>

<p>The wiring is simple: The Teensy (and most Arduinos) can do input pullup resistors for us. I mocked up the circuit with a little breadboard (ignore the weird angle of the Teensy here; it was required to get the pins into this small breadboard.) I downloaded some example button code to the Teensy and verified that it was working.</p>

<p><a href="http://www.flickr.com/photos/mattgauger/9454682228/" title="IMG_1897 by Matt Gauger, on Flickr"><img src="http://farm4.staticflickr.com/3725/9454682228_4bb073ea47_z.jpg" width="480" height="640" alt="IMG_1897" style="display: block; margin: 0 auto;" /></a></p>

<p>To assemble, we simply solder a digital IO pin to one side of the 1/4&#8221; jack, and the other wire gets soldered to ground pin. My button is going to be connected on pin 9.</p>

<p>I had a small project box, much bigger than the Teensy really needed, but suitable for the job. I used my Dremel to cut a round hole for the 1/4&#8221; jack, and a rectangular slightly bigger than the mini-USB cable plug for our USB cable.</p>

<p><a href="http://www.flickr.com/photos/mattgauger/9451903305/" title="IMG_1898 by Matt Gauger, on Flickr"><img src="http://farm4.staticflickr.com/3789/9451903305_4c6a3e0c35_z.jpg" width="480" height="640" alt="IMG_1898" style="display: block; margin: 0 auto;" /></a></p>

<p>Test fitting the Teensy in the project box:</p>

<p><a href="http://www.flickr.com/photos/mattgauger/9451906889/" title="IMG_1900 by Matt Gauger, on Flickr"><img src="http://farm4.staticflickr.com/3718/9451906889_8e5624fa7d_z.jpg" width="640" height="480" alt="IMG_1900" style="display: block; margin: 0 auto;" /></a></p>

<p>Lastly, I used some velcro inside to attach the Teensy to the project box. All done with assembly!</p>

<p><a href="http://www.flickr.com/photos/mattgauger/9451907469/" title="IMG_1902 by Matt Gauger, on Flickr"><img src="http://farm8.staticflickr.com/7451/9451907469_e6e6fc661f_z.jpg" width="480" height="640" alt="IMG_1902" style="display: block; margin: 0 auto;" /></a></p>

<p>The next step is to program the Teensy to send the key events we want. In this case, my coworker <a href="https://twitter.com/inyourdom">Josh</a> suggested a vim clutch that enters insert mode when you press down on the pedal, and leaves insert mode when you release it. Since the Teensy&#8217;s Button class detects both button press and button release events, we can write code to do that.</p>

<p>Here&#8217;s what the code looks like:</p>

<script src="https://gist.github.com/mathias/6168386.js"></script>


<p>(You can find the code in my chording keyboard repo on Github <a href="https://github.com/mathias/chording/blob/master/teensy/foot_pedal/foot_pedal.ino">here</a>.)</p>

<p>There are, of course, a few gotchas that I ran into:</p>

<p>The <code>KEY_ESC</code> constant that is referenced by the <a href="http://arduino.cc/en/Reference/KeyboardModifiers">Arduino documentation</a> didn&#8217;t work. Similarly, sending the hex value and character code didn&#8217;t work. I couldn&#8217;t find anything online that suggested that the Mac has some different ASCII character for the Escape key, so I had to find another way to leave insert mode.</p>

<p>With the Arduino&#8217;s Keyboard class, we can build up a key combo by calling <code>Keyboard.press</code> for each character in the combo, and then finally calling <code>Keyboard.releaseAll</code> when we&#8217;re ready to send the key combo to the computer. Since vim also has <code>Ctrl-[</code> as a way of leaving insert mode, I created that key combo on lines 34-36.</p>

<p>Of course, this code could be made to be even more robust by guarding against, say, inserting an <code>i</code> character when you are already in insert mode. Most likely, you&#8217;d send Ctrl-[ (and move building the key combo to a function we can reuse) and then send vim the command <code>:startinsert</code>.  I&#8217;ll leave implementing the more robust solution as an exercise for the reader.</p>

<h2>Final thoughts</h2>

<p>Does it work? I used it while writing this blog post, but I must admit, I have a strong natural reflex to hit ESC to leave insert as soon as I finish typing a word or sentence. However, when consciously trying, it is quite natural to use the foot pedal to enter/leave insert mode. One downside I found was that the Ctrl-[ combo seems to back up the cursor one character, which can be annoying.</p>

<p>For my personal use, I am thinking about mapping the key it sends to <code>Left-Alt</code> so that I can use the footpedal while in emacs&#8217; Org Mode and not have to move my left hand down to hit Alt with my ring finger every time I want to adjust a heading or start a new heading.</p>

<p>Overall, this pedal is much cheaper than the high-end pedals mentioned above. The total cost came to around $37, because I had some of the parts on hand. Further, you can upload new code to the Teensy on all operating systems, a big win over the Windows-only pedals above.</p>

<p>However, this pedal only has one foot switch. You could easily add more M-Audio sustain pedals to the design, and keep adding 1/4&#8221; jacks to a project box. The Teensy has plenty more IO lines to use! Or you could go for it all in one enclosure with the guitar pedal hardware.</p>

<p><a href="http://www.flickr.com/photos/mattgauger/9451908041/" title="IMG_1903 by Matt Gauger, on Flickr"><img src="http://farm4.staticflickr.com/3780/9451908041_c8446aa3e7_z.jpg" width="480" height="640" alt="IMG_1903" style="display: block; margin: 0 auto;" /></a></p>

<hr />

<p>If you have any questions or comments, I&#8217;d love to hear about it over on Twitter, where I am <a href="https://twitter.com/mathiasx">@mathiasx</a>.</p>

<h3>Research:</h3>

<ul>
<li><a href="http://hackaday.com/2012/06/21/building-a-clutch-for-vim/">Hackaday: Building a clutch for vim</a></li>
<li><a href="http://arduino.cc/en/Reference/KeyboardModifiers">Arduino Keyboard modifiers</a></li>
<li><a href="http://www.emacswiki.org/emacs/FootSwitches">Emacs Wiki: Foot Swtiches</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building a chording keyboard: progress so far]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/08/03/building-a-chording-keyboard-lessons-learned-and-progress-so-far/"/>
    <updated>2013-08-03T08:21:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/08/03/building-a-chording-keyboard-lessons-learned-and-progress-so-far</id>
    <content type="html"><![CDATA[<p>Chording keyboards have been a computing peripheral for a long time. They&#8217;ve been in use at least since Douglas Engelbart gave what is known as <a href="http://www.youtube.com/watch?v=yJDv-zdhzMY">The Mother of all Demos</a> in 1968. Rather than try to sum up the history and potential of the device here, I recommend you read the excellent essay <a href="http://www.loper-os.org/?p=861">Engelbart&#8217;s Violin</a> by Stanislav Datskovskiy on loper-os.org</p>

<p><img src="http://blog.mattgauger.com/images/engelkey.jpg" alt="Engelbart's chording keyboard in use" /></p>

<p><cite>Image via <a href="http://research.microsoft.com/en-us/um/people/bibuxton/buxtoncollection/detail.aspx?id=7">http://research.microsoft.com/en-us/um/people/bibuxton/buxtoncollection/detail.aspx?id=7</a></cite></p>

<p>I&#8217;ve always had an interest in building hardware. When I was younger, I dreamed of building robots some day that I could interact with, play games with, or maybe go to space with. Someday I hope that I&#8217;ll get that chance. But in the meantime, I&#8217;ve built all sorts of hardware, and I&#8217;ve always been interested in the low-level side of computing.</p>

<p>At <a href="http://bendyworks.com">Bendyworks</a> right now, we have flurry of activity and interest focusing on low-level computing, digital logic, and hardware. We&#8217;ve had several discussions in off-hours about learning computing from first principles: digital logic, circuit design, and taking that knowledge to the point of designing and building CPUs and then computers around those novel CPUs. There&#8217;s interest in the <a href="http://arduino.cc/en/">Arduino</a> and some of my coworkers are taking the so-called <code>nand2tetris</code> course: <a href="http://www.nand2tetris.org/">Building a Modern Computer from First Principles</a>.</p>

<p>We recently built a project at Bendyworks that we call <a href="https://github.com/bendyworks/concert_cam">concert_cam</a>, which takes pictures at the <a href="http://www.liveonkingstreet.com/">Live on King Street concerts</a> outside our office. You can see a <a href="https://www.facebook.com/media/set/?set=a.180416672130576.1073741826.180178628821047&amp;type=3">gallery the pictures taken at the most recent concert</a> on Facebook. At some point I&#8217;ll blog about the <code>concert_cam</code> project and provide some lessons learned.</p>

<p>But for now, I&#8217;d like to talk about a project I&#8217;ve been working on for awhile: a chording keyboard. I don&#8217;t have a clever name for it, so the code currently lives at <a href="https://github.com/mathias/chording">github.com/mathias/chording</a>. The repo represents only some of the attempts I&#8217;ve made at getting it to work. (Code from several other attempts to code a chording keyboard died in a VMware Linux VM that ate its own disk image, and I didn&#8217;t commit any of that code. Luckily, that code was mostly things I&#8217;d ruled out as possible solutions.)</p>

<p>Building a chording keyboard in software is not trivial, so I have moved on to building one purely in hardware.</p>

<div id="background-section"></div>


<h2>Background information</h2>

<p>USB devices that we use for input, like mice and keyboards, implement something called USB HID, for Human Interface Device. Linux, Mac OSX and other operating systems have supported USB HID for a long time.</p>

<p>To build a chording keyboard that can work on any computer without special software installed, the device will have to implement USB HID and send the correct key events for a given chord.</p>

<p>There are lots of chording keyboard projects and commercial products out there. To name just a few:</p>

<ul>
<li>The <a href="http://en.wikipedia.org/wiki/Microwriter">Microwriter</a>, which the author of loper-os.org discusses in the essay <a href="http://www.loper-os.org/?p=861">Engelbart&#8217;s Violin</a>, and also <a href="http://www.loper-os.org/?p=1066">covered reverse-engineering</a>.</li>
<li>The <a href="http://www.handykey.com/">twiddler</a>, which is commercially available. I have used my coworker <a href="http://sencjw.com/">Chris</a>&#8217;s twiddler quite a bit, but couldn&#8217;t get over the TV-remote-control ergonomics.</li>
<li>The <a href="http://rhodesmill.org/brandon/projects/tabspace-guide.pdf">tabspace layout for the twidder</a> (PDF link), which is an optimized key map layout for Twiddler.</li>
<li>The <a href="http://wearcam.org/septambic/">septambic keyer</a> by Steve Mann.</li>
<li>The <a href="http://chordite.com/">chordite</a> keyboard.</li>
<li>The <a href="http://symlink.dk/projects/spiffchorder/">spaceman spiff layout / spiffchorder project</a>.</li>
<li>The <a href="http://gkos.com/gkos/index-gkos-com.html">gkos</a> project to create a software chording keyboard for smartphones.</li>
</ul>


<p>Ultimately, none of these projects or products really fit what I had in mind for a chording keyboard.</p>

<p>Why a chording keyboard, you might ask?</p>

<p>Well, I spend most of my work day editing text. While I am quite proficient at vim and slowly getting better at emacs, the kinds of key combos that a professional programmer uses daily are quite complex. There is a constant risk of RSI or carpal tunnel (which plagued me in my teens, but I have been free of for over a decade.)</p>

<p>With a chording keyboard, one could take a common key combo that you use all the time and put it under a much easier-to-type chord. This becomes especially attractive to me in replacing some of the key-combos required for operating emacs (especially those that use alt.)</p>

<p>Of course, such a device isn&#8217;t designed to completely replace having a keyboard on the desk. Even with a lot of practice, the reality is that I&#8217;ll probably continue to be faster at typing words on QWERTY. But having a chording keyboard off the left side, and a mouse on the right, seems to make sense. I am, after all, a software craftsman, and if I feel like I need to build a particular tool (even a physical piece of hardware) to augment my current toolbox, then it makes sense to do it.</p>

<p>For a long time, I have dreamed of a way of being able to record programming language keywords and idioms as macros, as well as methods to type faster. Since I haven&#8217;t found any way to train myself to type QWERTY faster, I started to look at alternatives. Learning Dvorak or Colemak might help, but it still doesn&#8217;t get me away from the legacy typewriter keyboard design.</p>

<p>And still, those alternative layouts doesn&#8217;t get me to the point where I can type out an entire block of code at once. For example, I might want to map a key to output something I frequently type, such as a Javascript anonymous function. Knowing which editor I&#8217;m in, I could have the keyboard leave the cursor in the function body, ready to be filled in:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>function() {
</span><span class='line'>  _
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>(where the underscore shown is the cursor position)</p>

<p>And lastly, I wanted to build a chording keyboard because it&#8217;s cool, it&#8217;s different, and because <strong>we frequently accept the paradigms handed to us in computing without really thinking about how we might improve or replace them.</strong></p>

<p>To understand chording keyboards best, it is worth noting that while regular keyboards detect the initial key being pressed down, a chording keyboard must detect when all of the keys in a chord are released simultaneously. Due to how fast electronics really are, no human could actually release all of the keys at exactly the same moment. For that reason, we need to implement chording in a way that takes time into account and looks to see if any chord pattern matches in the past n milliseconds.</p>

<h2>Brief project history</h2>

<p>After reviewing possible hardware to use to build a chording keyboard, I stumbled upon the Razer Nostromo (and its earlier incarnations from Belkin.) These gaming pads are popular with PC gamers because it puts the WASD keys under your left hand and frees your right hand up for the mouse.</p>

<p><img src="http://blog.mattgauger.com/images/razer_nostromo.jpg" alt="Razer Nostromo" /></p>

<p>Other features the Nostromo had over other devices were supporting <a href="http://en.wikipedia.org/wiki/Rollover_(key)#n-key_rollover">N-key rollover</a> &mdash; basically, the ability for the keyboard to know that multiple keys are being pressed at once, and send all of those keys to the computer &mdash; as well as a little 4-way directional pad, and blue lights (always a plus!)</p>

<p>The Nostromo also comes with a piece of software that you can install and remap the key mappings with. The key mappings get saved onto the device, meaning the device can operate without the software. The current mode is indicated by three LEDs near the thumb, which count up in binary, yielding 8 key maps. Additionally, any of the keys can trigger a pre-recorded macro of many key events.</p>

<p>Sadly, while the Nostromo software can have one key press trigger a sequence of buttons for you, for example, to macro a complicated action in a game, it did not support detecting a chord (multiple key presses simultaneously) into a single key event. So with that limitation in mind, I set about trying to write code to detect chords and turn them into key presses in software rather than at the hardware layer.</p>

<h3>mxk</h3>

<p>On Linux, there is a project called <a href="http://welz.org.za/projects/mxk">mxk</a>. <code>mxk</code> is basically a USB HID swiss army knife and HID event remixer, able to take input from any USB device, run it through various rules, and then output new USB HID events to the USB bus with a &#8220;virtual&#8221; USB HID device. Many example configuration scripts are provided, and one of the most common use seems to be to create a key press that turns a QWERTY keyboard into a DVORAK keyboard and back again, without having to change the Linux system settings. It seemed promising.</p>

<p><code>mxk</code> even indicated that it had support for two different kinds of chording: braille keyboard chording and a simpler chord-matching function.</p>

<p>After banging my head against its confusing configuration syntax for about 2 weeks, I determined that <code>mxk</code> just couldn&#8217;t do what I wanted. Two issues cropped up: in the braille chording function, only one row of keys was supported and two hands were assumed. (Basically, it wanted ASDF and JKL; keys to form chords, and didn&#8217;t support anything else.)</p>

<p>The regular chording functionality seemed like it might work, until I ran into a huge, glaring issue: A key used in one chord couldn&#8217;t be used in another. For example, let&#8217;s say I&#8217;m mapping keys for the left hand on a QWERTY keyboard to be used in a chord. So I might have a chord like RE which maps to &#8216;a&#8217; and another chord like FE that maps to &#8216;k&#8217;. The E used in both chords didn&#8217;t work in <code>mxk</code>. It simply couldn&#8217;t support it; it could only watch for unique chords. This limits the key map for a chording keyboard made of a 12-key grid from some 495 combinations to 12, gaining us nothing since individual key presses are just as efficient.</p>

<p>With these limitations discovered, I tried to hack the code for <code>mxk</code> to support my use case better. But, I don&#8217;t have much in the way of C chops when it comes to device drivers and pointers, and implementing code against Linux&#8217;s libHID is kind of a pain. Further, the <code>mxk</code> source isn&#8217;t very well documented, outside of very few comments littered around the code. Additionally, I found libHID&#8217;s docs unapproachable.</p>

<p>I realized that I was <strong>working at the wrong abstraction level</strong>, like so many projects that had frustrated me before. So I decided to move up to something at a higher level, with the hope that someone else had figured out the headaches of low-level libHID implementation. There are many high level libraries built on libHID. But since there isn&#8217;t a whole lot of need for them in most computing, they tend to be abandoned, very old, simplistic, or all of the above. I also was frustrated that my attempts so far would lock me into only using a Linux machine, as my normal work environment at Bendyworks is Mac OSX. We pair all of the time, so I would not be able to use my chording keyboard whenenver I paired with someone else.</p>

<h3>Plover</h3>

<p>Another project that I found that seemed promising was <a href="https://github.com/plover/plover">Plover</a>. At first glance, Plover doesn&#8217;t seem to be the right kind of software at all. It is an open source stenographer program that allows transcriptionists and court stenographers to turn a regular QWERTY keybord with n-key rollover into a high-end steno tool. The specialized hardware that court stenographers use can cost thousands of dollars, so an open source project that implements it for free on a $100 keyboard is a great win for those in that field.</p>

<p>Despite coming mapped for stenography and transcription &mdash; a system which I find very confusing &mdash; at its heart, Plover is a cross-platform Python GUI app that supports turning chords into words or phrases. This seemed like exactly what I needed. Going through the source code, I noticed that different keyboards got different configuration classes, and set about trying to create a class to map the keys on the Nostromo to the key events that Plover was expecting.</p>

<p>Now Plover comes with a huge dictionary of words that chords map to. And those chords are made up of certain key events, but not the ones we&#8217;re used to. (Some idea of how they look can be found <a href="https://github.com/plover/plover/blob/master/plover/machine/sidewinder.py#L14-L51">here</a> on Github.) How those special events combine and whether they come at the beginning or end of the chord seems to be the most important part of understanding this system. I struggled to understand the mappings, but it was pretty complicated. Plover comes with a giant, 124,000+ line JSON dictionary. I threw that out and started trying to write my own JSON dictionary; a humbler one that simply mapped chords to key events and a few Ruby &amp; JavaScript programming idioms.</p>

<p>I struggled with understanding the key event names and how they combined (since I don&#8217;t have a background in stenography) and eventually, lost the work due to the VMware Linux VM crash mentioned above. Taking it as a sign that I should not continue down the route of using Plover, I put aside the chording keyboard project for many months.</p>

<h3>Teensy and a return to hardware</h3>

<p>Originally I had tried to avoid hacking hardware so that I could focus on what I do day-to-day: write software. But in the end, I felt like I had exhausted my ability to get this project off the ground by only writing software.</p>

<p>When we built the <code>concert_cam</code> project at Bendyworks, the first version of the button pedestal we built utilized a <a href="http://www.pjrc.com/teensy/">Teensy board</a> &mdash; basically, a small Arduino-like microcontroller. The huge feature that the Teensy provides over other Atmel boards is that it comes out-of-the-box with a firmware that sets it up as a USB HID device.</p>

<p>The basic process for programming and using the Teensy is this:</p>

<ul>
<li>You program it in the Arduino IDE like other Arduino boards</li>
<li>Anything you &#8220;println&#8221; will be sent as if someone had typed it on a USB keyboard.</li>
<li>Additionally, there is a Mouse class that you can use to send mouse movement, click, and scroll wheel information.</li>
<li>When you upload your code to the Teensy, it reboots, and immediately starts behaving like a USB HID device as far as the operating system is concerned.</li>
</ul>


<p>For the <code>concert_cam</code>, it was easy enough to have a big arcade-style button send the keyboard event of &#8220;p&#8221; (for press) to the Raspberry Pi that the Teensy was attached to. A script on the Raspberry Pi watched for this keyboard input and told the camera to take a picture. It was very quick to get that working.</p>

<p>Here&#8217;s the <code>concert_cam</code> button pedestal with Teensy and Raspberry Pi getting wired in:</p>

<p><a href="http://www.flickr.com/photos/mattgauger/9427820477/" title="IMG_1817 by Matt Gauger, on Flickr"><img src="http://farm8.staticflickr.com/7395/9427820477_a8b4630519_z.jpg" width="480" height="640" alt="IMG_1817"></a></p>

<p>Confident by my success with using the Teensy in the <code>concert_cam</code>, I decided to put a Teensy in my Nostromo, replacing the normal USB board inside it and translating keyboard chords into key press events at the hardware level.</p>

<p>The first step is to open up the Nostromo. This is pretty easy; just unscrew all the visible screws, and find &amp; unscrew the other screws underneath the rubber feet of the gamepad. The Nostromo comes apart into three pieces, and looks like this inside:</p>

<p><a href="http://www.flickr.com/photos/mattgauger/9427844525/" title="iPhoto by Matt Gauger, on Flickr"><img src="http://farm4.staticflickr.com/3784/9427844525_4b59fa4bc3_b.jpg" width="581" height="733" alt="iPhoto"></a></p>

<p>The first problem encountered is those little grey ribbons - they&#8217;re ZIF surface mount stuff, and everything else inside is surface mount here, too. For an electronics hobbyist, surface mount components can represent a big source of frustration. For me, I just didn&#8217;t want to deal with them. I can&#8217;t really solder to the cables with any precision and the spacing of the connectors was so small that there was no hope of attaching wires there. Further, the circuit boards had traces running inside but didn&#8217;t really have any pins that I could solder to. A real bummer.</p>

<p>I thought that maybe I could get more of the plastic cable connectors (the little white and black connectors on the main circuit board), but with a regular pin spacing, not surface mount. All attempts to find such a part were unsuccessful. So I had to get creative.</p>

<p>The Nostromo uses membrane keys, which most laptop and PC keyboards nowadays do. A long time ago, almost all keyboards used &#8220;mechanical&#8221; key switches &#8211; switches that had springs or other tension devices and sent a keypress when continuity was made between two contacts. The loud, much-loved IBM Model M keyboard counts as a mechanical keyboard. Gaming keyboards and a few hardcore programmers (like many of us at Bendyworks) are holdouts for using mechanical keyboards, and a few companies still make them. For mechanical key switches, the current winner is the Cherry MX line. (To learn more about mechanical keyboards and Cherry MX switches, I recommend <a href="http://www.wasdkeyboards.com/mechanical-keyboard-guide">this guide</a>.)</p>

<p>Cherry MX key switches are not all that expensive, and I&#8217;d only need 15 to convert the Nostromo. I put in an order for the Cherry MX browns from <a href="http://www.wasdkeyboards.com/">wasdkeyboards.com</a> and they shipped them out fast. I figured I could get away with using the keycaps from a number pad, which are also cheap, and so I threw those into the order as well.</p>

<p>However, by replacing the key switches, I was getting into a realm of hardware hacking that I was trying to avoid: fabbing physical things from scratch. For this project, I wanted the keyboard to be sturdy and reliable; I didn&#8217;t want it to fall apart or move under my hand or rattle. Making a mounting plate that they keys snap into is the typical way that hobbyists build their own mechanical keyboards. And lots of people do, over on sites like <a href="http://deskthority.net/">deskthority.net</a> and <a href="http://geekhack.org/">geekhack.org</a>, but without a really well stocked workshop or a Makerspace membership, I didn&#8217;t want to go down that road.</p>

<p>Luckily, some quick googling turned up a <a href="http://www.xim3.com/community/index.php?PHPSESSID=98v9639t6etse5msjbupuogp24&amp;topic=8122.0">forum post in which the author replaces Nostromo key switches with Cherry MX keys</a>. The mounting plate for the membrane keys in the Nostromo requires only a little dremeling to convert. Since I was also throwing out the existing USB circuit board for the Nostromo, I can get away with removing the membrane switch PCB and soldering a cable directly to the Teensy&#8217;s pin headers, getting rid of those pesky ZIF cables.</p>

<p>Currently, I&#8217;m waiting for the key switches to arrive so that I can cut down the white mounting plate for each switch. My plan is to wire up each key to an IO line on the Teensy. Typically, keyboards use multiplexing in a grid to let the computer know which key was pressed: essentially, rows of keys are connected to one set of pins and columns of keys are connected to another set of pins, and when a pin for a row and a column goes HIGH, you know which key was pressed based on it being the intersect of that row and column. The issue you run into here is, again, complicated by chording. While the microcontroller can figure out reasonably well individual keys, there are issues on some keyboards with &#8221;<a href="http://www.microsoft.com/appliedsciences/antighostingexplained.mspx">ghosting</a>&#8221; other keys when chording.</p>

<p>Since I only have about 15 keys and maybe another 4 or 5 input/outputs that I need, I can get away with using separate IO lines on the Teensy 2.0. The Teensy++ 2.0 has are even more IO lines, which would make it better suited to projects with more IO lines needed. Not needing diodes to ground, not having to wire up a matrix, and not having to detect two pins makes both the hardware and software here much simpler.</p>

<h3>Scroll wheel</h3>

<p>While waiting for the key switches to arrive, I began work on the one non-surface-mount component in the Nostromo that I could solder to: the scroll wheel. On the scroll wheel&#8217;s PCB, there is a mechanical encoder, a button (the click when you press down on a mouse scroll wheel) and an LED.</p>

<p><a href="http://www.flickr.com/photos/mattgauger/9430775972/" title="skitched-20130803-121011 by Matt Gauger, on Flickr"><img src="http://farm8.staticflickr.com/7453/9430775972_991c8e8a8d_c.jpg" width="600" height="800" alt="skitched-20130803-121011"></a></p>

<p>Here&#8217;s a quick link for reading up on how mechanical encoders work in mice, and particularly, how to interface one with an Arduino: <a href="http://forum.arduino.cc/index.php/topic,15336.0.html">Mouse Scroll Wheel Sensor and Arduino</a>. There&#8217;s also some source code in that thread that will probably prove useful later. Note in the picture that the middle leg of the encoder is ground, and the two ends correspond to the signals sent when you rotate it &mdash; you&#8217;ll have to figure out whether the scroll direction matches their location yourself by experimenting.</p>

<p>I used part of my Friday Growth Day at Bendyworks to start wiring up and coding the firmware for the Nostromo&#8217;s scroll wheel. The basic idea is that the mechanical encoder has two outputs. You monitor both lines on separate IO pins on the Teensy, and whichever IO line goes HIGH first is the direction of the scroll. With the Teensy&#8217;s convenient Mouse class, you can then just send a scroll event to the OS. In a matter of minutes, I had my scroll wheel scrolling web pages. Not bad.</p>

<p>I&#8217;ll be implementing a variation on the sliding buffer for key events, so I will probably also use that code for handling scrolls (over a much shorter, separate buffer.)</p>

<p>Since I was trying to understand the mechanical encoder and could only really connect alligator clips to one pin at a time, I wrote up a quick Arduino script to detect only one direction of scrolling. Here&#8217;s that code:</p>

<script src="https://gist.github.com/mathias/6147169.js"></script>


<p>In my repo on Github: <a href="https://github.com/mathias/chording/blob/master/teensy/scroll_wheel/scroll_wheel.ino">scroll_wheel.ino</a></p>

<p>Note that this does not implement a sliding buffer or direction detection.</p>

<p>Eventually, I&#8217;d like to break my scroll wheel code out into an Arduino library that takes the two input pin numbers and a velocity as parameters to the constructor, and implements the scroll direction detection. The library would send the scroll event for you based on the velocity you passed in. But that will have to come later.</p>

<h3>Future work</h3>

<p>I&#8217;m going to be getting the key switches in the next week and beginning the hardware hacking to install them.</p>

<p>On the software end, I&#8217;d like to write a script (probably in Ruby) that takes a standardized keyboard mapping file and converts it into a C++ header file that the Arduino can utilize for its chord mappings. That way, I don&#8217;t have to maintain the header file manually or know what C++ constants map to what, I will simply edit my simple key mappings file and regenerate the code.</p>

<p>The <a href="https://github.com/mathias/chording/blob/master/twiddler_keymap.txt">twiddler_keymap.txt</a> file in the repo represents the current plan for my keymap. It is based on the <a href="">Tabspace layout</a> mentioned above in the <a href="#background-section">Background</a> section. I haven&#8217;t found any reason to not use the Tabspace layout, as it seems sensible and leaves plenty of room in the unmapped chords for me to implement key combos, programming language idioms, and text editor movement.</p>

<p>One last decision I need to make is whether to replace the Nostromo&#8217;s thumb directional pad. The current thumbpad uses membrane switches similar to the keys, and is all surface mount with very little access to its signals. One thought is to replace the 4-way pad with a Playstation-controller style <a href="https://www.sparkfun.com/products/9032">joystick</a> from Sparkfun.</p>

<p><a href="https://www.sparkfun.com/products/9032">
<img src="http://blog.mattgauger.com/images/sparkfun_joystick.jpg" alt="Sparkfun thumb joystick" />
</a></p>

<p>With this joystick, I&#8217;d be able to implement either mouse movements or arrow key movements, and could probably toggle which it behaves like with the small button located above the directional pad. However, securely mounting the joystick into the Nostromo case so that it is durable might prove an issue. I&#8217;ve put off making this decision until I have successfully hacked the mechanical switches in.</p>

<p>I&#8217;ll be blogging about each step of finishing this chording keyboard as I go. Stay tuned for the next post about installing up the key switches and wiring them to the Teensy.</p>

<h3>Final thoughts</h3>

<p>I&#8217;ve got a lot of projects, and I put them down regularly to focus on something else. That list of projects continues to grow and grow. So I don&#8217;t feel very guilty that I&#8217;ve put down this project for awhile and am just now picking it up again. I&#8217;m making good progress, and find it interesting rather than frustrating, so I will continue work on it.</p>

<p>In truth, this project doesn&#8217;t really represent much value outside of the things I&#8217;m learning as I go. I have no ambitions of turning this into a commercial product, and while some people might find my notes here useful, I&#8217;m not trying to make a repeatable project that others can build part-for-part. Is it worth it? Definitely. Is it for everyone? Probably not.</p>

<p>One thing I&#8217;d like to do after completing this device is begin work on a custom computer. Specifically, I want to learn enough digital logic concepts to design a whole computer in a language like Verilog or VHDL, and then burn the design into a FPGA board.</p>

<p>Such a computer would <strong>not</strong> be intended to compete with your Core i7 quad core &#8211; I&#8217;m thinking of implementing a unique architecture with the overall processing capability of something like an early 80&#8217;s microcomputer. It would be interesting, but not entirely useful for day-to-day computing.</p>

<p>When the computer is built, I&#8217;d begin implement an operating system on top of that computer in Lisp, along the lines of what the author of <a href="http://loper-os.org">loper-os.org</a> has been working towards for many years.</p>

<p>Such a project may take a decade or more to realize, though, and so is not undertaken lightly or easily accomplished.</p>

<hr />

<p>If you have any questions, comments, or your own chording keyboard project, I&#8217;d love to hear about it over on Twitter, where I am <a href="https://twitter.com/mathiasx">@mathiasx</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Minsky's Circle Algorithm in Shoes.rb / Hackety Hack]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/07/27/minskys-circle-algorithm-in-shoes-dot-rb-slash-hackety-hack/"/>
    <updated>2013-07-27T11:32:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/07/27/minskys-circle-algorithm-in-shoes-dot-rb-slash-hackety-hack</id>
    <content type="html"><![CDATA[<hr />

<p><em>(This post is part of my blog archiving project. This post appeared on <a href="https://coderwall.com/p/fukypa">Coderwall</a> on July 27, 2013.)</em></p>

<hr />

<p>I wanted to try to implement Minsky&#8217;s Circle Algorithm from the famous <a href="http://en.wikipedia.org/wiki/HAKMEM">HAKMEM</a>. As noted in lots of other places online (<a href="http://brainwagon.org/2010/08/09/drawing-circles-ala-marvin-minsky/">1</a>, <a href="https://news.ycombinator.com/item?id=3111501">2</a>, <a href="http://cabezal.com/misc/minsky-circles.html">3</a>), the algorithm doesn&#8217;t plot a true circle, but rather a very round ellipse. Here&#8217;s the text from the HAKMEM entry:</p>

<blockquote><p>ITEM 149 (Minsky): CIRCLE ALGORITHM Here is an elegant way to draw almost circles on a point-plotting display:</p>

<blockquote><p>&nbsp;&nbsp;&nbsp;NEW X = OLD X - epsilon * OLD Y</p>

<p>&nbsp;&nbsp;&nbsp;NEW Y = OLD Y + epsilon * NEW(!) X</p></blockquote>

<p>This makes a very round ellipse centered at the origin with its size determined by the initial point. epsilon determines the angular velocity of the circulating point, and slightly affects the eccentricity. If epsilon is a power of 2, then we don&#8217;t even need multiplication, let alone square roots, sines, and cosines! The &#8220;circle&#8221; will be perfectly stable because the points soon become periodic.</p>

<p>The circle algorithm was invented by mistake when I tried to save one register in a display hack! Ben Gurley had an amazing display hack using only about six or seven instructions, and it was a great wonder. But it was basically line-oriented. It occurred to me that it would be exciting to have curves, and I was trying to get a curve display hack with minimal instructions.</p></blockquote>

<p>The benefit of using this algorithm, at the time, was that it doesn&#8217;t use cosine/sine or any other complicated functions, and so could be implemented on the rather-limited computers of that time to draw circles fast. (I believe it was used to draw the orbits of ships on the early game <a href="http://en.wikipedia.org/wiki/Spacewar_(video_game">SpaceWar</a>, but I don&#8217;t know that for sure.)</p>

<p>To implement it myself, I needed to be able to plot points on a display. So I turned to Hackety-Hack, which comes with Shoes for drawing graphics. The Shoes DSL for drawing shapes is rather simple, which means we can take the pseudocode above and turn it into a working demo rather easily:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="no">Shoes</span><span class="o">.</span><span class="n">app</span> <span class="k">do</span>
</span><span class='line'>  <span class="n">epsilon</span> <span class="o">=</span> <span class="mi">1</span><span class="o">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">16</span>
</span><span class='line'>  <span class="n">offset</span> <span class="o">=</span> <span class="mi">250</span>
</span><span class='line'>  <span class="n">x</span> <span class="o">=</span> <span class="mi">20</span>
</span><span class='line'>  <span class="n">y</span> <span class="o">=</span> <span class="mi">20</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">fill</span> <span class="n">red</span>
</span><span class='line'>  <span class="n">shape</span> <span class="k">do</span>
</span><span class='line'>    <span class="n">move_to</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">offset</span><span class="p">,</span><span class="n">y</span> <span class="o">+</span> <span class="n">offset</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="mi">100</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
</span><span class='line'>      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">y</span>
</span><span class='line'>      <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">x</span>
</span><span class='line'>      <span class="n">line_to</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">offset</span><span class="p">,</span><span class="n">y</span> <span class="o">+</span> <span class="n">offset</span><span class="p">)</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">fill</span> <span class="n">blue</span>
</span><span class='line'>  <span class="n">oval</span><span class="p">({</span><span class="ss">top</span><span class="p">:</span> <span class="mi">250</span><span class="p">,</span> <span class="ss">left</span><span class="p">:</span> <span class="mi">320</span><span class="p">,</span> <span class="ss">radius</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span> <span class="ss">center</span><span class="p">:</span> <span class="kp">true</span><span class="p">})</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>Epsilon is 1/16, as indicated by some quick googling &#8211; basically a small power of two. I have to use the offset to get the center of the circle closer to the center of the Shoes window &#8211; without the offset, the circle will only be a quarter-circle in the upper left corner.</p>

<h2>How does this compare to plotting a real circle?</h2>

<p>If we want to compare the roundness of our &#8220;circle&#8221; to a real circle drawn by Shoes, we can add this line in before the closing <code>end</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="n">fill</span> <span class="n">blue</span>
</span><span class='line'>  <span class="n">oval</span><span class="p">({</span><span class="ss">top</span><span class="p">:</span> <span class="mi">250</span><span class="p">,</span> <span class="ss">left</span><span class="p">:</span> <span class="mi">320</span><span class="p">,</span> <span class="ss">radius</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span> <span class="ss">center</span><span class="p">:</span> <span class="kp">true</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>Although their radiuses are going to be slightly different.</p>

<p>Here&#8217;s what we end up with. Minsky&#8217;s Circle Algorithm on the left in red, a real circle on the right in blue:</p>

<p><img src="http://www.mattgauger.com/img//Shoes-20130727-151954.jpg" alt="Hackety Hack" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WARNING: Nokogiri was built against LibXML version x.x.x]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/05/23/warning-nokogiri-was-built-against-libxml-version-x-dot-x-x/"/>
    <updated>2013-05-23T11:46:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/05/23/warning-nokogiri-was-built-against-libxml-version-x-dot-x-x</id>
    <content type="html"><![CDATA[<hr />

<p><em>(This post is part of my blog archiving project. This post appeared on <a href="https://coderwall.com/p/kia38w">Coderwall</a> on May 23, 2013.)</em></p>

<hr />

<p>When you run tests or rake, if you see:</p>

<pre><code>WARNING: Nokogiri was built against LibXML version 2.9.0, but has dynamically loaded 2.7.8
</code></pre>

<p>Then do the following:</p>

<pre><code> gem uninstall nokogiri libxml-ruby

brew update

brew uninstall libxml2
brew install libxml2 --with-xml2-config

brew uninstall libxslt
brew install libxslt
brew unlink libxslt

bundle config build.nokogiri -- --with-xml2-dir=/usr --with-xslt-dir=/usr --with-iconv-dir=/usr
bundle
</code></pre>

<p>Nokogiri should now be compiled against the right version!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reset a lost password on an Ubuntu VM]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/04/24/reset-a-lost-password-on-an-ubuntu-vm/"/>
    <updated>2013-04-24T11:46:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/04/24/reset-a-lost-password-on-an-ubuntu-vm</id>
    <content type="html"><![CDATA[<hr />

<p><em>(This post is part of my blog archiving project. This post appeared on <a href="https://coderwall.com/p/vibura">Coderwall</a> on April 24, 2013.)</em></p>

<hr />

<p>You may be like me and keep a couple virtual machines around on your laptop for development, testing, and gaming. I had an Ubuntu VM in VMWare that I&#8217;d lost the password to, and I wanted to reset it so that I could get back to coding.</p>

<p>Typically, with a desktop computer or a server, you hold down some key while the computer is booting to get into the Grub boot manager and then boot into something called &#8220;single user mode&#8221;, where you&#8217;re able to change passwords, fix configs, repair disks, etc.</p>

<p>Unfortunately, the boot screen just flies right by in Ubuntu under VMWare. So the first thing you&#8217;ll need to do is shut down the VM, and then get ready to start it up. <strong>But before you start the VM</strong>: get ready to hit <code>Shift</code> because that&#8217;s what will get you into Grub. Ready? Ok. Boot it and hit <code>Shift</code>.</p>

<p>Now you should be in Grub. If you don&#8217;t get it, don&#8217;t worry, just shut down and try again.</p>

<p>Choose the &#8216;Advanced Options&#8217; and then any of the &#8220;recovery&#8221; lines from the Grub menu for Ubuntu.</p>

<p>You&#8217;ll get dropped into another menu system. Choose <code>root</code>: this is the single-user mode where you are root.</p>

<p>Your / filesystem may be mounted as read-only at this point. Type this to mount it as read-write:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mount -rw -o remount /</span></code></pre></td></tr></table></div></figure>


<p>Now you can reset passwords, etc, like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>passwd myuser</span></code></pre></td></tr></table></div></figure>


<p>Good luck!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[By augmenting human intellect, we mean]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/03/17/by-augmenting-human-intellect/"/>
    <updated>2013-03-17T22:44:00-05:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/03/17/by-augmenting-human-intellect</id>
    <content type="html"><![CDATA[<blockquote>
By &#8220;augmenting human intellect&#8221; we mean increasing the capability of a man to approach a complex problem situation, to gain comprehension to suit his particular needs, and to derive solutions to problems. Increased capability in this respect is taken to mean a mixture of the following: more-rapid comprehension, better comprehension, the possibility of gaining a useful degree of comprehension in a situation that previously was too complex, speedier solutions, better solutions, and the possibility of finding solutions to problems that before seemed insoluble. And by &#8220;complex situations&#8221; we include the professional problems of diplomats, executives, social scientists, life scientists, physical scientists, attorneys, designers&#8211;whether the problem situation exists for twenty minutes or twenty years. We do not speak of isolated clever tricks that help in particular situations. We refer to a way of life in an integrated domain where hunches, cut-and-try, intangibles, and the human &#8220;feel for a situation&#8221; usefully co-exist with powerful concepts, streamlined terminology and notation, sophisticated methods, and high-powered electronic aids.
<footer>
<strong>Douglas C. Engelbart</strong>
&ndash;
<cite><a href="http://www.dougengelbart.org/pubs/augment-3906.html">Augmenting Human Intellect: A Conceptual Framework </a></cite>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Filter or Be Filtered]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/03/07/filter-or-be-filtered/"/>
    <updated>2013-03-07T22:09:00-06:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/03/07/filter-or-be-filtered</id>
    <content type="html"><![CDATA[<p>Eli Pariser&#8217;s talk, <a href="http://www.ted.com/talks/eli_pariser_beware_online_filter_bubbles.html">Beware online &#8220;filter bubbles&#8221;</a> recently hit the front page of the TED Talks website. I found it interesting because it discusses some of what I&#8217;ve seen happening online, and some of my fears for how we search and consume content. Watch the video if you haven&#8217;t to see just how much is already being filtered on the web for you.</p>

<p>Right after I saw the video, of course, <a href="http://washingtonpost.com/business/technology/facebook-to-change-news-feed-to-a-personalized-newspaper/2013/03/07/b294f61e-8751-11e2-98a3-b3db6b9ac586_story.html">Facebook announced</a> that they&#8217;ll be rolling out a new version of the the news feed. They are quoted as making it more like a &#8220;personal newspaper&#8221; &mdash; a filter, essentially, for the things Facebook thinks you want to see. As the video above pointed out, they&#8217;ve already been filtering <em>out</em> the things they think you don&#8217;t want for awhile.</p>

<p>No doubt there will be some backlash as people adjust to changes on Facebook, but very few will abandon it. And if you are the kind of person that would abandon Facebook over filtering, or privacy, or concerns about owning your own data, you don&#8217;t have a lot of choices of where to go.</p>

<p>Sure, you can specifically seek out services that aren&#8217;t going to give you a filtered world view &mdash; <a href="https://duckduckgo.com/">DuckDuckGo</a> comes to mind. But that&#8217;s not always possible. The problem is bigger than just the search engine you use and whether or not you&#8217;re logged into Facebook. Just about every site is run by someone else, and they are analyzing you constantly. They are in a brutal battle to keep you as their consumer and keep you from going to other sites. But are the things that they think you want to see what you really want or need to see?</p>

<p>As a developer, I&#8217;m capable of taking matters into my own hands, to some degree. Most of the sites that I use on a daily basis have an API and allow me to export or scrape my personal data. But the cost of switching off of the nice service, the well-designed UI/UX of an official mobile app, and so on has kept me from taking the plunge to export my data and go set up shop on my own version of various web services.</p>

<p>Recently I revamped a very old, empty repo that I had on Github. The point of this repo was code a way to export all of my data from <a href="https://www.last.fm/">Last.fm</a>. But for whatever reason the repo has been empty for something like 4 years now. So the other week, I sat down, checked the <a href="http://www.last.fm/api">Last.fm API docs</a>, and wrote a very simple Ruby script to dump out all the JSON it could about my top tracks, artists, and albums over the past 7 years. That script is available as my <a href="https://github.com/mathias/birdsong">birdsong</a> repo on Github.</p>

<p>So far, I don&#8217;t have a real use for the data. I could try to use some visualization tools on it to make cool graphs or maps. Or I could try and get analytics out of it: genres listened to, how they&#8217;ve changed over the years. But for now, I am content to just have the JSON data.</p>

<p>All in all, it&#8217;s around 30 megabytes of JSON data, which is really just plain text with no compression, so it is really quite a lot of data. There&#8217;s more I can do, though. I plan to do to start taking control, to both aggregate my own data and filter it.</p>

<p>For a long time it has bothered me that <a href="https://www.google.com/reader">Google Reader</a> stopped receiving new features, and the features that existed only went so far. To be fair, Google Reader has been a rock solid web service for many, many years for me. It allows me to read my feeds quickly, reliably, and has parsed feeds well &mdash; all problems I&#8217;ve had with other feed readers. It&#8217;s always had some neat features like showing me analytics of what I read.</p>

<p><img src="http://blog.mattgauger.com/images/google_reader_trends.png" alt="Google Reader Trends" /></p>

<p>But as far as discovering new content and helping me to eliminate content I don&#8217;t read or don&#8217;t want to read, Google Reader is not so great. Reader is terrible at suggesting new feeds to read to me; it constantly suggests Dilbert and Lifehacker, and has for the past 5 years or so. I have no interest in either of those. It has never analyzed my reading patterns to such a degree that it suggested something new that blew me away. I am looking for those kinds of interesting suggestions: not just for feeds that match what I already read, but things that are outside of my normal bubble but would be interesting to me.</p>

<p>Luckily, Google Reader has an API, and rather than just exporting my data and building a new service, I can start to build off of it. I get to keep a lot of the features I enjoy while extending it with my own code.</p>

<p>In Pariser&#8217;s talk, he talks about encoding algorithms of filtering and recommendation with a sense of civic duty. To some degree, this means having some journalistic integrity. Such an algorithm needs to present both sides of the story. One issue of many feed readers and other content online is that, well, it only shows one view. The view of the article you&#8217;re on.</p>

<p>But imagine a feed reader that was more like the front page of Google News. It would not only show you the blog post you&#8217;re reading, but all recent blog posts from other authors about similar topics. Maybe, if they&#8217;re responding to a news event or writing about a known fact, the reader could do the work to track down the original source. To take it even further, without even really needing to be aware of motive, politics, and other factors, a dumb feed reader with good suggestions could probably present both sides of the story. Both sides of an argument. Both liberal and conservative takes on the same bill.</p>

<p>Dreaming up features like this can be a deep rabbit hole. Start considering the consequences of pulling up all past articles you&#8217;ve read about similar keywords or tags. Or performing searches for academic papers on the topic. Pulling in data from Wikipedia. Looking up books you&#8217;ve read or are planning to read on Goodreads that are related to the blog post you&#8217;re reading. Or any other number of ways to slice and dice content. And it doesn&#8217;t have to stop with Google Reader.</p>

<p>Opportunities to make better tools and more intelligently consume information are all around us. At the same time, consumer-consuming corporations on the web try to trap us into filter bubbles. They try to provide us with what they think we want, but can they ever really know? In the end, it&#8217;s control-your-own-filters or be filtered<a href="#filter-or-be-filtered-note" name="filter-or-be-filtered-note-return"><sup>1</sup></a>.</p>

<hr />

<p><a name="filter-or-be-filtered-note"></a></p>

<p><strong>1</strong> The name of this article was lifted from Daniel Rushkoff&#8217;s <a href="http://www.goodreads.com/book/show/9408311-program-or-be-programmed">Program or be Programmed</a>, a book which I didn&#8217;t really enjoy. It was not what I thought it would be about: why we should learn to program so that we can control the complex technical systems around us rather than be controlled by them, or how programming&#8217;s problem solving skills can be applied elsewhere. Instead, I found the book to be some technology-fear-mongering and a bunch of diatribes about how things online or in computers are &#8220;less real.&#8221; Suffice to say, I did not enjoy it. <a href="#filter-or-be-filtered-note-return">&#8617;</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Insanely powerful widgets, brought to you by Moore's Law]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/03/03/insanely-powerful-widgets-brought-to-you-by-moores-law/"/>
    <updated>2013-03-03T11:10:00-06:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/03/03/insanely-powerful-widgets-brought-to-you-by-moores-law</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been teaching my downstairs neighbor basic electronics and how to solder. He&#8217;s a musician and has been working his way through several kits from <a href="http://bleeplabs.com/">Bleep Labs</a>.</p>

<p>As I explained each component: the resistor, the capacitor, the diode, etc., I eventually got to the transistor. I told my neighbor how transistors are rarely used on their own now. The transistors in the kit were there mainly because they were easy to solder, but usually a circuit designer would opt not to use them.</p>

<p>On its own, a single transistor can&#8217;t do much, and takes up some amount of space, which is actually quite large relative to the circuits we build now. I scored bags of hundreds of transistors that were about to be thrown out at the <a href="http://milwaukeemakerspace.org/">Milwaukee Makerspace</a> when we were putting together the electronics lab &mdash; not because they didn&#8217;t work but because that many transistors simply wouldn&#8217;t get used. &#8220;Nowadays, you might as well throw an Arduino in a project,&#8221; was one of the reasons. No one wants to work at the abstraction level of single transistors anymore.</p>

<p>It turned out that the <a href="http://bleeplabs.com/store/the-bleep-drum/">drum machine kit</a> that we were putting together contained an Atmel AVR microprocessor - the main chip of the Arduino. In an effort to save space and complexity, the designers had used a microprocessor instead of discrete transistors. The chip in the Arduino and the Bleep Drum is the ATmega328, which has something like 600,000 transistors inside it.
And I explained how the form factor of the components we were using was obsolete. Even the tight-packed pins of a typical integrated circuit (a computer chip, in common parlance), spaced at 0.1&#8221;, just isn&#8217;t dense enough for modern circuits. The parts we were using were all designed to be soldered to the circuit board by human hands. Slow, error-prone human hands. The vast majority of circuit boards produced today are <a href="http://en.m.wikipedia.org/wiki/Surface-mount_technology">surface mount</a>: parts placed by robots and soldered all in one go by another machine.</p>

<p>&#8220;It&#8217;s really neat that you know all this stuff,&#8221; my neighbor remarked. But I shrugged it off. This knowledge, especially of how analog circuits work and how audio signals are modified by analog components, is mostly obsolete. Better to just use some analog-to-digital converters and put a microprocessor on it. Or better yet, something way more powerful than a simple microprocessor.</p>

<p>We keep putting more and more transistors on a single die, or chip, every day. This trend was first spotted by Intel co-founder Gordon E. Moore, and so we call it <a href="http://en.wikipedia.org/wiki/Moore's_law">Moore&#8217;s law</a>. So far, Moore&#8217;s prediction that the number of transistors on integrated circuits would double every 2 years has been quite accurate. It has led us from the simplest integrated circuit in 1958 to the Core i7 processor in my Macbook Air today.</p>

<p>The other day I tweeted about the crazy processing power that we get today under Moore&#8217;s Law.</p>

<blockquote class="twitter-tweet" align="center"><p>Crazy future; my MBA doesn&#8217;t sweat when running Linux-in-VMware, Chrome, Emacs, LightTable, other apps, terminals &amp; 4 REPLs all at once.</p>&mdash; mathiasx (@mathiasx) <a href="https://twitter.com/mathiasx/status/307668858985140225">March 2, 2013</a></blockquote>


<script async src="http://blog.mattgauger.com//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>And in truth, I was running more software than I could fit into that tweet, because I was listening to music, had a few PDFs in the background, and was managing my ebook collection at the same time. But those notorious CPU hogs listed in the tweet should be enough to illustrate just how much is going on without really pushing the processing cores of the Macbook Air.</p>

<p>Remember, my 13&#8221; Macbook Air only weighs 2.96 pounds. In 2005, I had a 12&#8221; Powerbook G4 that weighed 4.6 pounds and had, by my back-of-the-envelope calculations on Geekbench scores <sup><a href="#geekbench-notes" name="geekbench-notes-return">1</a></sup>, my Macbook Air is almost 9 times as powerful as the Powerbook G4 was.</p>

<p>Where is this progress taking us? Well, my iPhone is already pretty powerful. It&#8217;s hard to get a raw number of FLOPS (floating-point operations per second) for the processor in an iPhone 4S, but we can get a Geekbench score for it. It is weighed against the same scale as the Macbook Air is measured on. On that scale, my iPhone measures<sup><a href="#geekbench-iphone-notes" name="geekbench-iphone-notes-return">2</a></sup> very close to the Powerbook G4 I had 8 years ago, but the iPhone has the advantage of having two cores.</p>

<p>Some people incorrectly read Moore&#8217;s Law as &#8220;processor <em>speed</em> doubling every 2 years,&#8221; which it is not. We&#8217;ve found that there&#8217;s more to processing power than just gigahertz, though. The number of cores in a processor, and therefore the number of simultaneous things that a computer can do, is increasing. While there&#8217;s some issues as we grow into this new paradigm where everything has multiple cores and we have to ensure consistency between them, this is overall a net win for those of us seeking more powerful computers.</p>

<p>To be honest, I don&#8217;t really even notice my computer as physical hardware anymore. It is just the stage for software to run on: quiet, fast, lightweight, and very infrequently does the hardware bog down to make me wait. Only a few short years ago, we would have to wait for the computer to do something &#8211; usually shown as the hourglass on Windows and the spinning beachball on Macs. Even things like copying a file between two directories could stop a system in its tracks, and the computer would simply stop accepting any input from the user. Now, processors, RAM, and SSDs are so fast that I rarely have to wait for them. And if I do have to wait, say, for some piece of software to be installed, the fact that the computer is multicore means that I can go and browse the internet in another window without noticing.</p>

<p>It&#8217;s likely that, just like the example of VMware running Linux running on my Macbook Air in the my tweet, eventually we will get to the point of having so much computing power embedded around us that we will virtualize everything. It&#8217;s possible that we will take not just files or even processes between computing devices but the whole environment, a whole virtualized machine and operating system. As a thought experiment, imagine pausing a VMware virtual machine while it is performing some CPU-intensive task on your laptop. Now copy that paused VM over to another machine, and start it back up. The software will continue to chug along on the CPU-intensive task like nothing happened<sup><a href="#vm-notes" name="vm-notes-return">3</a></sup>. Advances in processing power, storage speed, and wireless networking speed will continue to progress until this process could be seamless to the user.</p>

<p>In some regards, sending the whole VM across the wire and starting it back up on another processor is simpler than trying to marshal a raw process between two machines, and ensure that the process can still run in the other machine&#8217;s environment. It doesn&#8217;t solve the problem of running one process on many machines at once, but it could be used in cases where we can spin up one copy of a process that we want to parallelize, and then copy that VM to many different machines with chunks of the dataset to process. In fact, that&#8217;s basically how many large distributed processing projects like BOINC (the software that SETI@Home runs on) work.</p>

<p>And so it&#8217;s likely that, for reasons of ease of use, sandboxing for security and safety, and simply because we have so much processing power, in the future our phones and our wearable computers will simply be running a virtual machine. Then we don&#8217;t need to worry about what software is running on our desktop PCs when we get home and have access to a larger display; we just move our processing over to the desktop computer, which ever is more convenient. (Even more likely is that we just have a display that acts like an accessory that we can &#8220;throw&#8221; the video onto, rather than having a separate desktop computer.)</p>

<p>The things around us are getting progressively more powerful by way of cheap, small processors. Where before I was saying that electronics hobbyists would rather use an Arduino into a project than deal with many transistors, industry would rather throw a small ARM processor into everything around us and write software than design a custom piece of hardware.</p>

<p>Case in point, over on the Panic blog, the case of <a href="http://www.panic.com/blog/2013/03/the-lightning-digital-av-adapter-surprise/">The Lightning Digital AV Adapter Surprise</a>. After wondering why the new Lightning AV adapter for the iPad mini took a few moments to boot up, and seemed to display a scaled version of the video, they cracked open the Lightning AV cable to find: an ARM processor! As far as they can tell, the iPad mini sends a bit of software to the processor in the Lightning cable every time it is connected, essentially booting the cable up, and sets an Airplay stream down the cable to the other end, where the ARM processor decodes it, upscales it to HD, and sends it to the TV. This makes the Lightning AV cable, in essence, the world&#8217;s smallest AppleTV. And we thought the new AppleTV was small when it was debuted.</p>

<p>When I go to a concert now, the room is full of smartphones being pointed at the stage taking video or pictures. And while most people might think, &#8220;That&#8217;s a lot of pictures and video that will be uploaded to Facebook,&#8221; I think about the fact that the people in the room with me are holding more processing power in their hands than we had in most of the computer labs in my schools and in college. Those phones will just keep getting more powerful, and soon they&#8217;ll match the performance of the Macbook Air I&#8217;ve got in my backpack. Even the mundane things will have plenty of processing power because it will be cheap and simpler to put a cheap processor in it. But those cheap processors are getting more powerful every day, and that is exciting.</p>

<p>So while I may have learned digital logic in college and can help you build up a simple adder from NAND gates, and as a hobbyist I&#8217;ve learned to build <a href="http://www.geofex.com/article_folders/fuzzface/fffram.htm">guitar fuzz pedals from a few transistors</a>, that knowledge is increasingly obsolete in the face of rapid progress. We will soon be packing powerful processors into everything around us, sometimes in surprisingly ways, simply because it is easier and cheaper than designing a custom piece of hardware. But the future is exciting, and that knowledge isn&#8217;t completely useless, as long as I can share it with a few more people to show us just how far we&#8217;ve come.</p>

<hr />

<p><a name="geekbench-notes"></a></p>

<p><strong>1.</strong></p>

<p>&#8220;Geekbench scores are calibrated against a baseline score of 1,000 (which is the score of a single-processor Power Mac G5 @ 1.6GHz). Higher scores are better, with double the score indicating double the performance.&#8221;</p>

<p>Scores:</p>

<ul>
<li><a href="http://browser.primatelabs.com/geekbench2/1713385">MacBook Air (13-inch Mid 2012)</a>: 7675</li>
<li><a href="http://browser.primatelabs.com/geekbench2/1545796">PowerBook G4 (12-inch 1.5 GHz)</a>: 861</li>
</ul>


<p><a href="#geekbench-notes-return">&#8617;</a></p>

<p><a name="geekbench-iphone-notes"></a>
<strong>2.</strong> Geekbench score for <a href="http://browser.primatelabs.com/ios-benchmarks">iPhone 4S</a>: 651 <a href="#geekbench-iphone-notes-return">&#8617;</a></p>

<p><a name="vm-notes"></a>
<strong>3.</strong> Of course, there&#8217;s some issues with this. Anything that was happening synchronously would probably failed, as well as anything that depends on a network connection in progress. But for the purposes of the thought experiment, let&#8217;s ignore those problems. <a href="#vm-notes-return">&#8617;</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Glass: You can't control the future]]></title>
    <link href="http://blog.mattgauger.com/blog/2013/03/02/google-glass-you-cant-control-the-future/"/>
    <updated>2013-03-02T15:09:00-06:00</updated>
    <id>http://blog.mattgauger.com/blog/2013/03/02/google-glass-you-cant-control-the-future</id>
    <content type="html"><![CDATA[<p>There&#8217;s been quite a bit of backlash surrounding the new Google Glass product. As someone who has wanted wearable computing for awhile, I&#8217;d like to talk about it a bit. My only real qualifications on this subject come from the fact that I&#8217;ve read a lot of scifi<sup><a href="#accelerando-note" name="accelerando-note-return">1</a></sup> and that I&#8217;m an open source developer that would like to build software for wearable computing that makes people&#8217;s lives better.</p>

<p>When I&#8217;m talking about wearable computing glasses in general rather than just the Google Glass product, I will call them smart glasses. There doesn&#8217;t seem to be a consistent name yet, and the phrase <a href="http://en.wikipedia.org/wiki/EyeTap">eyetap</a> only refers to a very specific type of smart glasses.</p>

<h2>The promise</h2>

<p>As Amber Case explains in this TED Talk, <a href="http://www.ted.com/talks/amber_case_we_are_all_cyborgs_now.html">we are all cyborgs now</a>. As soon as man started using tools, we were augmenting what evolution gave us to become something more. A cyborg. When you drive a car, you are a cyborg because your legs could not carry you that fast. Welcome to the future, human.</p>

<p>That progress marches on constantly, much faster than evolution could ever provide us with enhancements. Computers, the internet, and smartphones are some of the latest and greatest in the enhancements that we add to our bodies to be something more. We&#8217;re already using smartphones to constantly be connected to a wider world than just what we can see and hear in the room. We&#8217;re extending our brains by using things like Google Search and Wikipedia to find and remember far more than our meatbrains could do on their own. And we&#8217;re connected to others to a degree that no other form of communication has matched. When scifi authors write about this kind of brain enhanced by technology, they sometimes refer to it as the exocortex. I&#8217;d argue that we already have exocortexes: our digital selves, the software and websites we use, the tools like Twitter and Facebook that we communicate over, are all part of those exocortexes. Without them, we are less than the whole. And while not everyone feels it yet, I certainly feel a little limited when cut off from my exocortex.</p>

<p>The promise, then, of Google Glass is to constantly be connected to that information source and communications tools. Not to interrupt your daily life, but to simply be better integrated into it. Some people want to point out that Glass is going to be a distraction from &#8220;real life&#8221;, but your real life already includes these &#8220;distractions&#8221; to a degree that you&#8217;re probably not thinking about. How often do you check your email during your work day? Twitter? What apps do you use on your smartphone to find the next bar to go to or figure out a restaurant that everyone can eat at? Does using any of those constitute putting real life on hold while you spend some quality time with something fake? No, they&#8217;re just part of life.</p>

<h2>The buzz</h2>

<p>I was initially quite excited about Google Glass, because it is the first real promise of wearable computing for the masses at a price point that we will probably be able to afford. For nearly a year, the product has been announced but no real details have surfaced. With the announcement of the Google Glass Explorer contest, more information has been leaking out of the Googleplex. After the <a href="http://www.youtube.com/watch?v=9c6W4CCU9M4">Youtube video showing real Glass in use</a> was posted, I quickly realized that Google Glass was not intended for me in the way that I was hoping.</p>

<p>Simply put, Glass is going to do the things that consumers now want to do quickly with their smartphones: receive and send texts &amp; email, take pictures, take videos, and post that content up to things like Facebook, Youtube, and Google+. Another valid use is quickly searching Google for something, which could be useful for everything from trivia night to trying to remember what goes in your favorite korma.</p>

<p>But the things I&#8217;m interested in? Coding while walking around (twiddling fingers in the air, no doubt), augmenting my poor social skills by having my wearable remember faces and previous conversations, providing heads-up documentation while I am doing some task, reading full ebooks in a sitting with some sort of speed-reading app, etc. And some of these, like coding and reading, are quite focused activities that would benefit from having full-screen display of information rather than just a hovering box in the corner of one eye. Since the Glass only really shows notifications and thumbnails of photos and videos, it isn&#8217;t going to provide that focused experience. At least until Google or some other company builds binocular, full-vision smart glasses.</p>

<p>Then again, building a device that most consumers will want to use is exactly what Google should be doing. I&#8217;m a relatively tiny market, and it&#8217;d make no sense for Google to prioritize my features over the average consumer. I&#8217;m well aware of that. But all that said, I still plan on being an early-adopter, at least after the price drops a little.</p>

<h2>The marketing bullshit</h2>

<p>You may have heard that <a href="http://www.independent.co.uk/news/world/americas/google-cofounder-sergey-brin-feels-emasculated-by-smartphones-8514748.html">Sergey Brin said</a> that smartphones are &#8220;emasculating.&#8221; I&#8217;m not going to linger on this topic too long, but whether he thought this up on the fly or a marketing team came up with it, it makes him sound like an idiot. And in case you forgot, Google makes smartphones. Is it &#8220;emasculating&#8221; to open a refrigerator? What about when you ride the bus rather than drive a car in to work? What does this tell female smartphone users when you say this? I believe the correct usage of the word &#8220;emasculating&#8221; is to &#8220;deprive (a man) of his male role or identity. Ex: he feels emasculated because he cannot control his sons&#8217; behavior.&#8221; What does that have to do with a smartphone? It&#8217;s just a poor choice of words all around. Sorry Sergey, but I&#8217;m calling bullshit on your statement.</p>

<h2>The wearable device Cambrian explosion</h2>

<p>We can only hope that as soon as Google Glass comes out, two things start to happen: hackers figure out how to root (or jailbreak, or whatever we&#8217;re going to call it) Glass and install Linux on it. This will ensure that open source software can start being developed for it for all sorts of niche users (like me) and not just the average consumer mentioned above. It also will help to combat some of the security and privacy concerns outlined below. Maybe in the long run, Linux isn&#8217;t the best OS to run on such a device, but that doesn&#8217;t matter initially. As soon as open source hackers figure it out, anything and everything can run on it. We&#8217;ll see a Cambrian explosion of wearable computing apps.</p>

<p>I think we&#8217;ll also see hardware manufacturers, especially the OEMs that typically make keyboards, mice, and cheap Android phones, start to produce similar glasses to the Google Glass devices. They&#8217;ll likely run Android or some flavor of whatever Microsoft is calling a mobile OS, but will probably be a lot easier to hack than the Google Glass device. And they&#8217;ll get cheaper. The best part about all of this is that by leading the way, Google is practically ensuring that we&#8217;re going to have lots of manufacturers building these devices, and they&#8217;re going to get cheaper. The demand for wearable displays in the past were limited to applications in military and some industry jobs, along with academic research, and so wearable displays tended towards the expensive and impractical in the past. Eventually, smart glasses will probably be as common as smartphones, and around the same price point. Don&#8217;t be surprised if, in a few years, it makes a lot more sense for someone to wear smart glasses than to carry around a smartphone in their pocket.</p>

<p>By being first to market, Google is also giving us a good model for what interactions with smart glasses can look like. The early, proto-smartphones like the Blackberry were arguably very poor in terms of user experience &amp; interaction design. It wasn&#8217;t until the Apple iPhone came along that we started to get good UX on mobile devices. Now, even free, low-end Android phones come with some UX heritage imprinted from Apple&#8217;s iOS. While it remains to be seen whether Glass&#8217;s UX is great and not just as good as the Youtube video makes it out to be, I hope that it helps imprint some good UX concepts onto all future devices.</p>

<h2>The &#8220;dorky&#8221; backlash</h2>

<p>I&#8217;ve seen a few blogs, perhaps in an attempt to stir up trouble and get pageviews, call out Google Glass for being dorky. You&#8217;ll see phrases like &#8220;But why would anyone want to wear something so dorky?&#8221; The authors of these pieces of trying to enforce the status quo the same way that kids in school make fun of the clothes that others wear. Why are they doing that? They may have valid fears of the technology&#8217;s privacy implications. But more likely, they&#8217;re responding to what, in literature, we&#8217;d call &#8220;the fear of the other.&#8221; The Google Glass device is new and unknown. People who would break from the tribe and wear it are weird; possibly nonhuman. They are the other.</p>

<p>There&#8217;s a fear mentioned in some blog posts about Glass that someone might pay more attention to their Glass display than to the other person in a social situation. I imagine that the way it works out in reality is that common courtesy comes into play here, and that you wouldn&#8217;t ignore someone in favor of your glass any more than you&#8217;d walk away from someone you were talking to to look at Twitter on your phone. That said, some people have done that to me, and I expect that it is really just a fault of people rather than the technology.</p>

<p>Some of this backlash, too, is the fear that someone else with that easy access to information and search results (perhaps even more discreetly than the voice searching we&#8217;ve seen so far) is going to give others an unfair advantage. Suddenly everyone will remember everything and be experts on trivia, or last quarter&#8217;s financials, or any other things that smart glasses will make easy. But again, as I discussed before, this is all part of the wearer&#8217;s exocortex. It is as much as part of them as using a hammer or using a calendar on the wall to remember something.</p>

<p>By being a part of the cyborg human, the device is a prosthetic that the wearer uses to enable their exocortex. But rather than compensating for some handicap, it helps to enhance the wearer. Would you deny someone their hearing aids because they might be able to hear more than you? I think the feelings and popular opinion on these topics will change as more people start wearing smart glasses and other wearable technology. It&#8217;s already perfectly acceptable to use your smartphone to play Angry Birds while sitting in a waiting room, and I&#8217;m pretty sure that the activities that the Google Glass will lend itself to will soon become socially acceptable, too.</p>

<h2>The fear</h2>

<p>The biggest, and most valid in my mind, issue with Google Glass is what it will mean for everyone to suddenly have an always-on, always-available camera and microphone on their face. I&#8217;d suggest you go read Mark Hurst&#8217;s article on Creative Good, <a href="http://creativegood.com/blog/the-google-glass-feature-no-one-is-talking-about/">The Google Glass feature no one is talking about</a> if you haven&#8217;t yet, to get up to speed on this debate.</p>

<p>While I believe in privacy and support organizations like the <a href="https://eff.org">EFF</a>, I think it is a little short-sighted and silly to react so strongly to the fact that the Google Glass device will have a camera on it. The two fears outlined in that article are:</p>

<ul>
<li>That anyone, at any time, could be taking photos or video of you without your consent. And you wouldn&#8217;t know.</li>
<li>That Google will now be able to index and otherwise process any audio, video, and images you send to them, along with the other data the Glass will send along: date and time, Google user account, etc.</li>
</ul>


<p>This seems to happen with every technology. And you may not realize it, but if you are advocating against the Google Glass for the above reasons, then you have far more reasons to be vocal about banning smartphones and even cheap digital cameras. I think it&#8217;s easy for someone to exclaim &#8220;But they could be taking videos of me in a public place, possibly something embarrassing!&#8221; and not realize that there already exists a whole bunch of terrible usage of existing technology out there to exploit women by taking pictures and video of them without their consent. No one seems up in arms, marching to ban the cheap digital camera on behalf of exploited women. The same technology is used by parents to take pictures and videos of their kids. Here, the technology itself is not so much to blame as the people who would use it to exploit others.</p>

<p>There have been attempts to try and regulate digital cameras and smart phones in the past, usually to force them to emit some kind of loud shutter noise when a picture is taken or a video is started. But just about everything comes with a camera now; are you really going to regulate all of that? Part of my point here is that you can&#8217;t regulate the future and try to lock down technology, because the companies that want to sell you the technology will just find a way around it. Let&#8217;s be honest here, governments are too slow to out-maneuver technology.</p>

<p>The fact of the matter is that in public, you&#8217;re probably being monitored by far more than just someone&#8217;s glasses, and that&#8217;s far more worrying than worrying about this new technology that Google is building. Security cameras abound. Your movements online are tracked by any number of ISPs, advertisement platforms, and governments. Have you been up in arms all this time about that and only now adding Google Glass to the list of technologies to worry about? I&#8217;m just pointing out the absurdity of singling out Google Glass here.</p>

<p>Now, what about the fear that, simply put, you won&#8217;t know if someone with Google Glass glasses on could be taking a video and you wouldn&#8217;t know it? Isn&#8217;t that true that they could already be doing this every time you&#8217;re standing around someone with a smartphone in their hand? The fact is that the majority of people are probably going to be polite and follow the same kinds of social expectations you&#8217;d have around that. Just like you&#8217;re already doing whenever you take out your smartphone. Do people take videos of people on the bus because they think they&#8217;re funny? Sure, but that&#8217;s not the only use for a camera on a smartphone.</p>

<p>Lastly, there&#8217;s the concern that all of the data from Glass will be going into Google, to be indexed and searched, and could be subpoenaed by the government. This problem does not really point at the technology as the source of that concern. <strong>If you&#8217;re really worried about what kinds of things a corporation or government could do with all that information, especially a corrupt government, then the problem lies with the governments and corporations.</strong> You&#8217;ve been contributing to the constant stream of information into Google and Facebook&#8217;s datacenters for years. Twitter will give up your information to the government if pressured; yet we communicate over Twitter all of the time. The government has been installing taps into data exchanges for years to monitor online communications. So think about it. It might make a lot more sense for you to focus on fixing those organizations, or weakening their growing Big Brother powers, rather than chasing after perceived rights lost when someone wears a camera on their face in public.</p>

<p>Open source, again, provides a way out here: It&#8217;s likely that an open source OS like Linux will put more control about what information it leaks into the hands of users. At the same time, the open source software probably won&#8217;t see widespread usage by the average consumer, and so we should continue to question and call out this kind of abuse of information by corporations and governments. And, we can do what Mozilla is doing with <a href="http://www.mozilla.org/en-US/firefox/partners/">Firefox OS</a> and provide software that encodes some of our ideals about freedom and privacy right into the software, while making it attractive for manufacturers to use by making it free.</p>

<p>So don&#8217;t try to shout down a fledgling technology just because it could be used to limit your freedoms or privacy. Lots of technologies <em>could</em> be used to limit those things. You can&#8217;t regulate the technology, because cheap clones are on the way and a lot of people are going to want them. Instead, the real menace here is those that would use technology to limit your privacy. Those are what you should fear when you feel uneasy about the future. I&#8217;d like to see a lot more discussion on that topic, but the latest gadget fad pays the bills (with advertising, at least) better, I suppose. And I guess I&#8217;d like to see more writing on the <strong>potential</strong> of new technologies to improve the human condition and make us better cyborgs, rather than just whether or not it will be the killer Facebook app. But we can all dream, right?</p>

<hr />

<p><a name="accelerando-note"></a></p>

<p><strong>1</strong>: In particular, <a href="static/fiction/accelerando/accelerando.html">Accelerando</a> features a main character with smart glasses. It&#8217;s an interesting portrait of how a well-connected digital savant might use this wearable technology while still interacting with people and places.
<a href="#accelerando-note-return">&#8617;</a></p>
]]></content>
  </entry>
  
</feed>
