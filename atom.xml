<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Matt Gauger</title>
    <description></description>
    <link>http://blog.mattgauger.com/</link>
    <atom:link href="http://blog.mattgauger.com/atom.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 21 Nov 2017 19:01:48 -0600</pubDate>
    <lastBuildDate>Tue, 21 Nov 2017 19:01:48 -0600</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Elixir Code Quality Tools</title>
        <description>&lt;p&gt;My &lt;a href=&quot;/blog/2014/09/15/clojure-code-quality-tools/&quot;&gt;Clojure Code Quality Tools&lt;/a&gt; post remains one of the more popular articles on this blog. Since then, I’ve been writing a lot more Elixir code. I thought it’d be fun to write a similar post on what to use with the Elixir programming language.&lt;/p&gt;

&lt;p&gt;By default, Elixir will do a good job with pattern matching and unused functions warnings, as well as giving you deprecation warnings. But as you learn and progress in mastery of Elixir, you’ll want more feedback. That’s where code quality tools come in.&lt;/p&gt;

&lt;p&gt;As indicated in the original post, tools should help us follow best practices. The top issues I run into with Elixir code are checking my function signatures and pattern matching to ensure I’ve caught all cases, enforcing good style, and checking my code coverage. This post introduces 5 tools that are now a part of my Elixir workflow, depending on the project.&lt;/p&gt;

&lt;p&gt;This post will have less examples than the last, but you can refer to each project’s README to help you get started. Instead, I’ll cover why you might want to use each of these tools and what problems they solve.&lt;/p&gt;

&lt;h1 id=&quot;doctestshttpelixir-langorggetting-startedmix-otpdocs-tests-and-withhtmldoctests&quot;&gt;&lt;a href=&quot;http://elixir-lang.org/getting-started/mix-otp/docs-tests-and-with.html#doctests&quot;&gt;doctests&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;Built in to Elixir itself, doctests are a simple way to couple examples of useage where your function definition lives, in the source. They define an example call from an &lt;code&gt;iex&lt;/code&gt; prompt, and show what the return should be. When you set up a simple test file in the suite to run doctests, it will automatically check that the examples match the actual function call response. All it takes is a test file such as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;defmodule Alohomora.ResourceTest do
  use ExUnit.Case, async: true
  doctest Alohomora.Resource
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And to test functions with doctests in your &lt;code&gt;Alohomora.Resource&lt;/code&gt; namespace. Best of all, there’s nothing extra to add – these tests will run when you run &lt;code&gt;mix test&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;dialyxirhttpsgithubcomjeremyjhdialyxir&quot;&gt;&lt;a href=&quot;https://github.com/jeremyjh/dialyxir&quot;&gt;dialyxir&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;This library is actually a set of mix tasks on top of the popular Dialyzer tool for Erlang. Dialyzer, if you haven’t encountered it yet, is a DIscrepancy AnaLYZer for ERlang programs. That is to say, it finds dead code, type issues, and unnecessary tests. In my experience, it finds unreachable branches, and it finds tuple returns that aren’t matching a pattern where they’re used. These two seem to be the bulk of the things it finds for me, at least. It will also find functions that aren’t defined for the number of parameters you’re passing, but it seems to have issues with certain libraries I use – those libraries do in fact define functions with that signature.&lt;/p&gt;

&lt;p&gt;To really get the power of Dialyzer, you’ll to start &lt;a href=&quot;https://hexdocs.pm/elixir/typespecs.html&quot;&gt;including type specs&lt;/a&gt; in your source.&lt;/p&gt;

&lt;h1 id=&quot;dogmahttpsgithubcomlpildogma-and-credohttpsgithubcomrrrenecredo&quot;&gt;&lt;a href=&quot;https://github.com/lpil/dogma&quot;&gt;dogma&lt;/a&gt; and &lt;a href=&quot;https://github.com/rrrene/credo&quot;&gt;credo&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;Style guides help a team to write consistent code, more than they specify architecture patterns or idiomatic solutions. If you want to start applying a style guide to your Elixir code, look no further than dogma. As indicated on its README, “It’s highly configurable so you can adjust it to fit your style guide, but comes with a sane set of defaults so for most people it should just work out-of-the-box.” I’d recommend starting with its default style guide and seeing what it yells about.&lt;/p&gt;

&lt;p&gt;The kinds of things that dogma will tell you about are lines too long, trailing whitespace, and so on. You’ve probably seen similar output if you use a tool like &lt;code&gt;rubocop&lt;/code&gt; in Ruby.&lt;/p&gt;

&lt;p&gt;Credo has some overlap with dogma, but it does far more. This tool is more concerned with code smells. Some examples are checking function complexity, negated conditionals, and idiomatic ways to format your pipe operators and one-line functions. You can read up on the &lt;a href=&quot;https://github.com/rrrene/elixir-style-guide&quot;&gt;credo docs&lt;/a&gt; to understand everything it checks for.&lt;/p&gt;

&lt;p&gt;Ultimately, you may feel like you only need one or the other. For myself, I use credo with &lt;code&gt;mix credo --strict&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;excoverallshttpsgithubcomparrotyexcoveralls&quot;&gt;&lt;a href=&quot;https://github.com/parroty/excoveralls&quot;&gt;ExCoveralls&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;Code coverage in your tests is an important metric to keep track of. While striving for 100% code coverage isn’t always worth it, it is good to know whether you’re exercising the code you think you are, and ensuring that all edge cases and error cases that you coded for have been checked with a test.&lt;/p&gt;

&lt;p&gt;Installing ExCoveralls in your project will allow you to print out your code coverage for each module to the shell, as HTML, or to post the code coverage to Coveralls.io. ExCoveralls also supports being run from a few different CI tools including CircleCI, Semaphore, and Travis. If you don’t need all this, you could look into &lt;a href=&quot;https://github.com/mrinalwadhwa/excov&quot;&gt;ExCov&lt;/a&gt; or simply run &lt;code&gt;mix test --cover&lt;/code&gt; – although I find this built-in mix task’s output to be the least useful.&lt;/p&gt;

&lt;h1 id=&quot;the-erlang-observer-gui&quot;&gt;The Erlang observer GUI&lt;/h1&gt;

&lt;p&gt;This one is built in, simply launch it from your `iex terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iex&amp;gt; :observer.start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And it will launch a GUI tool. The GUI has charts of memory and processing done, as well as a graph of application supervisor trees. Honestly, there’s a lot more in this tool than I’ve had time to explore and learn about.&lt;/p&gt;

&lt;h1 id=&quot;mix-profilefprof&quot;&gt;&lt;code&gt;mix profile.fprof&lt;/code&gt;&lt;/h1&gt;

&lt;p&gt;This is another built-in tool that you can use. Profiling might not be the first tool you need when developing, but when you want to understand and trace what your code is doing, the &lt;code&gt;fprof&lt;/code&gt; tool’s output can be incredibly handy. Make sure you run this with &lt;code&gt;MIX_ENV=prod&lt;/code&gt; when you use this. It is also possible to &lt;a href=&quot;https://selfamusementpark.com/profiling-a-slow-elixir-test&quot;&gt;wrap fprof to profile slow test cases&lt;/a&gt;, which I have found useful in the past. There’s other libraries that you can install for profiling and tracing Elixir, but so far, &lt;code&gt;mix profile.fprof&lt;/code&gt; has worked well enough for me.&lt;/p&gt;

&lt;h1 id=&quot;final-thoughts&quot;&gt;Final Thoughts&lt;/h1&gt;

&lt;p&gt;This post was 5 tools for your Elixir workflow. If you’ve been working in Elixir for awhile, you may be already using them. And there’s probably more tools that I don’t know about, out there.&lt;/p&gt;

&lt;p&gt;Let me know if you found this blog post useful, or if you have any other tools to recommend!&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Nov 2017 00:00:00 -0600</pubDate>
        <link>http://blog.mattgauger.com/2017/11/21/elixir-code-quality-tools/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2017/11/21/elixir-code-quality-tools/</guid>
        
        
      </item>
    
      <item>
        <title>A new look</title>
        <description>&lt;p&gt;You might notice that this looks a little different. I’ve switched to a much more modern, cleaner theme for my blog. I’ve also redirected all of the old &lt;code&gt;/blog/&lt;/code&gt; subpaths to their new locations (Sadly, it seems GitHub pages does not support permanent redirects with any sort of config file, so the redirects are all in JavaScript.)&lt;/p&gt;

&lt;p&gt;Let me know if you notice anything that seems wrong. &lt;a href=&quot;mailto:contact@mattgauger.com&quot;&gt;contact@mattgauger.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And if you’re curious what this site looked like before the redesign, here’s some screen shots:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/old-theme-homepage.png&quot;&gt;&lt;img src=&quot;/images/old-theme-homepage.png&quot; alt=&quot;Old theme home page&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/images/old-theme-archives.png&quot;&gt;&lt;img src=&quot;/images/old-theme-archives.png&quot; alt=&quot;Old theme archives&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 24 Oct 2017 10:48:00 -0500</pubDate>
        <link>http://blog.mattgauger.com/2017/10/24/a-new-look/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2017/10/24/a-new-look/</guid>
        
        
      </item>
    
      <item>
        <title>Why build intelligence augmentation tools?</title>
        <description>&lt;p&gt;In a &lt;a href=&quot;http://blog.mattgauger.com/blog/2014/01/12/a-theory-of-compound-intelligence-gain/&quot;&gt;past blog post&lt;/a&gt; I talked about the concept of &lt;em&gt;intelligence augmentation&lt;/em&gt;. The idea of building software to augment intelligence has been around for some time. That post covers its history more than this one will.&lt;/p&gt;

&lt;p&gt;I’ve noticed that software developers I know (myself included) will have a thought: Imagine a tool that would allow flexible note-taking, archive and index their documents and email, and enable hyperlinking to any content in that index. This tool would have some sort of AI agent architecture on top of it that would offer improved searching, find related content automatically, and otherwise assist you in thinking and researching. Variations on this tool might include improved filtering of incoming information, or improving their own ability to learn new things.&lt;/p&gt;

&lt;p&gt;Such thoughts tend to lead people to start designing architectures and picking programming languages to implement it in. Or they might start designing a UI. Or they fall down the rabbit hole of knowledge systems, machine learning, and natural language processing.&lt;/p&gt;

&lt;p&gt;Indeed, such a note-capturing system is the &lt;a href=&quot;http://www.loper-os.org/?p=8&quot;&gt;source of inspiration for loper-os&lt;/a&gt;, a more-perfect Lisp machine project envisioned and taken up by Stanislav Datskovskiy. (Although he is still working on the hardware on which to write loper-os and thus run his thought-capturing system. Again, rabbit holes.)&lt;/p&gt;

&lt;p&gt;I’ve had discussions with at least a dozen other people about how they would build such a virtual assistant. Clearly, there’s some tooling lacking here that a lot of people have thought about and feel a need for.&lt;/p&gt;

&lt;p&gt;Why is building a virtual assistant such a tempting thought for software developers? It’s likely because they experience technology as constant change. Their work and communication revolves around technology.&lt;/p&gt;

&lt;p&gt;The tools and services we use now (read: Twitter, Facebook, email, and so on) only compound the &lt;a href=&quot;https://en.wikipedia.org/wiki/Information_overload&quot;&gt;information overload&lt;/a&gt; that occurs when you try to stay up to date with your email and your calendar. Or when you try to stay up to date with everyone on social media. Suffice to say, the people who use technology the most may feel this pain the greatest.&lt;/p&gt;

&lt;p&gt;Let’s take a step back and think about why we would want to augment our own intelligence. And in particular, I’m going to focus on building software here. We could also have discussions around using smart drugs (nootropics), or of using genetics and medicine. Or we might discuss building hardware such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Brainport&quot;&gt;brainports&lt;/a&gt; or &lt;a href=&quot;https://www.youtube.com/watch?v=ZrGPuUQsDjo&quot;&gt;Elon Musk’s neural lace&lt;/a&gt;, but those are out of scope for this article and for my expertise. Software I know.&lt;/p&gt;

&lt;p&gt;In 1997, Garry Kasparov lost to Deep Blue at chess. This was the first case of a computer defeating a world champion. After this point, advances in computing power meant that off-the-shelf chess software running on a modern laptop can play as well as Deep Blue. Since the search space of chess is now in the CPU’s reach, no human can hope to beat the best computer at chess again.&lt;/p&gt;

&lt;p&gt;Yet, Kasparov noticed something. If you combine software with a human player, and let the human use the computer software to explore the results of a particular move before making it, that team plays better than man or computer alone. They call these man-machine hybrids “centaurs.” Kasparov called this game &lt;a href=&quot;https://en.wikipedia.org/wiki/Advanced_Chess&quot;&gt;Advanced Chess&lt;/a&gt;, and an offshoot called freestyle chess has emerged with teams of humans and computers on each side.&lt;/p&gt;

&lt;p&gt;To bring it back to our terminology, a centaur composed of a human operating a computer is an &lt;em&gt;augmented human&lt;/em&gt;. The chess software is an intelligence augmentation tool. Now, chess and its rules are not something as complex as writing a more compelling document or pulling together disparate academic papers and original research into one new thesis. We do not yet have the tools to enable a regular researcher to become a super-researcher simply by giving them software to consult.&lt;/p&gt;

&lt;p&gt;The complexity of problems that we need to solve is ever-increasing. This was the main reason that &lt;a href=&quot;http://www.dougengelbart.org/pubs/augment-3906.html&quot;&gt;Engelbart cited&lt;/a&gt; in 1962 for exploring augmenting human intellect:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Man’s population and gross product are increasing at a considerable rate, but the complexity of his problems grows still faster, and the urgency with which solutions must be found becomes steadily greater in response to the increased rate of activity and the increasingly global nature of that activity. Augmenting man’s intellect, in the sense defined above, would warrant full pursuit by an enlightened society if there could be shown a reasonable approach and some plausible benefits.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The benefits to be able to create a super-researcher or super-productive professional should be obvious. There are likely aspects of your job or your hobbies that you can imagine aided by better software.&lt;/p&gt;

&lt;p&gt;In particular, when we augment the brain, we will look at it like another piece of technology:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;improving short and long term memory recall (storage)&lt;/li&gt;
  &lt;li&gt;improving the number of different ideas we can hold in our heads at once (RAM)&lt;/li&gt;
  &lt;li&gt;improving the speed, focus, and association-making aspects of our thinking (CPU)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What kinds of features might we want to see in these tools? A possible, but not exhaustive, list might include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;filtering the noise of your email inbox, news sources (and fake news), social media, and more&lt;/li&gt;
  &lt;li&gt;proactively providing related content and automatically categorizing content&lt;/li&gt;
  &lt;li&gt;visualizing and summarizing information so that you can work with it more effectively&lt;/li&gt;
  &lt;li&gt;helping us to remember everything we’ve ever seen, heard, or said in the real world&lt;/li&gt;
  &lt;li&gt;helping us remember names and otherwise augment our social ability&lt;/li&gt;
  &lt;li&gt;optimizing our time, schedule, and work load (as SRI’s CALO focused on)&lt;/li&gt;
  &lt;li&gt;optimizing our health (as an outgrowth of the &lt;a href=&quot;http://quantifiedself.com/&quot;&gt;quantified self&lt;/a&gt; movement)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So we, as software developers and &lt;a href=&quot;http://blog.mattgauger.com/blog/2017/03/12/mining-for-computation-on-the-beach/&quot;&gt;tool-makers&lt;/a&gt;, see a need and want to build tools. We know what kinds of tools we might create. But why else might we, as humans, want to build these tools?&lt;/p&gt;

&lt;h2 id=&quot;productivity&quot;&gt;Productivity&lt;/h2&gt;

&lt;p&gt;If we extrapolate from the Advanced Chess centaurs, then augmented humans will be better than unaugmented workers. In some cases, augmented humans will be able to get more work done than AI/ML tools. In a time when automation continues to threaten our jobs, we might yet find meaningful work for a longer period of time if we can join with machine learning technologies to become augmented humans. In the short term, being more productive is more likely to earn you raises and advancement. You may have better choices about what to work on, or how you work with it.&lt;/p&gt;

&lt;p&gt;A worker becomes more valuable as their ability to solve more problems and get more done increases. A more productive work force can help us to have a healthier economy and to smooth the transition to a fully-automated world. Once we reach that level of automation, we can hope to find post-scarcity, an end of wage labor, and the ability to fill our time with leisure.&lt;/p&gt;

&lt;p&gt;The downsides to augmenting for productivity are that if there are some barriers to entry here, such as cost, then only the rich can afford such tools. The average worker still won’t benefit from expensive productivity improvements. Worse, we may not even see any benefit for those that weren’t working in professional roles now. Those with jobs threatened by automation – truck drivers, factory workers, and so on – may be hardest hit by expensive or unavailable augmentation tools. We should focus on helping those workers train for their next career, and help those entering the workforce keep up.&lt;/p&gt;

&lt;h2 id=&quot;education-and-better-learning&quot;&gt;Education and better learning&lt;/h2&gt;

&lt;p&gt;The education system cannot move fast enough for the rapid pace of change. Those applying to college now should be looking at what jobs will be available in 5 years when they choose a major. Jobs that may become automated in that time makes those jobs a bad decision. But the existing college system does not tell students to avoid jobs that may soon be irrelevant.&lt;/p&gt;

&lt;p&gt;If you are likely to change careers in your lifetime, does it make sense to pursue a particular degree? (At least, in cases where it is not required for certification/practice, such as law or medicine.) Or should you optimize for a lifetime of learning?&lt;/p&gt;

&lt;p&gt;The cost of higher education is high, and most students take on loans to complete their degrees. Is this cost worth it? Do they learn enough in a degree to pay back the loans later? Do they retain enough information from that learning period to later use it in their job?&lt;/p&gt;

&lt;p&gt;And if technology is moving so fast that colleges can’t keep up, will workers be able to juggle learning new advances while working full time?&lt;/p&gt;

&lt;p&gt;We need software that accelerates learning and increases retention. More learning in shorter periods of time can help students – and workers in the workforce – to keep up. Better retention means better job performance and success.&lt;/p&gt;

&lt;p&gt;There’s been a lot of research into learning on multiple fronts. I recommend the book &lt;a href=&quot;https://www.goodreads.com/book/show/18693655-a-mind-for-numbers&quot;&gt;A Mind for Numbers&lt;/a&gt; and its related MOOC &lt;a href=&quot;https://www.coursera.org/learn/learning-how-to-learn&quot;&gt;Learning How to Learn&lt;/a&gt; to find out more about this topic and how to put that research into practice.&lt;/p&gt;

&lt;p&gt;There are a long list of startups now offering online courses, nano-degrees, and certificates of study. Khan Academy presents videos for elementary school studies through graduate admissions tests. But putting a class online as a screencast does not turn these courses into an intelligence augmentation tool.&lt;/p&gt;

&lt;p&gt;There’s the entire internet and all of Wikipedia available whenever we use a search engine. Ebooks give us access to a shelf of books without needing an expensive and wasteful physical copy. (Especially when it comes to textbooks.) There’s note-taking applications and word processors with spell-checkers. There’s flashcard apps, such as SuperMemo, that use a &lt;a href=&quot;https://en.wikipedia.org/wiki/Spaced_repetition&quot;&gt;spaced repetition&lt;/a&gt; to help with memorization and language learning. So why aren’t these enough to enable people to learn better?&lt;/p&gt;

&lt;p&gt;The difference between existing tools and what we need from educational augmentation tools is personalization to the learner and optimizing the learning. These existing tools are inert and require the learner to expend all of the energy and thinking to use the tool. Intelligence augmentation tools could be proactive learning tools that can do more than  provide the content to learn. They could actually bring the right content to the user at the right time (as in spaced repetition). They could structure the learning to the individual, rather than the current method of teaching to the widest range of students. They could let the learner explore at their own pace and go off on tangents of learning to related topics. Last, these tools would keep track of the current level of learning and track mastery of each topic.&lt;/p&gt;

&lt;p&gt;All of these features are lacking in current tools. The area seems ripe for change and improvement.&lt;/p&gt;

&lt;h2 id=&quot;more-free-time&quot;&gt;More free time&lt;/h2&gt;

&lt;p&gt;Increased productivity gives us more benefits than getting more done at work. We should have the ability to work less if we are more productive. This could free up more time for leisure, hobbies, entertainment, and further higher education goals.&lt;/p&gt;

&lt;p&gt;Since there’s an association (at least in the USA) between labor and success in life, it might be hard to convince ourselves that working less per week is a positive. Yet, I see the rise of full-time travelers, many of whom work as contractors for less than 40 hours per week, as an sign that this will become socially acceptable. These digital nomads might have the most success with intelligence augmentation tools and the work of the future (as &lt;a href=&quot;http://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html&quot;&gt;Charles Stross’s Manfred Macx&lt;/a&gt; did.)&lt;/p&gt;

&lt;p&gt;As we approach a post-scarce society (and hopefully we do), work for pay will have less importance. Being able to spend time with friends and family, be entertained, and pursue intellectual interests will all become more acceptable ways to spend our time.&lt;/p&gt;

&lt;h2 id=&quot;solving-complex-problems&quot;&gt;Solving complex problems&lt;/h2&gt;

&lt;p&gt;As noted by Engelbart, our world is increasingly complex. One way that academia has dealt with this is increasing specialization. A PhD may only have a deep expertise on a narrow subject. Outside of academia, we have the forces of globalization and technological progress to contend with. Narrow specialization may not always work. Our world changes rapidly and has difficult multi-disciplinary problems to solve. Global warming, food, clean water, and eradicating disease are all tough problems. How can we go about solving them?&lt;/p&gt;

&lt;p&gt;In the space of all the possible intelligences, imagine intelligence drawn on a curve. On the top of that scale is the most intelligent human (Einstein, Newton, or any other that you wish.) The rest of us are somewhere in the middle of the scale, and on the lower end of the scale, animals. Of course, the graph goes much farther up and to the right than the smartest human so far. We just haven’t seen those intelligences yet.&lt;/p&gt;

&lt;p&gt;In that space of possible minds, there exists a new category. The augmented humans, or centaurs, have their own range of intelligences. Augmentation could allow regular humans reach a range that includes Einstein-level intelligence. For specific topics or skills, centaurs could rank much farther up the curve than the smartest humans. We’ve already seen this with Freestyle Chess: the best human chess players, unaugmented, are no match for a team of computers and humans working together. Augmented humans with good software will be able to surpass the smartest natural humans in multiple aspects, and we can give that augmentation software to far more people.&lt;/p&gt;

&lt;p&gt;Intelligence augmentation tools won’t just let us do more work faster, then, but unlock the ability to understand and solve problems that we previously could not. This will power new forms of technology and science well beyond what we’ve accomplished today.&lt;/p&gt;

&lt;h2 id=&quot;in-conclusion&quot;&gt;In conclusion&lt;/h2&gt;

&lt;p&gt;I’m excited to be thinking about and writing about these topics again. There’s potential to start building some of these tools today. In particular, to build personalized tools as experiments. These early tools will be like the tracking done by the quantified self movement: separate data points from individuals with little overlap. But cross-pollination of ideas and techniques will be possible. Conversations around these experiments will be important to develop the technology further.&lt;/p&gt;

&lt;p&gt;From these personal experiments, we can learn to build generic tools for everybody. Those generic solutions will allow the creation of freely-available software. Open source should help with concerns around access only being available to the wealthy and the privileged.&lt;/p&gt;

&lt;p&gt;We’ll still be on our own to deal with the ethics involved in augmentation, which I did not touch on in this article.&lt;/p&gt;

&lt;p&gt;If you find these topics interesting and would like to discuss them, I invite you to join me over on the new &lt;a href=&quot;https://intaug.org&quot;&gt;Intelligence Augmentation BBS&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Apr 2017 10:48:00 -0500</pubDate>
        <link>http://blog.mattgauger.com/2017/04/10/why-build-intelligence-augmentation-tools/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2017/04/10/why-build-intelligence-augmentation-tools/</guid>
        
        
      </item>
    
      <item>
        <title>My current setup: Habits tracking</title>
        <description>&lt;p&gt;In the past, &lt;a href=&quot;/blog/2013/12/28/an-unscientific-study-in-behavior-change-with-software/&quot;&gt;I blogged about&lt;/a&gt; how I used Lift.do (now &lt;a href=&quot;https://www.coach.me&quot;&gt;coach.me&lt;/a&gt;) to prompt for habit-forming. Learning how to form new habits is one of the key tools to focusing on your growth and the ability learn more. You might recall from that previous post that I refer to the &lt;a href=&quot;http://www.foggmethod.com/&quot;&gt;Fogg method&lt;/a&gt; for behavior change. The three steps are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Select the right target behavior.&lt;/li&gt;
  &lt;li&gt;Make the target behavior easy to do.&lt;/li&gt;
  &lt;li&gt;Ensure a trigger will prompt the behavior.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So why did I stop using Lift.do? In short, because Reminders.app for iOS and MacOS got better.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/reminders_app_example.png&quot; alt=&quot;Reminders.app example&quot; style=&quot;display: block; margin: 0 auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You may recall that Lift.do emailed me every morning a reminder for one habit I was trying to form: take a Vitamin D.&lt;/p&gt;

&lt;p&gt;It’s possible that I could have had Lift.do email about other habits at different times. It could have sent me a digest email of all my habits for the day, each morning. But, sending more emails would quickly overwhelm my inbox and help turn it into the dreaded TODO list.&lt;/p&gt;

&lt;p&gt;The prompt or trigger to perform a habit should happen as close to the right moment as possible. With recurring reminders in Reminders.app, I now get notifications for each habit. I can easily tweak the schedule to fit where I think the habit will best fit in.&lt;/p&gt;

&lt;p&gt;The notifications show on both my laptop and phone, and I usually have my phone on me at all times. My phone can bug me wherever I am, because I have my phone with me. Completing a task on my phone or my laptop syncs to the other device thanks to iCloud.&lt;/p&gt;

&lt;p&gt;As a result, I’m no longer just tracking the one Vitamin D habit. (In fact, I don’t track Vitamin D at all anymore. It has become a real habit and doesn’t need a prompt every morning.) I track 14 habits that happen daily, and an additional 3 that happen every other day or on a custom schedule.&lt;/p&gt;

&lt;p&gt;The ease of these tasks varies. Some of them I would do anyways or have already formed habits around. Having the record makes it easier to remember whether I really did them 8 hours later.&lt;/p&gt;

&lt;p&gt;Some of these tasks are harder or take more motivation to do each day. I have habits that I’m forming as part long-term learning goals. The easiness of these goals comes having broken it down to tasks that I absolutely can do every day. There’s power in having small amounts of consistent progress every day.&lt;/p&gt;

&lt;p&gt;I’d recommend that you think about setting the goal for a new habit to the smallest thing you could do every day. For example: practice for just 5 minutes. Allow yourself to take more time if you have it. If you get to the end of the day, and you’re being honest with yourself, can you fit in 5 minutes of practice before turning in? You will make a lot of progress this way.&lt;/p&gt;

&lt;h2 id=&quot;what-am-i-lacking-with-this-setup&quot;&gt;What am I lacking with this setup?&lt;/h2&gt;

&lt;p&gt;Reminders.app doesn’t really track of the history of checked-off items. It only knows whether I missed a deadline (and how long ago that was) and what’s due today. Items checked off yesterday wait until they’re due today, and then notify me. I don’t have Lift.do’s graphs or &lt;a href=&quot;http://lifehacker.com/281626/jerry-seinfelds-productivity-secret&quot;&gt;Seinfield’s “streaks calendar”&lt;/a&gt;. But this seems ok. I have a general idea of how well I’ve been doing lately. For longer-term goals, like fitness, I use other apps that have their own “streaks calendar.”&lt;/p&gt;

&lt;p&gt;Despite saying in &lt;a href=&quot;/blog/2013/12/28/an-unscientific-study-in-behavior-change-with-software/&quot;&gt;my previous post on habits&lt;/a&gt; that I’ve found progress bars and charts to be motivating, I don’t find that I need those now. Having a list in Reminders.app and knowing whether I’ve done today’s items is enough.&lt;/p&gt;

&lt;p&gt;A protip is that you can view all of your scheduled reminders in Reminders.app in a separate list called Scheduled. I keep this list up in Reminders.app most of the time, and use a separate list as a more general/on-the-fly TODO list. I tend to use Emacs’ excellent &lt;a href=&quot;http://orgmode.org/&quot;&gt;Org mode&lt;/a&gt; for my real TODO lists, among many other things. (Org mode does a lot. You should check it out!)&lt;/p&gt;

&lt;h2 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h2&gt;

&lt;p&gt;This approach triggers habits much more consistently and improves the likelihood that I can get through so many small tasks in a given day. It doesn’t require additional software or notebooks in my process. For something as simple as habit-tracking, I’m not too worried that I’m locked to an Apple app on Apple hardware. This list could be move to something else with little efort, but convenience wins right now.&lt;/p&gt;

&lt;p&gt;Overall, this process works for me. And that might be the most important point.&lt;/p&gt;
</description>
        <pubDate>Mon, 27 Mar 2017 17:53:00 -0500</pubDate>
        <link>http://blog.mattgauger.com/2017/03/27/my-current-setup-habits-tracking/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2017/03/27/my-current-setup-habits-tracking/</guid>
        
        
      </item>
    
      <item>
        <title>Mining for computation on the beach</title>
        <description>&lt;p&gt;The introduction to &lt;a href=&quot;https://www.goodreads.com/book/show/1639039.Writing_GNU_Emacs_Extensions&quot;&gt;Writing GNU Emacs Extensions&lt;/a&gt; introduces Emacs by talking about plumbers. “Plumbers?” you might think. The thing it wants us to think about is whether plumbers make their own tools.&lt;/p&gt;

&lt;p&gt;Plumbers buy pipes and fittings in standardized sizes. They depend on the &lt;a href=&quot;https://en.wikipedia.org/wiki/International_Building_Code&quot;&gt;International Building Code&lt;/a&gt; and local building codes to tell them what is safe and necessary. They use tools made for the tasks they’ll likely need to do. As the book says, “a plumber doesn’t tinker with his wrench.”&lt;/p&gt;

&lt;p&gt;I imagine that there are plumbers do build their own little jigs to hold pipes together, or to trace a pattern before cutting a hole. These solutions come from experience from past work and knowing the current problem. The book might fall a little flat here – plumbers can solve problems by making things. But what about their standard tools?&lt;/p&gt;

&lt;p&gt;Again, from the book, “the plumber would tinker with their tools, if they knew how.”&lt;/p&gt;

&lt;p&gt;Are most plumbers like the programmer that uses Emacs? Likely not. Because, the book says, Emacs is a tool that programmers can use to build tools. Emacs is a kind of &lt;a href=&quot;https://en.wikipedia.org/wiki/Ouroboros&quot;&gt;ouroboros&lt;/a&gt;: software that builds software, software that can change itself.&lt;/p&gt;

&lt;p&gt;A better example of makers making tools is the machinist in their machine shop. Machinists make jigs and holders all the time. And they must, or they’d never be able to clamp an odd-shaped piece to work on it. But the abilities of machinist goes beyond jigs and holders.&lt;/p&gt;

&lt;p&gt;The tools in a machine shop are sufficient to create more tools. With a lathe and a vertical mill, one could create the hard parts of any of the machine tools in the shop. Granted, most machinists would not consider creating another vertical mill from scratch. The labor involved would suggest that one should buy one from a manufacturer. A manufacturer builds tools at scale. Such tools come at a reasonable cost relative to the labor to create a mill yourself. But the ability of a machinist to recreate everything from scratch is there, if need be.&lt;/p&gt;

&lt;p&gt;Software is much cheaper to build. The ease of modifying Emacs causes people to build all sorts of tools with it. Those tools go beyond editing of source files. There’s IRC clients, web browsers, and more. There’s even a system called &lt;a href=&quot;https://www.emacswiki.org/emacs/TrampMode&quot;&gt;TRAMP&lt;/a&gt; that allows you to edit a file over FTP, SFTP, NTFS, and more. TRAMP makes them all appear to be a local buffer in Emacs.&lt;/p&gt;

&lt;p&gt;If the machinist wanted to recreate their machine shop from scratch, what kind of reference would they need for that?&lt;/p&gt;

&lt;p&gt;There exists a shelf full of books that sets out to create a machine shop from scratch – the &lt;a href=&quot;http://gingerybookstore.com/&quot;&gt;Gingery books series ‘Build Your Own Metal Working Shop From Scrap’&lt;/a&gt;. These colorful books haunt the book cases of Makerspaces and home shops. The first book starts with sand on the beach and charcoal made from trees inland. With this start, you can cast aluminum and zinc parts. Take some scrap with some common parts and the second book will teach you how to make a metal lathe. This continues for seven books, until you have built your own home machine shop from scrap and sand on the beach. With these books, you are able to build more tools and replace anything worn out or broken.&lt;/p&gt;

&lt;p&gt;Having these books on your shelf might be interesting if you like to make physical things. Owning them might be part of your expanded understanding of how the world works.&lt;/p&gt;

&lt;p&gt;And of course, these books might be a good idea to have on your shelf for any zombie apocalypse that might befall us.  (Whether you’ll need a machine shop in the apocalypse is a worthwhile question. Antibiotics and growing food might be more important. As an aside, what other references would we want on our shelf to recreate civilization?)&lt;/p&gt;

&lt;p&gt;For computation, there are several books that set out to teach from the level of “sand on the beach.” What might that look like?&lt;/p&gt;

&lt;p&gt;Start with relays, simple electromagnetic switches. A relay can only be on or off. The binary state means that we can represent numbers by counting in binary. We can treat on or off like true and false. With enough switches, we can create logic gates for all the types of logic operations. Then, we can combine these gates into more complex mechanisms like adders or a full 8-bit CPU. Lastly, we can begin to understand how the instruction set works in a CPU to create software. That’s the approach in &lt;a href=&quot;https://www.goodreads.com/book/show/13020367-code&quot;&gt;Code: The Hidden Language of Computer Hardware and Software&lt;/a&gt;. I recommend this book highly. The difficulty curve of each chapter is just right to keep you engaged through the whole book. I only wish I’d read it a decade earlier!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://nand2tetris.org/&quot;&gt;Nand2Tetris&lt;/a&gt; is a free book and online course. This approach uses hardware emulation rather than relays as a building block. The book starts with basic gates and works up to a “general-purpose computer system.” Or rather, something we can build a Tetris clone on. Following along in the hardware emulation software is a good way to grok the details. Hardware emulation avoids most of the frustrations of my undergraduate digital logic course. Namely, having to build a test harness to ensure the quad NAND gates weren’t faulty.&lt;/p&gt;

&lt;p&gt;Computer science is about the theory of computation. If you’d like to learn about that, then &lt;a href=&quot;https://www.goodreads.com/book/show/15842786-understanding-computation&quot;&gt;Understanding Computation&lt;/a&gt; by Tom Stuart is next on the list. This book uses Ruby, which makes it more approachable than more academic books. This book helps to fill in some of the gaps in my understanding from a career in mostly-web programming.&lt;/p&gt;

&lt;p&gt;That covers the hardware and the computational theory that goes into programming. But what about programming itself? What if we wanted to start with the basics of programming? To answer this, we’d want books that teach us to how go from assembly to something higher-level. We’d want to know how what issues one might face when stepping up a level from machine code.&lt;/p&gt;

&lt;p&gt;I’m afraid I don’t have much to suggest beyond the classics on programming here. Stick with favorites like &lt;a href=&quot;https://www.goodreads.com/book/show/515601.The_C_Programming_Language&quot;&gt;The C Programming Language&lt;/a&gt; by Kernighan and Ritchie, and you can’t go wrong.&lt;/p&gt;

&lt;p&gt;If you want an alternative world view on solving problems, read &lt;a href=&quot;https://www.goodreads.com/book/show/23165738-programming-a-problem-oriented-language&quot;&gt;Programming A Problem Oriented Language: Forth - how the internals work&lt;/a&gt; by Charles H. Moore and wrap your head around Forth.&lt;/p&gt;

&lt;p&gt;Another book in this vein might be &lt;a href=&quot;http://www.buildyourownlisp.com/&quot;&gt;Build Your Own Lisp&lt;/a&gt; if you’ve never completed such a feat. Or look to &lt;a href=&quot;https://github.com/kanaka/mal&quot;&gt;mal&lt;/a&gt; and its wealth of implementations to understand how to build a Lisp. Implementing lambda calculus interpreters and Lisp-like languages is a good pastime, and one that I’d like to practice more.&lt;/p&gt;

&lt;p&gt;At the level of operating systems, we find more valuable resources. &lt;a href=&quot;https://www.goodreads.com/book/show/337375.Lions_Commentary_on_UNIX&quot;&gt;Lions’ Commentary on UNIX&lt;/a&gt; provides the UNIX source code with commentary. Suppressed by AT&amp;amp;T long ago for revealing their trade secrets, it’s now easy to get a copy of on Amazon.&lt;/p&gt;

&lt;p&gt;Imagine starting from scratch and creating an operating system. And, creating a language to go with that operating system. That’s the path taken in &lt;a href=&quot;https://www.goodreads.com/book/show/116985.Project_Oberon&quot;&gt;Project Oberon&lt;/a&gt; by Niklaus Wirth. This book will help you to think about different facets of a problem and how to solve it from all sides. You might want to abandon what you take for granted in computing. It’s an alternative-computing rabbit hole that will make you wonder why current computing is so mundane. (This, along with learning about Lisp machines, might make you interested in reinventing the wheel. Fair warning.)&lt;/p&gt;

&lt;p&gt;At this point, we’re diverging from covering the basics and into realms that I enjoy thinking about. If you’ve come this far and you really must push your understanding past traditional Turing machines, then I have one book to recommend to you. It’s much more expensive than when I bought it, and is only available used. &lt;a href=&quot;https://www.goodreads.com/book/show/6033620-the-architecture-of-symbolic-computers&quot;&gt;The Architecture of Symbolic Computers&lt;/a&gt; by Kogge is a tome on symbolic and logical computing. If you’ve taken the rabbit hole of Oberon and have made time to learn about Lisp machines, this book is a real treat. Symbolic and logic computing are part of a complete understanding of computation.&lt;/p&gt;

&lt;p&gt;Stepping back from our tangent, you might ask, “What does this all have to do with Emacs?” Well, I’d put &lt;a href=&quot;https://www.goodreads.com/book/show/1639039.Writing_GNU_Emacs_Extensions&quot;&gt;Writing GNU Emacs Extensions&lt;/a&gt; on the list, as the book about building tools. It won’t cover the other tools you’ll likely need in computing: how to build a compiler, how to write Makefiles, and so on. But if you want to build tools, it is good to have a deep understanding of a tool for building tools. Emacs is a good platform to tinker, and it can be that workshop from which your other tools emerge. Learning Emacs, and how to build things in Emacs, has been rewarding to me and my time invested.&lt;/p&gt;

&lt;p&gt;Even now, hackers are rebuilding Emacs in Rust with a project called &lt;a href=&quot;https://github.com/Wilfred/remacs&quot;&gt;remacs&lt;/a&gt;. The ouroboros Emacs is helping to rebuild itself in a new language.&lt;/p&gt;

&lt;p&gt;You need to know your tools, and know where they came from, to know them well. This list is a good start on a deep knowledge of computing. Books help us to understand what came before, and to think about where we can go.&lt;/p&gt;

&lt;p&gt;I’ve set up an &lt;a href=&quot;https://www.goodreads.com/review/list/2450080-mathiasx?shelf=apocalyptic-computing&quot;&gt;&lt;code&gt;apocalyptic-computing&lt;/code&gt; bookshelf on Goodreads&lt;/a&gt; to track these books. The name suggests that this is the list of books I’d bring with me to rebuild society, should we need it. With a list like this can we go “mining for computation on the beach” and hope to know enough to start from scratch.&lt;/p&gt;

&lt;p&gt;What books would be on your &lt;code&gt;apocalyptic-computing&lt;/code&gt; shelf? &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;Let me know&lt;/a&gt;, or set up your own Goodreads shelf and send it to me!&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;If you want to learn Emacs itself before you dive into Writing GNU Extensions, then I recommend &lt;a href=&quot;https://www.masteringemacs.org/&quot;&gt;Mastering Emacs&lt;/a&gt; and the &lt;a href=&quot;http://cestlaz.github.io/stories/emacs/&quot;&gt;Using Emacs&lt;/a&gt; video series.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://orgmode.org/&quot;&gt;Org mode&lt;/a&gt; is perhaps the most important tool I’ve learned in Emacs, and now powers large parts of my life.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 12 Mar 2017 00:00:00 -0600</pubDate>
        <link>http://blog.mattgauger.com/2017/03/12/mining-for-computation-on-the-beach/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2017/03/12/mining-for-computation-on-the-beach/</guid>
        
        
      </item>
    
      <item>
        <title>Clojure Data Science: Sent Counts and Aggregates</title>
        <description>&lt;hr /&gt;

&lt;p&gt;This is Part 3 of a series of blog posts called &lt;a href=&quot;/categories/clojure-data-science/&quot;&gt;Clojure Data Science&lt;/a&gt;. Check out the &lt;a href=&quot;/2014/04/13/clojure-data-science-refactoring-and-cleanup/&quot;&gt;previous post&lt;/a&gt; if you missed it.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;For this post, we want to generate some summaries of our data by doing aggregate queries. We won’t yet be pulling in tools like &lt;a href=&quot;http://storm.incubator.apache.org/&quot;&gt;Apache Storm&lt;/a&gt; into the mix, since we can accomplish this through Datomic queries. We will also talk about trade-offs of running aggregate queries on large datasets and devise a way to save our data back to Datomic.&lt;/p&gt;

&lt;h2 id=&quot;updating-dependencies&quot;&gt;Updating dependencies&lt;/h2&gt;

&lt;p&gt;It has been some time since we worked on &lt;a href=&quot;https://github.com/mathias/autodjinn&quot;&gt;autodjinn&lt;/a&gt;. Libraries move fast in the Clojure ecosystem, and we want to make sure that we’re developing against the most recent versions of each dependency. Before we begin making changes, let’s update everything. If you have already read my &lt;a href=&quot;/blog/2014/09/15/clojure-code-quality-tools/&quot;&gt;Clojure Code Quality Tools&lt;/a&gt; post, you’ll be familiar with the &lt;code&gt;lein ancient&lt;/code&gt; plugin.&lt;/p&gt;

&lt;p&gt;Below is output when I run &lt;code&gt;lein ancient&lt;/code&gt; on the last post’s finished git tag, &lt;code&gt;v0.1.1&lt;/code&gt;. To go back to that state, you can run &lt;code&gt;git checkout v0.1.1&lt;/code&gt; on the &lt;a href=&quot;https://github.com/mathias/autodjinn&quot;&gt;autodjinn repo&lt;/a&gt;.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/c349dc7cb110edb56235.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;It looks like our &lt;a href=&quot;https://github.com/james-henderson/nomad&quot;&gt;nomad&lt;/a&gt; dependency is out of date. Update the version number in &lt;code&gt;project.clj&lt;/code&gt; to &lt;code&gt;0.7.0&lt;/code&gt; and run &lt;code&gt;lein ancient&lt;/code&gt; again to verify that it worked.&lt;/p&gt;

&lt;p&gt;If you take a look at &lt;code&gt;project.clj&lt;/code&gt; yourself, you may notice that our project is still on Clojure &lt;code&gt;1.5.1&lt;/code&gt;. &lt;code&gt;lein ancient&lt;/code&gt; doesn’t look at the version of Clojure that we’re specifying; it assumes you have a good reason for picking the Clojure version you specify. In our case, we’d like to be on the latest stable Clojure, version &lt;code&gt;1.6.0&lt;/code&gt;. Update the version of Clojure in &lt;code&gt;project.clj&lt;/code&gt; and then run your REPL. There should be no issues with using the functionality in the app that we created in previous posts. If there is, carefully read the error messages and try to find a solution before moving on.&lt;/p&gt;

&lt;p&gt;To save on the hassle of upgrading, I have created a tag for the project after upgrading Clojure and nomad. To go to that tag in your local copy of the repo, run &lt;code&gt;git checkout v0.1.2&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;datomic-query-refresher&quot;&gt;Datomic query refresher&lt;/h2&gt;

&lt;p&gt;If you remember back to the &lt;a href=&quot;/2014/03/30/clojure-data-science-ingesting-your-gmail-inbox/&quot;&gt;first post&lt;/a&gt;, we wrapped up by querying for entity IDs and then using Datomic’s built-in &lt;code&gt;entity&lt;/code&gt; and &lt;code&gt;touch&lt;/code&gt; functions to instantiate each message with all of its attributes. We had to do this because the query itself only returned a set of entity IDs:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/ab5a827ca860c89e0043.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Note that the Datomic query is made up of several parts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;code&gt;:find&lt;/code&gt; clause says what will be returned. In this case, it is the &lt;code&gt;?eid&lt;/code&gt; variable for each record we matched in the rest of the query.&lt;/li&gt;
  &lt;li&gt;The &lt;code&gt;:where&lt;/code&gt; clause gives a condition to match. In this case, we want all &lt;code&gt;?eid&lt;/code&gt; where the entity has a &lt;code&gt;:mail/uid&lt;/code&gt; fact, but we don’t care about the &lt;code&gt;:mail/uid&lt;/code&gt; fact’s value, so we give it a wildcard with the underscore (&lt;code&gt;_&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We could pass in the &lt;code&gt;:mail/uid&lt;/code&gt; we care about, and only get one message’s entity-ID back.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/4990c69f1e4c4a7dc7e9.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Notice how the &lt;code&gt;?uid&lt;/code&gt; variable gets passed in with the &lt;code&gt;:in&lt;/code&gt; clause, as the third argument to &lt;code&gt;d/q&lt;/code&gt;?&lt;/p&gt;

&lt;p&gt;Or we could change the query to match on other attributes:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/3685937809a50e36c424.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;In all these cases, we’d still get the entity IDs back because the &lt;code&gt;:find&lt;/code&gt; clause tells Datomic to return &lt;code&gt;?eid&lt;/code&gt;. Typically, we pass around entity IDs and lazy-load any facts (attributes) that we need off that entity.&lt;/p&gt;

&lt;p&gt;But, we could just as easily return other attributes from an entity as part of a query. Let’s ask for the recipients of all the emails in our system:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/be2baf0af0b652966240.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;While it is less common to return only the value of an entity’s attribute, being able to do so will allow us to build more functionality on top of our email abstraction later.&lt;/p&gt;

&lt;p&gt;One last thing. Take a look at the return of that query above. Remember that the results returned by a Datomic query are a &lt;a href=&quot;http://clojure.github.io/clojure/clojure.core-api.html#clojure.core/set&quot;&gt;set&lt;/a&gt;. In Clojure, sets are a collection of unique values. So we’re seeing the unique list of addresses that are in the To: field in our data. What we’re not seeing is duplicate recipient addresses. To be able to count the number of times an email address received a message, we’ll need a list with non-unique members.&lt;/p&gt;

&lt;p&gt;Datomic creates a unique set for the values returned by a query. This is generally a great thing, since it gets around some of the issues that one can run into with JOINing in SQL. But in this case, it is not ideal for what we want to accomplish. We could try to get around the uniqueness constraint on output by returning vectors of the entity ID and the &lt;code&gt;?to&lt;/code&gt; address, and then mapping across the result to pull out the second item:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/d6401a036d032caccde3.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;There’s a simpler way that we can use in the Datomic query. By keeping it inside Datomic, we can later combine this approach with more-complex queries. We can tell the Datomic query to look at other attributes when considering what the unique key is by passing the query a &lt;code&gt;:with&lt;/code&gt; clause. By changing our query slightly to include a &lt;code&gt;:with&lt;/code&gt; clause, we end up with the full list of recipients in our datastore:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/f36ae56bef0e1b6cdfa9.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;At this point, it might be a good idea to review Datomic’s &lt;a href=&quot;http://docs.datomic.com/query.html&quot;&gt;querying&lt;/a&gt; guide. We’ll be using some of the advanced querying features found in the later sections of that guide, most notably aggregate functions.&lt;/p&gt;

&lt;h2 id=&quot;sent-counts&quot;&gt;Sent Counts&lt;/h2&gt;

&lt;p&gt;For this feature, we want to find all the pairs of from-to addresses for each email in our datastore, and then sum up the counts for each pair. We will save all these sent counts into a new entity type in Datomic. This will allow us to ask Datomic questions like who sends you the most email, and who you send the most email to.&lt;/p&gt;

&lt;p&gt;We start by building up the query in our REPL. Let’s start with a simpler query, to count how many emails have been sent &lt;em&gt;to&lt;/em&gt; each email address in our data store. Note that this isn’t sufficient to answer the question above, since we won’t know who those emails came &lt;em&gt;from&lt;/em&gt;; they could have been sent by us or by someone else, or they could have been sent to us. Later, we’ll make it work with from-to pairs that allow us to know things like who is sending email to us.&lt;/p&gt;

&lt;p&gt;A simple way to do this would be to wrap our previous query in the &lt;a href=&quot;http://clojure.github.io/clojure/clojure.core-api.html#clojure.core/frequencies&quot;&gt;frequencies&lt;/a&gt; function that Clojure.core provides. &lt;code&gt;frequencies&lt;/code&gt; returns a map of items with their count from a Clojure collection.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/af050f75d1c610d6d422.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;However, we want to perform the same sort of thing in Datomic itself. To do that, we’re going to need to know about aggregate functions. Aggregate functions operate over the intermediate results of a Datomic query. Datomic provides functions like &lt;code&gt;max&lt;/code&gt;, &lt;code&gt;min&lt;/code&gt;, &lt;code&gt;sum&lt;/code&gt;, &lt;code&gt;count&lt;/code&gt;, &lt;code&gt;rand&lt;/code&gt; (for getting a random value out of the query results), and more. With aggregates, we need to be sure to use a &lt;code&gt;:with&lt;/code&gt; clause to ensure we aggregate over all our values.&lt;/p&gt;

&lt;p&gt;Looking at that short list of aggregate functions I’ve named, we can see that we probably want to use the &lt;code&gt;count&lt;/code&gt; function to count the occurance of each email address in a to field in our data. To see how aggregates work, I’ve come up with a simpler example (the only new thing to know is that Datomic’s Datalog implementation can query across Clojure collections as easily as it can against a database value, so I’ve given a simple vector-of-vectors here to describe data in the form&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[database-id person-name]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;When the query looks at records in the data, our &lt;code&gt;:where&lt;/code&gt; clause gives each position in the vector an id and a name based on position in the vector.)&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/6b8da156388ed1cd9290.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Let’s review what happened there. Before the &lt;code&gt;count&lt;/code&gt; aggregate function was applied, our results looked like this:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[[&quot;Jon&quot;] [&quot;Jon&quot;] [&quot;Bob&quot;] [&quot;Chris&quot;]]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So the &lt;code&gt;count&lt;/code&gt; function just counts across the values of the variable it is passed (in our case, &lt;code&gt;?name&lt;/code&gt;), and by pairing it with the original &lt;code&gt;?name&lt;/code&gt; value, we get each name and the number of times it appears in our dataset.&lt;/p&gt;

&lt;p&gt;It makes sense that we can do the same thing with our recipient email addresses from the previous query. Combining our previous queries with the &lt;code&gt;count&lt;/code&gt; aggregate function, we get:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/8b346f1019d588bea534.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;That looks like the same kind of data we were getting with the use of the &lt;code&gt;frequencies&lt;/code&gt; function before! So now we know how to use a Datomic aggregate function to count results in our queries.&lt;/p&gt;

&lt;p&gt;What’s next? Well, what we really want is to get results that are of the form&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[from-address to-address]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and count those tuples. That way, we can differentiate between email sent to us versus email we’ve sent to others, etc. And eventually, we’d like to save those queries off as functions that we can call to compute the counts from other places in our project.&lt;/p&gt;

&lt;p&gt;We can’t pass a tuple like &lt;code&gt;[from-address to-address]&lt;/code&gt; to the &lt;code&gt;count&lt;/code&gt; aggregate function in one query. The way around this is to write two queries. The inner query will return the tuples, and the outer query will return the tuple and a count of the tuple in the output data. Since the queries run on the peer, we don’t really have to worry about whether it is one query or two, just that it returns the correct data at the end.&lt;/p&gt;

&lt;p&gt;So what would the inner query look like? Remember that the outer query will still need a field to pass to the &lt;code&gt;:with&lt;/code&gt; clause, so we’ll probably want to pass through the entity ID.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/61e60a563ffc29f06af8.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Those tuples will be used by our outer query. However, we also need a combined value for the count to operate on. For that, we can throw in a function call in the &lt;code&gt;:where&lt;/code&gt; clause and give it a binding at the end for Datomic to use for that new value. In this case, I’ll combine the &lt;code&gt;?from&lt;/code&gt; and &lt;code&gt;?to&lt;/code&gt; values into a PersistentVector that the &lt;code&gt;count&lt;/code&gt; aggregate function can use. The combined query ends up looking like this:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/d26c7175670b8c29e7c2.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;And the output is as we expect.&lt;/p&gt;

&lt;h2 id=&quot;reusable-functions&quot;&gt;Reusable functions&lt;/h2&gt;

&lt;p&gt;The next step is to turn the query above into various functions we can use to query for from-to counts later. In our data, we don’t just have recipients in the To: field, we also have CC and BCC recipients. Those fields will need their own variations of the query function, but since they will share so much functionality, we will try to compose our functions in such a way that we avoid duplicate code.&lt;/p&gt;

&lt;p&gt;In general, when I write query functions for Datomic, I use multiple arities to always allow a database value to be passed to the query function. This can be useful, for example, when we want to query against previous (historical) values of the database, or when we want to work with a particular database value across multiple queries, to ensure our data is consistent and doesn’t change between queries.&lt;/p&gt;

&lt;p&gt;Such a query function typically looks like this:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/f61fb370a3a2120daf6f.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;By taking advantage of multiple arities, we can default to not having to pass a database value into the function. But in the cases where we do need to ensure a particular database version is used, we can do that. This is a very powerful idiom that I’ve learned since I began to use Datomic, and I suggest you structure all your query functions similarly.&lt;/p&gt;

&lt;p&gt;Now, let’s take that function that only queries for &lt;code&gt;:mail/to&lt;/code&gt; addresses and make it more generic, with specific wrapper functions for each case where we’d want to use it:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/67647105799f7f2ff1cf.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Note that we had to change the inner query to take the attr we want to query on as a variable; this is the proper way to pass a piece of data into a query we want to run. The &lt;code&gt;$&lt;/code&gt; that comes first in the &lt;code&gt;:in&lt;/code&gt; clause tells Datomic to use the second &lt;code&gt;d/q&lt;/code&gt; argument as our dataset (the db value we pass in), and the &lt;code&gt;?attr&lt;/code&gt; tells it to bind the third &lt;code&gt;d/q&lt;/code&gt; argument as the variable &lt;code&gt;?attr&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;While the three variations on functions are similar, we keep the code DRY. (DRY is an acronym for Don’t Repeat Yourself.) In the long run, less code should mean less bugs and the ability to fix problems in one place.&lt;/p&gt;

&lt;p&gt;Building complex systems by composing functions is one of the features of Clojure that I enjoy the most! And notice how we got to these finished query functions by building up functionality in our REPL: another aspect of writing systems in Clojure that I appreciate.&lt;/p&gt;

&lt;h2 id=&quot;querying-against-large-data-sets&quot;&gt;Querying against large data sets&lt;/h2&gt;

&lt;p&gt;Right now, our functions calculate the sent counts across all messages every time they’re called. This is fine for the small sample dataset I’ve been working with locally, but if it were to run against the 35K+ messages that are in my Gmail inbox alone (not to mention all the labels and other places my email lives…) it would take a very long time. With even bigger datasets, we can run into an additional problem: the results may not fit into memory.&lt;/p&gt;

&lt;p&gt;When building systems with datasets big enough that they don’t fit into memory, or that may take too much time to compute to be practical, there are two general approaches that we will explore. The first is storing results as data (known as memoizing or caching the results), and the other is breaking up the work to run on distributed systems like Hadoop or Apache Storm.&lt;/p&gt;

&lt;p&gt;For this data, we only want to avoid redoing the calculating every time we want to know the sent counts. Currently, the data in our system changes infrequently, and it’s likely that we could tell the system to recompute sent counts only after ingesting new data from Gmail. For these reasons, a reasonable solution will be to store the computed sent counts back into Datomic.&lt;/p&gt;

&lt;h2 id=&quot;a-new-entity-type-to-store-our-results&quot;&gt;A new entity type to store our results&lt;/h2&gt;

&lt;p&gt;For all three query functions we wrote, each result is of the form:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[from-address to-address count]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Let’s add to the Datomic schema in our &lt;code&gt;core.clj&lt;/code&gt; file to create a new &lt;code&gt;:sent-count&lt;/code&gt; entity type with these three attributes. Note that sent counts don’t really have a unique identifier of their own; it is the combination of &lt;code&gt;from&lt;/code&gt; -&amp;gt; &lt;code&gt;to&lt;/code&gt; addresses that uniquely identifies them. However, we will leave the &lt;code&gt;from&lt;/code&gt; and &lt;code&gt;to&lt;/code&gt; addresses as separate fields so it is easy to use them in queries.&lt;/p&gt;

&lt;p&gt;Add the following maps to the &lt;code&gt;schema-txn&lt;/code&gt; vector:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/661dadfdb2e639209452.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;You’ll have to call the &lt;code&gt;update-schema&lt;/code&gt; function in your REPL to run the schema transaction.&lt;/p&gt;

&lt;p&gt;Something that’s worth calling out is that we’re using a Datomic schema &lt;code&gt;valueType&lt;/code&gt; that we haven’t seen yet in this project: &lt;code&gt;db.type/ref&lt;/code&gt;. In most cases, you’d want to use the &lt;code&gt;ref&lt;/code&gt; type to associate with other entities in Datomic. But we can also use it to associate with a given list of facts. Here, we give the &lt;code&gt;ref&lt;/code&gt; type an enum of the possible values that &lt;code&gt;:sent-count/type&lt;/code&gt; can have: &lt;code&gt;to&lt;/code&gt;, &lt;code&gt;cc&lt;/code&gt;, and &lt;code&gt;bcc&lt;/code&gt;. By adding this &lt;code&gt;type&lt;/code&gt; field to our new entities, we can either choose to look at sent counts for only one type of address, or we can sum up all the counts for a given from-to pair and get the total counts for the system.&lt;/p&gt;

&lt;p&gt;Our next job is to add some functions to create the initial sent counts data, as well as to query for it. To keep things clean, I created a &lt;code&gt;sent-counts&lt;/code&gt; namespace for these functions to live in. I’ve provided it below with minimal explanation, since it should look very familiar to what we’ve already done.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/mathias/autodjinn/blob/29cc08d1ead6043287ecb82136d3ee519668100f/src/autodjinn/sent_counts.clj&quot;&gt;/src/autodjinn/sent_counts.clj&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After adding in the &lt;code&gt;sent_counts.clj&lt;/code&gt; file, running:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;(sent-counts/create-sent-counts)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;will populate your datastore with the sent counts computed with functions we created earlier.&lt;/p&gt;

&lt;p&gt;Note: The sent counts don’t have any sort of unique key on them, so if you run &lt;code&gt;create-sent-counts&lt;/code&gt; multiple times, you’ll get duplicate results. We’ll handle that another time when we need to update our data.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping up&lt;/h2&gt;

&lt;p&gt;We’ve covered a lot of material on querying Datomic. In particular, we used aggregate functions to get the counts and sums of records in our data store. Because we don’t want to run the queries all the time, we created a new entity type to store our sent counts and saved our data into it. With query functions like those found in the &lt;code&gt;sent-counts&lt;/code&gt; namespace, we can start to ask our data questions like “In the dataset, what address was sent the most email?”&lt;/p&gt;

&lt;p&gt;If you want to compare what you’ve done with my version, you can run &lt;code&gt;git diff v0.1.3&lt;/code&gt; on the &lt;a href=&quot;https://github.com/mathias/autodjinn&quot;&gt;autodjinn repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Please let me know what you think of these posts by sending me an email at &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&lt;/a&gt;. I’d love to hear from you!&lt;/p&gt;
</description>
        <pubDate>Thu, 23 Oct 2014 18:18:00 -0500</pubDate>
        <link>http://blog.mattgauger.com/2014/10/23/clojure-data-science-sent-counts-and-aggregates/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2014/10/23/clojure-data-science-sent-counts-and-aggregates/</guid>
        
        
      </item>
    
      <item>
        <title>Clojure Code Quality Tools</title>
        <description>&lt;p&gt;I work with many programming languages on a daily basis. As a polyglot programmer, I’ve come to appreciate tools that help me follow best practices. For JavaScript, there’s the excellent &lt;a href=&quot;http://jshint.com/&quot;&gt;jshint&lt;/a&gt;. When I need to verify some XML, there’s &lt;a href=&quot;http://xmlsoft.org/xmllint.html&quot;&gt;xmllint&lt;/a&gt;. In a Ruby on Rails project, I can count on the &lt;a href=&quot;http://rubygems.org/gems/rails_best_practices&quot;&gt;rails_best_practices&lt;/a&gt; gem. For Ruby smells, I reach for &lt;a href=&quot;https://github.com/bbatsov/rubocop&quot;&gt;rubocop&lt;/a&gt;. There’s tools like &lt;a href=&quot;https://github.com/colszowka/simplecov&quot;&gt;SimpleCov&lt;/a&gt; to measure test coverage on my Ruby projects. &lt;a href=&quot;https://github.com/square/cane&quot;&gt;cane&lt;/a&gt; helps me to ensure line length, method complexity, and more in my Ruby code. &lt;a href=&quot;https://github.com/scrooloose/syntastic&quot;&gt;Syntastic&lt;/a&gt; helps bring real syntax checking to vim for many languages. Every day, more open source tools are introduced that help me to improve the quality of the software that I write.&lt;/p&gt;

&lt;p&gt;It follows that when I write Clojure code, I want nice tooling to help me manage code quality, namespace management, and out-of-date dependencies. What tools do I use on a day-to-day basis for this? In this post, I’ll show 5 tools that I use in my workflow every day on Clojure projects, and also provide some other tools for further exploration. Most of these tools exist as plugins to the excellent &lt;a href=&quot;http://leiningen.org/&quot;&gt;Leiningen&lt;/a&gt; tool for Clojure.&lt;/p&gt;

&lt;h2 id=&quot;lein-deps-tree&quot;&gt;lein deps :tree&lt;/h2&gt;

&lt;p&gt;In the past, &lt;code&gt;lein deps&lt;/code&gt; was a command that downloaded the correct versions of your project’s dependencies. Running &lt;code&gt;lein deps&lt;/code&gt; is no longer necessary, as each lein command now checks for dependencies before executing. But &lt;code&gt;deps&lt;/code&gt; provides an interesting variant for our uses: &lt;code&gt;lein deps :tree&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;:tree&lt;/code&gt; keyword at the end instructs lein to print out your project’s dependencies as a tree. This itself is a good visualization, but not what we’re looking for. The tree command will first print out any dependencies-of-dependencies which have conflicts with other dependencies. For example, here’s what &lt;code&gt;lein deps :tree&lt;/code&gt; says for one of my projects:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/8eca3548f751bec6ea55.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;As you can see, the tool suggests dependencies that request conflicting versions, and how we can modify our &lt;code&gt;project.clj&lt;/code&gt; file to resolve those conflicting versions by excluding one or the other. This isn’t always very useful, but when you run into issues because two different Clojure libraries require two wildly different &lt;code&gt;joda-time&lt;/code&gt; versions (a situation I have run into before), it will be good to know what dependencies are causing that issue and how you might go about resolving it.&lt;/p&gt;

&lt;p&gt;Note that this functionality disappeared in Leiningen 2.4.3 but is back in 2.5.0, so make sure you run &lt;code&gt;lein upgrade&lt;/code&gt;!&lt;/p&gt;

&lt;h2 id=&quot;lein-ancienthttpsgithubcomxsclein-ancient&quot;&gt;&lt;a href=&quot;https://github.com/xsc/lein-ancient&quot;&gt;lein-ancient&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;This plugin to &lt;code&gt;lein&lt;/code&gt; exists simply to check your project for outdated dependencies. Without &lt;a href=&quot;https://github.com/xsc/lein-ancient&quot;&gt;lein-ancient&lt;/a&gt;, I’d be unable to keep up with some of the faster-moving libraries in the Java and Clojure world.&lt;/p&gt;

&lt;p&gt;After adding ancient to your &lt;code&gt;~/.lein/profiles.clj&lt;/code&gt;, running the &lt;code&gt;lein ancient&lt;/code&gt; command yields output on the same project as before:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/bac5e554f971d7aa462f.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Whoops! Looks like I haven’t been keeping up to date with my dependencies. &lt;code&gt;lein ancient&lt;/code&gt; makes checking for new dependency versions easy. Further, thanks to the ubiquity of &lt;a href=&quot;http://semver.org/&quot;&gt;semantic versioning&lt;/a&gt; in Clojure projects, it is usually quite safe to bump the minor versions (0.0.x) of dependencies.&lt;/p&gt;

&lt;p&gt;You can also use lein-ancient to find outdated lein plugins in your &lt;code&gt;~/.lein/profiles.clj&lt;/code&gt; file. Just run it with the &lt;code&gt;profiles&lt;/code&gt; argument:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/02b999542ea837b87e30.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;lein-kibithttpsgithubcomjonasekibit&quot;&gt;&lt;a href=&quot;https://github.com/jonase/kibit&quot;&gt;lein kibit&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;As we gain experience and confidence in a programming language, we begin to talk about whether we’re writing &lt;em&gt;idiomatic&lt;/em&gt; code. I’d argue that idiomatic code is code that accomplishes a goal with proper use of language features, in a way that other developers familiar with that language would understand. A simpler way to say it might be: idiomatic code uses the community-accepted best practices of how to do something.&lt;/p&gt;

&lt;p&gt;Clojure’s design seeks to solve some problems found in older Lisps, as well as add in niceties like complementary predicate functions. A good example of these convenient complementary functions are &lt;code&gt;if&lt;/code&gt; and &lt;code&gt;if-not&lt;/code&gt;. Clojure also contains several cases of simplification for common usage. For example, when you don’t need an else clause on an &lt;code&gt;if&lt;/code&gt;, you can use the &lt;code&gt;when&lt;/code&gt; macro.&lt;/p&gt;

&lt;p&gt;Wouldn’t it be great if there was someone who was well-versed in Clojure idioms pairing with you and offering suggestions? That’s exactly what &lt;a href=&quot;https://github.com/jonase/kibit&quot;&gt;kibit&lt;/a&gt; does.&lt;/p&gt;

&lt;p&gt;Running against a project I’d set up to contain some smells, &lt;code&gt;lein kibit&lt;/code&gt; found:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/fc0d446aeb90f44a6731.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;These kinds of small improvements are all over our Clojure projects. They’re not show-stopper bugs, but they’re small places for improvement.&lt;/p&gt;

&lt;p&gt;Kibit’s suggestions are almost always logically equivalent to the original code. Still, I always do some smoke-testing to ensure the code still works after using Kibit’s suggestion, and it generally does. Problems I frequently fix with Kibit are replacing &lt;code&gt;if&lt;/code&gt; statements with the &lt;code&gt;when&lt;/code&gt; macro, as well as places where the code checks for empty seqs, or that I can simplify nil checks.&lt;/p&gt;

&lt;p&gt;You can point lein kibit at a specific namespace by appending the path, like this: &lt;code&gt;lein kibit src/foo/bar.clj&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Kibit catches many cases where there is a more-idiomatic way to express what you are trying to do. I recommend running it often. In fact, it’s possible to use &lt;a href=&quot;https://github.com/jonase/kibit#usage-from-inside-emacs&quot;&gt;kibit in your emacs buffers&lt;/a&gt; if you want it to be that much more convenient and real-time.&lt;/p&gt;

&lt;h2 id=&quot;eastwoodhttpsgithubcomjonaseeastwood&quot;&gt;&lt;a href=&quot;https://github.com/jonase/eastwood&quot;&gt;Eastwood&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;For linting Clojure code, there’s Eastwood. It is similar in functionality to Kibit, bit will catch different issues than Kibit. Built on two interesting Clojure projects: &lt;a href=&quot;https://github.com/clojure/tools.analyzer&quot;&gt;tools.analyzer&lt;/a&gt; and &lt;a href=&quot;https://github.com/clojure/tools.analyzer.jvm&quot;&gt;tools.analyzer.jvm&lt;/a&gt;, Eastwood does a powerful examination of your code inside the JVM. It is worth highlighting that since Eastwood loads your code to analyze it, it might trigger any side effects that happen when your code loads: writing files, modifying databases, etc. Note that it only loads the code; it does not execute it.&lt;/p&gt;

&lt;p&gt;After adding &lt;code&gt;eastwood&lt;/code&gt; to your lein &lt;code&gt;profiles.clj&lt;/code&gt;, simply run: &lt;code&gt;lein eastwood&lt;/code&gt; and you will see output like:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/b93cea02293eac933bee.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;That’s a lot of problems for a simple file! Notice how one mistake got caught for two reasons: A misplaced docstring (placed after the arguments vector) becomes just a string in the function body that will be thrown away.&lt;/p&gt;

&lt;p&gt;Another nice catch that Eastwood provides is detecting the redefinition of the var &lt;code&gt;qux&lt;/code&gt; in the file.&lt;/p&gt;

&lt;p&gt;But Eastwood covers a lot more cases than just vars being def’d more than once. See the &lt;a href=&quot;https://github.com/jonase/eastwood#whats-there&quot;&gt;full list&lt;/a&gt; to find out what else it does. There’s a few linters that are disabled by default, but they might make sense to enable for your project.&lt;/p&gt;

&lt;p&gt;Frequently running lint tools can help prevent subtle problems that come from code that looks correct but contains some small error. Eastwood is less concerned with style than tools like JSHint are, but we have other tools that cover stylistic concerns.&lt;/p&gt;

&lt;h2 id=&quot;lein-bikeshedhttpsgithubcomdakronelein-bikeshed&quot;&gt;&lt;a href=&quot;https://github.com/dakrone/lein-bikeshed&quot;&gt;lein bikeshed&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;This is a relative newcomer to my own tool set. &lt;a href=&quot;https://github.com/dakrone/lein-bikeshed&quot;&gt;lein bikeshed&lt;/a&gt; has features related to the low-hanging fruit in our Clojure code: lines longer than 80 characters, blank lines at ends of files, and more. It will also tell you what percentage of functions have docstrings. Like other tools mentioned here, it is a lein plugin that you add to your &lt;code&gt;profiles.clj&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;A run of &lt;code&gt;lein bikeshed&lt;/code&gt; on its own source (which purposefully includes some code designed to fail) looks like this:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/271e06ebce8fe6428b83.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Bikeshed might give a lot of output for your existing projects, but the warnings are worth investigating and addressing. You can always silence the long-lines warning if it doesn’t matter to you with the &lt;code&gt;-m&lt;/code&gt; command line argument.&lt;/p&gt;

&lt;h2 id=&quot;tying-it-all-together-with-a-lein-alias&quot;&gt;Tying it all together with a Lein alias&lt;/h2&gt;

&lt;p&gt;Wouldn’t it be great to run all these tools frequently, so that you can check for as many problems as possible? Well, you can, with a lein alias. (The lein wiki documents aliases in the &lt;a href=&quot;https://github.com/technomancy/leiningen/blob/stable/sample.project.clj#L195-L211&quot;&gt;lein sample.project.clj&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;In &lt;code&gt;~/.lein/profiles.clj&lt;/code&gt;, inside your &lt;code&gt;:user&lt;/code&gt; map, add the line:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/eef9f3f3e9e0ba40cb78.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Now, when you want to run all these tools at once on a project, you simply invoke &lt;code&gt;lein omni&lt;/code&gt;. I use this alias on all my Clojure(Script) projects. I have grown accustomed to seeing the kinds of output that a clean Clojure project will have.&lt;/p&gt;

&lt;p&gt;It’s worth noting that I don’t run Eastwood unless it is necessary for the project. When it is necessary, I override the alias in the project’s &lt;code&gt;project.clj&lt;/code&gt; to run Eastwood as well.&lt;/p&gt;

&lt;p&gt;This command can take some time to complete, but with an alias we’re only spinning up lein once.&lt;/p&gt;

&lt;h2 id=&quot;and-a-bash-alias&quot;&gt;And a bash alias&lt;/h2&gt;

&lt;p&gt;The output of &lt;code&gt;lein omni&lt;/code&gt; can be long, which can either result in a lot of scrolling or neglecting to run the command due to the inconvenience. To help manage the length of the output, I’ve created a bash alias that runs the plugins and pipes them to less.&lt;/p&gt;

&lt;p&gt;My personal bash alias also runs midje at the end. You can choose whether to run the tests for your own alias. That’s just my personal preference.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/8b6a0040fcd7e4ae890f.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Note that just like running the lein alias above, this may take a bit of time. Since we’re piping it to &lt;code&gt;less&lt;/code&gt;, it might take awhile before &lt;code&gt;less&lt;/code&gt; receives output. While it is still running, output will periodically show up at the bottom of the &lt;code&gt;less&lt;/code&gt; buffer. You can use both Emac’s and vim’s movement commands in &lt;code&gt;less&lt;/code&gt; to advance the buffer. I find &lt;code&gt;less&lt;/code&gt; to be more manageable for scrolling through output than switching to &lt;code&gt;tmux&lt;/code&gt;’s history scrolling mode.&lt;/p&gt;

&lt;h2 id=&quot;managing-your-namespaces-lein-slamhoundhttpsgithubcomtechnomancyslamhound&quot;&gt;Managing your namespaces: &lt;a href=&quot;https://github.com/technomancy/slamhound&quot;&gt;lein slamhound&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Namespace management often becomes an issue on nontrivial Clojure projects. Actively developing a project means managing the functions we pull in from other namespaces and from libraries. These require statements can often get out of date. Often, they’re either missing namespaces that are needed, or containing requirements for old functions that are no longer used in the current code.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/technomancy/slamhound&quot;&gt;slamhound&lt;/a&gt; is a tool that can help to manage dependencies in your namespaces. It knows how to require and import Clojure and Java dependencies, and can remove stale requires that are no longer necessary. Slamhound can often fix missing requires for functions that it can resolve.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note: slamhound rewrites the namespace macros in your project’s .clj files!&lt;/strong&gt; I recommend only running it on code that’s committed to git (or whatever you use as a VCS) so that you can review and  rollback any changes it makes.&lt;/p&gt;

&lt;p&gt;The most basic way to use slamhound is to add it to your &lt;code&gt;~/.lein/profiles.clj&lt;/code&gt; as a dependency. Then add this alias:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/f3799e60c63b0aebf17e.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Now you can use slamhound on a project by running &lt;code&gt;lein slamhound&lt;/code&gt; in the project’s directory. There’s also REPL and Emacs support, which you can learn more about in the &lt;a href=&quot;https://github.com/technomancy/slamhound#repl-usage&quot;&gt;slamhound README&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;measuring-test-coverage-with-cloveragehttpsgithubcomlshiftcloverage&quot;&gt;Measuring test coverage with &lt;a href=&quot;https://github.com/lshift/cloverage&quot;&gt;cloverage&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;It is often claimed that less unit testing is necessary in Clojure because Clojure is functional and makes use of immutable data structures. And it is true that with functional programming, most tests are simple: given some input, the output should be a certain value.&lt;/p&gt;

&lt;p&gt;Some would even argue that Clojure functions should be well-factored enough into simple functions that the behavior of the function is apparent and requires no tests. Still others maintain that developing in the REPL is as good as writing unit tests, since functions are constantly evaluated and integrated with this style of development.&lt;/p&gt;

&lt;p&gt;That said, there’s still mutable Java code to interop with, there’s still the necessary evil of functions with side effects, and we might want to check the &lt;em&gt;structure&lt;/em&gt; of the data we’re producing in our functions rather than the value of it. For all those reasons and to check that I don’t introduce regressions, I tend to write unit tests in Clojure.&lt;/p&gt;

&lt;p&gt;This blog post isn’t a platform to argue for or against testing Clojure. But when you do test, you may wonder how to tell how much test coverage your test suite has. How do we know at a glance what percentage of our namespaces is being tested? And how do we find lines that are never being exercised in our tests? After all, we can’t improve what we don’t measure.&lt;/p&gt;

&lt;p&gt;That’s where &lt;a href=&quot;https://github.com/lshift/cloverage&quot;&gt;cloverage&lt;/a&gt; comes in. Cloverage is another lein plugin, so it gets added to &lt;code&gt;~/.lein/profiles.clj&lt;/code&gt; like the others. Then run &lt;code&gt;lein cloverage&lt;/code&gt; in your project; it will run the test suite and generate a coverage report.&lt;/p&gt;

&lt;p&gt;The coverage report appears in &lt;code&gt;target/coverage&lt;/code&gt; as HTML files, broken down by namespace.&lt;/p&gt;

&lt;p&gt;You can still use Cloverage even if you don’t use &lt;code&gt;clojure.test&lt;/code&gt;. I use &lt;a href=&quot;https://github.com/marick/Midje&quot;&gt;midje&lt;/a&gt; in most of my tests. To use Cloverage in those situations, wrap your tests in a &lt;code&gt;deftest&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Since &lt;code&gt;deftest&lt;/code&gt; has a hyphenated Clojure keyword as its identifier, and Midje facts have a string as an identifier, I’ve come to use the &lt;code&gt;deftest&lt;/code&gt; to group related tests together. Usually this means naming the group of tests after the function I’m testing. Then I name Midje facts after the situation that the fact exercises. This makes sense to me because it fits well with the hierarchy of rspec unit tests in Ruby.&lt;/p&gt;

&lt;p&gt;Here’s an example of using this approach:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/94e1a4d7b8bce7c02e23.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Cloverage also outputs a &lt;code&gt;coverage.txt&lt;/code&gt; file that might be useful for use with services like &lt;a href=&quot;http://coveralls.io&quot;&gt;Coveralls&lt;/a&gt;. I haven’t used this, so I can’t comment on its usefulness.&lt;/p&gt;

&lt;p&gt;If you’re using &lt;a href=&quot;https://github.com/slagyr/speclj&quot;&gt;speclj&lt;/a&gt; for your tests, you might run into some issues getting Cloverage to play nice. I don’t use speclj often, so when I couldn’t get it to work with Cloverage, I didn’t pursue the issue.&lt;/p&gt;

&lt;h2 id=&quot;final-thoughts&quot;&gt;Final Thoughts&lt;/h2&gt;

&lt;p&gt;In this post, I covered 5 tools to add to your workflow all the time, and some others that might be useful in certain cases. I’m sure there’s more tools out there that are useful that I don’t know about, and I’d love to hear about them.&lt;/p&gt;

&lt;p&gt;I’m also thinking about writing some posts about other development tools that I use, particularly how I use &lt;a href=&quot;https://github.com/marick/midje&quot;&gt;midje&lt;/a&gt; to test, and how you can benchmark code with &lt;a href=&quot;https://github.com/davidsantiago/perforate&quot;&gt;perforate&lt;/a&gt;. If you’re interested in those topics, get in touch and let me know.&lt;/p&gt;

&lt;p&gt;Have fun and enjoy your cleaner codebase with these tools in your tool belt!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Interested in commenting or contacting me? Send an email to &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&lt;/a&gt;. Thanks!&lt;/p&gt;

</description>
        <pubDate>Mon, 15 Sep 2014 13:39:00 -0500</pubDate>
        <link>http://blog.mattgauger.com/2014/09/15/clojure-code-quality-tools/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2014/09/15/clojure-code-quality-tools/</guid>
        
        
      </item>
    
      <item>
        <title>Atreus: My Custom Keyboard</title>
        <description>&lt;p&gt;Last year I wrote about about building &lt;a href=&quot;/blog/2013/08/03/building-a-chording-keyboard-lessons-learned-and-progress-so-far/&quot;&gt;chording keyboards&lt;/a&gt; and &lt;a href=&quot;/blog/2013/08/06/a-simple-text-editor-foot-pedal/&quot;&gt;USB foot pedals&lt;/a&gt;. At the time, using the &lt;a href=&quot;http://www.pjrc.com/teensy/&quot;&gt;Teensy micro controller&lt;/a&gt; as a USB HID device was possible, but it still required a lot of research. There was no good central resource for knowledge about building keyboards. Since then, the &lt;a href=&quot;http://deskthority.net/wiki/ErgoDox&quot;&gt;Ergo Dox&lt;/a&gt; keyboard was released as open source and got quite popular. This seems to have opened the door for many to get into building keyboards.&lt;/p&gt;

&lt;p&gt;My friend &lt;a href=&quot;http://coglib.com/~icordasc&quot;&gt;Ian&lt;/a&gt; ordered an Ergo Dox on the Massdrop crowdfunding campaign, after I suggested that I’d teach him to solder and we’d assemble it together. Finding time to get together and build it took almost a year, but we’ve started meeting up weekly to assemble the Ergo Dox. Building his keyboard has been a lot of fun, and inspired me to work on my own keyboard projects again.&lt;/p&gt;

&lt;p&gt;Almost exactly a month ago, I started working on building my own keyboard. I wanted to build a keyboard from scratch that could replace my daily-driver keyboard, a PFU Happy Hacking Lite, so it had to be smaller than most &lt;a href=&quot;http://deskthority.net/wiki/Tenkeyless&quot;&gt;tenkeyless&lt;/a&gt; keyboards. The Ergo Dox’s columnar layout was always intriguing, but I wasn’t sure that I needed all those keys. (Normal keyboards stagger the keys of each row, which is a holdover from preventing mechanical typewriters from jamming. Columnar layouts assign a column of keys to each finger.)&lt;/p&gt;

&lt;p&gt;Through &lt;a href=&quot;http://geekhack.org&quot;&gt;Geekhack&lt;/a&gt;, I found the &lt;a href=&quot;https://github.com/technomancy/atreus&quot;&gt;Atreus&lt;/a&gt;, a keyboard designed by &lt;a href=&quot;http://technomancy.us/&quot;&gt;Phil Hagelberg&lt;/a&gt; (better known as &lt;a href=&quot;https://github.com/technomancy&quot;&gt;technomancy&lt;/a&gt; online.) The Atreus is open source (&lt;a href=&quot;https://github.com/technomancy/atreus&quot;&gt;hardware&lt;/a&gt;, &lt;a href=&quot;https://github.com/technomancy/atreus-firmware&quot;&gt;firmware&lt;/a&gt;), and has gone through several revisions at this point. My keyboard is done now, and I wanted to share it.&lt;/p&gt;

&lt;p&gt;&lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/mattgauger/14785511628&quot; title=&quot;IMG_3220&quot;&gt;&lt;img src=&quot;https://farm6.staticflickr.com/5592/14785511628_8eea0e6a61_c.jpg&quot; width=&quot;800&quot; height=&quot;600&quot; alt=&quot;IMG_3220&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://technomancy.us/173&quot;&gt;The original Atreus&lt;/a&gt; was constructed out of layers of laser-cut acrylic. Since then, some folks on the &lt;a href=&quot;http://geekhack.org/index.php?topic=54759.0&quot;&gt;Geekhack thread&lt;/a&gt; have redesigned the laser-cut design to be cut out of a sheet of birch plywood on &lt;a href=&quot;https://ponoko.com&quot;&gt;Ponoko&lt;/a&gt;. Ponoko is a great: you upload a file and choose materials and size. The Ponoko website keeps you updated on your project’s status as they check your design, pick materials, and so on. Later, your laser-cut project arrives in the mail. I highly recommend Ponoko’s service if you need laser cutting and can’t get it done at a local makerspace.&lt;/p&gt;

&lt;p&gt;&lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/mattgauger/14785346149&quot; title=&quot;IMG_3156&quot;&gt;&lt;img src=&quot;https://farm6.staticflickr.com/5565/14785346149_53f639dc31_c.jpg&quot; width=&quot;800&quot; height=&quot;600&quot; alt=&quot;IMG_3156&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I finished the birch ply with semi-gloss marine polyurethane. The polyurethane should give it a durable finish, and added a nice amber tint to the wood. The downside is that more than a week after the final coat went on, the poly is still out gassing some headache-inducing fumes.&lt;/p&gt;

&lt;p&gt;After applying the finish, I hot-glued the switches in and soldered it together. There’s no PCB with this design, just point-to-point with wires and components to a central Teensy. I used &lt;a href=&quot;http://deskthority.net/wiki/Cherry_MX_Clear&quot;&gt;Cherry MX Clear&lt;/a&gt; switches for the majority of the keys because they seem the closest to my Happy Hacking’s Topre switches to me. The modifiers are &lt;a href=&quot;http://deskthority.net/wiki/Cherry_MX_Black&quot;&gt;Cherry MX Blacks&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Assembling the Atreus with point-to-point soldering wasn’t too bad, but I’ve had a lot of experience soldering. I’ve no doubt that the construction will be durable and reliable, but a PCB might make it easier to assemble for beginners. There’s some talk on Geekhack about using the &lt;a href=&quot;http://deskthority.net/workshop-f7/onehand-20-keyboard-t6617.html&quot;&gt;One Hand PCB&lt;/a&gt; as a circuit board for a Atreus-like keyboard.&lt;/p&gt;

&lt;p&gt;The rest of my images from the build on Flickr in &lt;a href=&quot;https://www.flickr.com/photos/mattgauger/sets/72157646763805951/&quot;&gt;this album&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After hours of soldering, the moment of truth came: I plugged in the Teensy, uploaded the firmware, and typed some keys. It worked! I felt relieved that the keyboard worked on the first try. Because I had checked for continuity and shorts throughout the soldering process, I can be confident that my Atreus won’t have any issues with ghosting or glitches. The finished keyboard feels really solid; maybe more so than some plastic keyboards I’ve typed on before.&lt;/p&gt;

&lt;p&gt;Because the Atreus uses a columnar layout, I’m not planning to use it with a QWERTY layout. So, I decided to learn Dvorak. I’ve been practicing on the home row on &lt;a href=&quot;http://dvorak.nl&quot;&gt;dvorak.nl&lt;/a&gt;, which is a great website for learning Dvorak in your browser. The neat thing about that typing tutor is that you don’t have to commit to changing any key layouts at the OS-level. I’ve got the default QWERTY layout on my Atreus now, but will be switching to a hardware-native Dvorak layout soon.&lt;/p&gt;

&lt;p&gt;Since the Atreus uses a Teensy as its brain, it can be reconfigured easily by uploading a new firmware. Keyboard layouts for the Atreus start as a JSON file, and then an emacs function can be invoked to compile and upload the firmware to the board. The same JSON file can also be used to generate an HTML table of the layout with Org Mode in emacs. More information can be found on the &lt;a href=&quot;https://github.com/technomancy/atreus-firmware&quot;&gt;firmware project repo&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;what-next&quot;&gt;What next?&lt;/h2&gt;

&lt;p&gt;I haven’t worked on my chording keyboard in a long time.  I’m happy to see that things like the &lt;a href=&quot;https://github.com/tmk/tmk_keyboard&quot;&gt;tmk firmware&lt;/a&gt; will now make that project much easier. With my new knowledge and the many open source projects now available, I’m going to restart work on &lt;a href=&quot;/blog/2013/08/03/building-a-chording-keyboard-lessons-learned-and-progress-so-far/&quot;&gt;that project&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Further, I’ve been playing with Matt Adereth’s &lt;a href=&quot;https://github.com/adereth/dactyl&quot;&gt;dactyl&lt;/a&gt; to design chording keyboard layouts. Dactyl allows me to write Clojure code and output it in a format that OpenSCAD can generate a 3D model with. OpenSCAD can export the files to the formats that 3D printers use. 3D printing has a lot of promise for iteratively prototyping unique ergonomic peripherals, and I intend to try out several ideas for one-hand / chording keyboards.&lt;/p&gt;

&lt;p&gt;If you’re interested in building your own keyboard, I would recommend the Ergo Dox. Especially if you can get the kit that Massdrop produced, because the circuit boards are well-made. Otherwise, spend some time on the Geekhack &amp;amp; Deskthority forums, read some wiki pages, and test some keyboards. And if you’re interested in building the Atreus, join the &lt;a href=&quot;http://geekhack.org/index.php?topic=54759.0&quot;&gt;discussion&lt;/a&gt;! Everyone in that thread has been very helpful.  This project wouldn’t have been possible without their answers and advice.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Interested in commenting or contacting me? Send an email to &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&lt;/a&gt;. Thanks!&lt;/p&gt;

&lt;script async=&quot;&quot; src=&quot;//embedr.flickr.com/assets/client-code.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

</description>
        <pubDate>Tue, 19 Aug 2014 21:38:00 -0500</pubDate>
        <link>http://blog.mattgauger.com/2014/08/19/atreus-my-custom-keyboard/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2014/08/19/atreus-my-custom-keyboard/</guid>
        
        
      </item>
    
      <item>
        <title>Housekeeping: Imported Coderwall protips</title>
        <description>&lt;p&gt;As part of my continuing effort to archive content I’ve created to this blog, I’ve migrated all of &lt;a href=&quot;https://coderwall.com/p/u/mathias&quot;&gt;my Coderwall protips&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here’s a quick list of the posts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/2013/11/14/indent-and-colorize-html-strings-in-pry/&quot;&gt;Indent and Colorize HTML Strings in Pry&lt;/a&gt; &lt;em&gt;November 14, 2013.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2013/09/03/git-fml/&quot;&gt;git fml&lt;/a&gt; &lt;em&gt;September 3, 2013.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2013/07/27/minskys-circle-algorithm-in-shoes-dot-rb-slash-hackety-hack/&quot;&gt;Minsky’s Circle Algorithm in Shoes.rb / Hackety Hack&lt;/a&gt; &lt;em&gt;July 27, 2013.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2013/05/23/warning-nokogiri-was-built-against-libxml-version-x-dot-x-x/&quot;&gt;WARNING: Nokogiri Was Built Against LibXML Version x.x.x&lt;/a&gt; &lt;em&gt;May 23, 2013.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2013/04/24/reset-a-lost-password-on-an-ubuntu-vm/&quot;&gt;Reset a Lost Password on an Ubuntu VM&lt;/a&gt; &lt;em&gt;April 24, 2013.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2013/01/24/find-naughty-naughty-model-calls-in-your-views/&quot;&gt;Find Naughty Naughty Model Calls in Your Views&lt;/a&gt; &lt;em&gt;January 24, 2013.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2012/12/25/find-a-unique-name-for-your-project/&quot;&gt;Find a Unique Name for Your Project&lt;/a&gt; &lt;em&gt;December 25, 2012.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 27 Jul 2014 12:05:00 -0500</pubDate>
        <link>http://blog.mattgauger.com/2014/07/27/housekeeping-imported-coderwall-protips/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2014/07/27/housekeeping-imported-coderwall-protips/</guid>
        
        
      </item>
    
      <item>
        <title>Clojure Data Science: Refactoring and Cleanup</title>
        <description>&lt;hr /&gt;

&lt;p&gt;This is Part 2 of a series of blog posts called &lt;a href=&quot;/categories/clojure-data-science&quot;&gt;Clojure Data Science&lt;/a&gt;. Check out the &lt;a href=&quot;/blog/2014/03/30/clojure-data-science-ingesting-your-gmail-inbox/&quot;&gt;previous post&lt;/a&gt; if you missed it.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Welcome to the second post in this series. If you followed along in the last post, your code should be ready to use in this post. If not, or if you need to go back to known working state, you can clone the &lt;a href=&quot;https://github.com/mathias/autodjinn&quot;&gt;autodjinn repo&lt;/a&gt; and &lt;code&gt;git checkout v0.1.0&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I started out writing this post to develop simple functionality on our inbox data. Finishing the post was taking longer than I was expecting, so I split the post in half in the interest of posting this sooner.&lt;/p&gt;

&lt;p&gt;In this post, we need to create an email ingestion script that we can run repeatedly with &lt;code&gt;lein&lt;/code&gt;. And we need to talk about refactoring our code out into maintainable namespaces.&lt;/p&gt;

&lt;p&gt;So make sure your Datomic transactor is running and launch a REPL, because it is time to give our code a makeover.&lt;/p&gt;

&lt;h2 id=&quot;a-gmail-ingestion-script&quot;&gt;A Gmail ingestion script&lt;/h2&gt;

&lt;p&gt;Because Clojure sits on the JVM, it shares some similarities with Java. One of these is the special purpose of a &lt;code&gt;-main&lt;/code&gt; function. You can think of this as the &lt;code&gt;main&lt;/code&gt; method in a Java class. The &lt;code&gt;-main&lt;/code&gt; function in a Clojure namespace will be run when a tool like &lt;code&gt;lein&lt;/code&gt; tries to “run” the namespace. That sounds like exactly what we want to do with our Gmail import functionality, so we will add a &lt;code&gt;-main&lt;/code&gt; function that calls our &lt;code&gt;ingest-inbox&lt;/code&gt; function. To get started, we will only have it print us a message.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/9965864.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;You can then run this by invoking &lt;code&gt;lein run -m autodjinn.core&lt;/code&gt;. You should see &lt;code&gt;Hello world!&lt;/code&gt; if everything worked. You may notice that the process doesn’t seem to quit after it prints the hello world message – this seems to be problem with Leiningen. To ensure that our process ends when the script is done, we can add a &lt;code&gt;(System/exit 0)&lt;/code&gt; line to the end of our &lt;code&gt;-main&lt;/code&gt; function to ensure that the process quits normally. On *nix systems, a 0 return code means successful exit, and a nonzero response code means something went wrong. Knowing this, we can take advantage of response codes in the future to signal that an error occurred in our script. But for now, we will have the script end by returning 0 to indicate a successful exit.&lt;/p&gt;

&lt;p&gt;Think back to what we did to ingest email in our REPL in the last post. We had to connect to the database, run the data schema transaction, and then we were able to run &lt;code&gt;ingest-inbox&lt;/code&gt; to pull in our email.&lt;/p&gt;

&lt;p&gt;The following function will do the same thing. Remember that things like trying to create an existing database or performing a schema update against the same schema in Datomic should be harmless. It will add a new transaction ID, but it will not modify or destroy data. Putting together all the steps we need to run, we get a &lt;code&gt;-main&lt;/code&gt; function that looks like this:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/9965933.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;refactoring-namespaces&quot;&gt;Refactoring namespaces&lt;/h2&gt;

&lt;p&gt;With Clojure, one must walk a fine line between putting all of your functions into one big file, and having too many namespaces. One big file quickly grows unmaintainable and gains too many responsibilities.&lt;/p&gt;

&lt;p&gt;But having too many namespaces can also be a problem. It may create strange cyclic dependency errors. Or you may find that with many separate namespaces, you have to require many namespaces to get anything done.&lt;/p&gt;

&lt;p&gt;To avoid this, I start with most code in one namespace, and then look for common functionality to extract to a new namespace. Good candidates to extract are those that all talk about the same business logic or business domain. You may notice that the responsibility for one group of functions is different than the rest of the functions. That is a good candidate for a new namespace. Looking at responsibilities can be a good way to determine where to break apart functions into namespaces.&lt;/p&gt;

&lt;p&gt;In this project, we can identify two responsibilities that currently live in our autodjinn.core namespace. The first is working with the database. The second is ingesting Gmail messages. As our project grows, we will not want the code for ingesting Gmail messages to live in &lt;code&gt;autodjinn.core&lt;/code&gt;. With that in mind, let’s create a new file called &lt;code&gt;src/autodjinn/gmail_ingestion.clj&lt;/code&gt; and move over the vars and functions that we think should live there. That file should look like this:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/9966207.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Be sure to remove the functions and vars that we moved to this file from the &lt;code&gt;autodjinn.core&lt;/code&gt; namespace. Note that we moved the &lt;code&gt;-main&lt;/code&gt; function here, too, so that we can now run &lt;code&gt;lein run -m autodjinn.gmail-ingestion&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You may also notice that we still had to require the &lt;code&gt;datomic.api&lt;/code&gt; namespace here to be able to perform a transaction. Our &lt;code&gt;autodjinn.core&lt;/code&gt; namespace already handles database interaction, though. So let’s write a &lt;code&gt;create-mail&lt;/code&gt; function in &lt;code&gt;core.clj&lt;/code&gt; and call it in our new namespace:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/9966294.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;And in &lt;code&gt;gmail_ingestion.clj&lt;/code&gt; we change &lt;code&gt;ingest-inbox&lt;/code&gt; to use the new function. While we’re at it, we’ll break out a convenience function to prepare the attr map for Datomic:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/9966304.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;If we run our &lt;code&gt;lein run -m autodjinn.gmail-ingestion&lt;/code&gt; command, we should see that the code is still working.&lt;/p&gt;

&lt;p&gt;Don’t forget to remove the &lt;code&gt;datomic.api&lt;/code&gt; requirement in &lt;code&gt;gmail-ingestion&lt;/code&gt; namespace! Now we only need to require Datomic in the &lt;code&gt;autodjinn.core&lt;/code&gt; namespace.&lt;/p&gt;

&lt;p&gt;There’s one more low-hanging fruit that we can refactor about this code before moving on. The config file is loaded and used in both namespaces. We already require everything from &lt;code&gt;autodjinn.core&lt;/code&gt; into &lt;code&gt;autodjinn.gmail-ingestion&lt;/code&gt;. So we can safely change a few lines to use the config in &lt;code&gt;gmail_ingestion.clj&lt;/code&gt; and stop requiring &lt;code&gt;nomad&lt;/code&gt; in two places:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/9966372.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;And in &lt;code&gt;core.clj&lt;/code&gt;:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/mathias/9966384.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Running &lt;code&gt;lein run -m autodjinn.gmail-ingestion&lt;/code&gt; one more time, we should see that our changes did not break the system. The config is now only loaded once, and we use it everywhere.&lt;/p&gt;

&lt;p&gt;That’s it! We’ve taken care of some low-hanging fruit and are ready to implement some new functionality. If you want to compare what you’ve done with my version, you can run &lt;code&gt;git diff v0.1.1&lt;/code&gt; on the &lt;a href=&quot;https://github.com/mathias/autodjinn&quot;&gt;autodjinn repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Please let me know what you think of these posts by sending me an email at &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;&amp;#099;&amp;#111;&amp;#110;&amp;#116;&amp;#097;&amp;#099;&amp;#116;&amp;#064;&amp;#109;&amp;#097;&amp;#116;&amp;#116;&amp;#103;&amp;#097;&amp;#117;&amp;#103;&amp;#101;&amp;#114;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&lt;/a&gt;. I’d love to hear from you!&lt;/p&gt;
</description>
        <pubDate>Sun, 13 Apr 2014 16:28:00 -0500</pubDate>
        <link>http://blog.mattgauger.com/2014/04/13/clojure-data-science-refactoring-and-cleanup/</link>
        <guid isPermaLink="true">http://blog.mattgauger.com/2014/04/13/clojure-data-science-refactoring-and-cleanup/</guid>
        
        
      </item>
    
  </channel>
</rss>

